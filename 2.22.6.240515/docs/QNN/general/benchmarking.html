

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Benchmarking &mdash; Qualcomm® AI Engine Direct</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom_css.css" type="text/css" />
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Operations" href="operations.html" />
    <link rel="prev" title="Tutorials" href="tutorials.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Qualcomm® AI Engine Direct
          

          
          </a>

          
            
            
              <div class="version">
                v2.22.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="backend.html">Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="op_packages.html">Op Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Benchmarking</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#command-line-parameters">Command line parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-the-benchmark">Running the benchmark</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#running-inceptionv3-that-is-shipped-with-the-sdk">Running InceptionV3 that is shipped with the SDK</a></li>
<li class="toctree-l3"><a class="reference internal" href="#viewing-the-results-csv-file-or-json-file">Viewing the results (csv file or JSON file)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#running-the-benchmark-with-your-own-network-and-inputs">Running the benchmark with your own network and inputs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prepare-inputs">Prepare inputs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#create-a-run-configuration">Create a run configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#configuration-structure">Configuration structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="#architecture-support">Architecture support</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#run-the-benchmark">Run the benchmark</a></li>
<li class="toctree-l2"><a class="reference internal" href="#measurement-methodology">Measurement methodology</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#performance-timing">Performance (“timing”)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#benchmark-dependencies">Benchmark dependencies</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="operations.html">Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Qualcomm® AI Engine Direct</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Benchmarking</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="benchmarking">
<h1>Benchmarking<a class="headerlink" href="#benchmarking" title="Permalink to this heading">¶</a></h1>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">¶</a></h2>
<p>The benchmark shipped in the Qualcomm® <a class="reference internal" href="introduction.html#qnn-ai-engine-note"><span class="std std-ref">AI Engine Direct</span></a> SDK consists of a set of python scripts that runs a network on a
target device and collects performance metrics. It uses executables and libraries found in
the SDK package to run a compiled ‘’model.so’’ file on the target, using a set of inputs for the network,
and a file that points to that set of inputs.</p>
<p>The input to the benchmark scripts is a configuration file in JSON format. The SDK ships with a
configuration file for running the InceptionV3 model that is created following instructions in the SDK documentation.
The SDK users are encouraged to create their own configuration files and use the benchmark scripts to run on target devices
to collect timing measurements.</p>
<p>The configuration file allows the user to specify:</p>
<ul class="simple">
<li><p>Name of the benchmark (i.e., InceptionV3)</p></li>
<li><p>Host path to use for storing results</p></li>
<li><p>Device paths to use (where to push the necessary files for running the benchmark)</p></li>
<li><p>Device to run the benchmark on (only one device is supported per run)</p></li>
<li><p>Hostname/IP of the remote machine to which devices are connected</p></li>
<li><p>Number of times to repeat the run</p></li>
<li><p>Model specifics (name, location of ‘’model.so’’, location of inputs, etc.)</p></li>
<li><p>QNN backend configuration(s) to use (combination of CPU, GPU, and DSP)</p></li>
<li><p>Measurements to take (“timing”)</p></li>
<li><p>Profiling level of measurements (“basic” or “detailed”)</p></li>
</ul>
</div>
<div class="section" id="command-line-parameters">
<h2>Command line parameters<a class="headerlink" href="#command-line-parameters" title="Permalink to this heading">¶</a></h2>
<p>To see all available command line parameters use the “-h” option when running <code class="docutils literal notranslate"><span class="pre">qnn_bench.py</span></code>.</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span>usage: qnn_bench.py [-h] -c CONFIG_FILE [-o OUTPUT_BASE_DIR_OVERRIDE]
                    [-v DEVICE_ID_OVERRIDE] [-r HOST_NAME]
                    [-t DEVICE_OS_TYPE_OVERRIDE] [-d] [-s SLEEP]
                    [-n ITERATIONS] [-p PERFPROFILE]
                    [--backend_config BACKEND_CONFIG] [-l PROFILINGLEVEL]
                    [-json] [-be BACKEND [BACKEND ...]] [--htp_serialized]
                    [--dsp_type {v65,v66,v68,v69,v73,v75}]
                    [--arm_prepare] [--use_signed_skel] [--discard_output]
                    [--test_duration TEST_DURATION] [--enable_cache]
                    [--shared_buffer] [--clean_artifacts] [--cdsp_id {0,1}]

Run the qnn_bench

required arguments:
  -c CONFIG_FILE, --config_file CONFIG_FILE
                        Path to a valid config file
                        Refer to sample config file config_help.json present at &lt;SDK_ROOT&gt;/benchmarks/QNN/
                        to know details on how to fill parameters in config file

optional arguments:
  -o OUTPUT_BASE_DIR_OVERRIDE, --output_base_dir_override OUTPUT_BASE_DIR_OVERRIDE
                        Sets the output base directory.
  -v DEVICE_ID_OVERRIDE, --device_id_override DEVICE_ID_OVERRIDE
                        Use this device ID instead of the one supplied in config file.
  -r HOST_NAME, --host_name HOST_NAME
                        Hostname/IP of remote machine to which devices are connected.
  -t DEVICE_OS_TYPE_OVERRIDE, --device_os_type_override DEVICE_OS_TYPE_OVERRIDE
                        Specify the target OS type, valid options are
                        [&#39;aarch64-android&#39;, &#39;aarch64-windows-msvc&#39;, &#39;aarch64-qnx&#39;,
                        &#39;aarch64-oe-linux-gcc9.3&#39;, &#39;aarch64-oe-linux-gcc8.2&#39;, &#39;aarch64-ubuntu-gcc7.5&#39;]
  -d, --debug           Set to turn on debug log
  -s SLEEP, --sleep SLEEP
                        Set number of seconds to sleep between runs e.g. 20 seconds
  -n ITERATIONS, --iterations ITERATIONS
                        Set the number of iterations to execute for calculating metrics
  -p PERFPROFILE, --perfprofile PERFPROFILE
                        Specify the perf profile to set. Valid settings are
                        low_balanced, balanced, default, high_performance,
                        sustained_high_performance, burst, low_power_saver,
                        power_saver, high_power_saver, system_settings
  --backend_config BACKEND_CONFIG
                        config file to specify context priority or provide backend extensions related parameters or enable htp specific linting profile
  -l PROFILINGLEVEL, --profilinglevel PROFILINGLEVEL
                        Set the profiling level mode (basic, detailed, backend). Default is basic.
  -json, --generate_json
                        Set to produce json output.
  -be BACKEND [BACKEND ...], --backend BACKEND [BACKEND ...]
                        The backend to use
  --htp_serialized      qnn graph prepare is done on x86 and execute is run on target
  --dsp_type {v65,v66,v68,v69,v73,v75}
                        Specify DSP variant for QNN BM run
  --arm_prepare         qnn graph prepare is done on ARM and execute is run on target
  --use_signed_skel     use signed skels for HTP runs
  --discard_output      To discard writing output tensors after test execution.
  --test_duration TEST_DURATION
                        Specify duration for test execution in seconds
                        Loops over the input_list until this amount of time has transpired
  --enable_cache        To prepare graph on device first using qnn-context-binary-generator and
                         and then execute graph using qnn-net-run to accelerate the execution. Defaults to disable.
  --shared_buffer       Enables usage of shared buffer between application and backend for graph I/O
  --clean_artifacts     Clean the model specific artifacts after inference
  --cdsp_id {0,1}       To specify cdsp core to use when a SOC has multiple cdsp cores. By Default is 0.
</pre></div>
</div>
</div>
<div class="section" id="running-the-benchmark">
<h2>Running the benchmark<a class="headerlink" href="#running-the-benchmark" title="Permalink to this heading">¶</a></h2>
<div class="section" id="prerequisites">
<h3>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Set up the QNN SDK using the steps provided in <a class="reference internal" href="setup.html"><span class="doc">Setup</span></a>.</p></li>
<li><p>Complete the 'Tutorial Setup' and 'Model Conversion and Build' sections of <a class="reference internal" href="tutorial2.html"><span class="doc">Converting and executing a CNN model with QNN</span></a>.</p></li>
<li><p>(Optional) If the device is connected to a remote machine, the remote adb server setup must be
performed by the user.</p></li>
</ul>
</div>
<div class="section" id="running-inceptionv3-that-is-shipped-with-the-sdk">
<h3>Running InceptionV3 that is shipped with the SDK<a class="headerlink" href="#running-inceptionv3-that-is-shipped-with-the-sdk" title="Permalink to this heading">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">qnn_bench.py</span></code> is the main benchmark script to measure and report performance statistics. To use it with the InceptionV3 model:</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp"># Running inceptionV3_sample.json (CPU backend)</span>
<span class="n">cd</span><span class="w"> </span><span class="n">$QNN_SDK_ROOT</span><span class="o">/</span><span class="n">benchmarks</span><span class="o">/</span><span class="n">QNN</span>
<span class="n">python3</span><span class="mf">.10</span><span class="w"> </span><span class="n">qnn_bench</span><span class="p">.</span><span class="n">py</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">inceptionV3_sample</span><span class="p">.</span><span class="n">json</span>

<span class="cp"># Running inceptionV3_quantized_sample.json (HTP backend by generating context binary on X86)</span>
<span class="n">cd</span><span class="w"> </span><span class="n">$QNN_SDK_ROOT</span><span class="o">/</span><span class="n">benchmarks</span><span class="o">/</span><span class="n">QNN</span>
<span class="n">python3</span><span class="mf">.10</span><span class="w"> </span><span class="n">qnn_bench</span><span class="p">.</span><span class="n">py</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">inceptionV3_quantized_sample</span><span class="p">.</span><span class="n">json</span><span class="w"> </span><span class="o">--</span><span class="n">dsp_type</span><span class="w"> </span><span class="n">v68</span><span class="w"> </span><span class="o">--</span><span class="n">htp_serialized</span>
</pre></div>
</div>
</div>
<div class="section" id="viewing-the-results-csv-file-or-json-file">
<h3>Viewing the results (csv file or JSON file)<a class="headerlink" href="#viewing-the-results-csv-file-or-json-file" title="Permalink to this heading">¶</a></h3>
<p>All results are stored in the “HostResultDir” directory that is specified in the configuration JSON file. The
benchmark creates time-stamped directories for each benchmark run. All timing results are stored in
microseconds.</p>
<p>For convenience, a <code class="docutils literal notranslate"><span class="pre">latest_results</span></code> link is created that always points to the most recent run.</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp"># In inceptionV3_sample.json, &quot;HostResultDir&quot; is set to &quot;inception_v3.repo/results&quot;</span>
<span class="n">cd</span><span class="w"> </span><span class="n">$QNN_SDK_ROOT</span><span class="o">/</span><span class="n">benchmarks</span><span class="o">/</span><span class="n">QNN</span><span class="o">/</span><span class="n">inception_v3</span><span class="p">.</span><span class="n">repo</span><span class="o">/</span><span class="n">results</span>
<span class="cp"># Notice the time stamped directories and the &quot;latest_results&quot; link.</span>
<span class="n">cd</span><span class="w"> </span><span class="n">$QNN_SDK_ROOT</span><span class="o">/</span><span class="n">benchmarks</span><span class="o">/</span><span class="n">QNN</span><span class="o">/</span><span class="n">inception_v3</span><span class="p">.</span><span class="n">repo</span><span class="o">/</span><span class="n">results</span><span class="o">/</span><span class="n">latest_results</span>
<span class="cp"># Notice the .csv file, open this file in a csv viewer (Excel, LibreOffice Calc)</span>
<span class="cp"># Notice the .json file, open the file with any text editor</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><strong>CSV benchmark results file</strong></div>
</div>
<p>The CSV file contains results similar to the example below. Some measurements may not be apparent in
the CSV file. To get all timing information, the profiling level must be set to <em>detailed</em>. By default,
the profiling level is set to <em>basic</em>.</p>
<div class="figure align-default">
<img alt="../_static/resources/benchmarking_csv_output.png" src="../_static/resources/benchmarking_csv_output.png" />
</div>
<div class="line-block">
<div class="line"><strong>Section 1: Execution information</strong></div>
</div>
<p>This section contains:</p>
<ul class="simple">
<li><p>SDK version used to generate the benchmark run</p></li>
<li><p>Model name and path to the compiled model file</p></li>
<li><p>Backends selected for the benchmark</p></li>
<li><p>Additional execution information</p></li>
</ul>
<div class="line-block">
<div class="line"><strong>Section 2: Performance metrics</strong></div>
</div>
<p>This section contains measurements for model initialization and execution. The profiling level
affects the amount of measurements collected.</p>
<ul class="simple">
<li><p>Init Stats [NetRun] measures the time taken to build and configure QNN.</p></li>
<li><p>Finalize Stats [NetRun] measures the time taken by QNN to finalize the graph.</p></li>
<li><p>De-Init Stats [NetRun] measures the time taken to de-initialize QNN.</p></li>
<li><p>Total Inference Time [NetRun] measures the entire execution time of one inference pass. This
includes any input and output processing, copying of data, etc. This is measured at the start and
end of the execute call.</p></li>
</ul>
<div class="line-block">
<div class="line"><strong>Section 3: Per-layer detailed performance statistics</strong></div>
</div>
<p>This section contains the execution stats of each layer of the neural network model.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This information will be present only if the profiling level is set to <em>detailed</em>.</p>
</div>
<div class="line-block">
<div class="line"><strong>JSON benchmark results file</strong></div>
</div>
<p>The benchmark results published in the CSV file can also be made available in JSON format. The
contents are the same as in the CSV file, structured as key-value pairs, and will help parsing the
results in a simple and efficient manner. The JSON file contains results similar to the following example.</p>
<div class="figure align-default">
<img alt="../_static/resources/benchmarking_json_output.png" src="../_static/resources/benchmarking_json_output.png" />
</div>
<div class="line-block">
<div class="line"><strong>Section 4: Linting Profile Stats</strong></div>
</div>
<p>Linting profiling mode is an HTP exclusive configuration that provides per op
cycle count on the main thread as well as background execution information.
See here <a class="reference internal" href="htp/htp_backend.html#qnn-htp-profiling"><span class="std std-ref">QNN HTP Profiling</span></a> for more information.</p>
</div>
</div>
<div class="section" id="running-the-benchmark-with-your-own-network-and-inputs">
<h2>Running the benchmark with your own network and inputs<a class="headerlink" href="#running-the-benchmark-with-your-own-network-and-inputs" title="Permalink to this heading">¶</a></h2>
<div class="section" id="prepare-inputs">
<h3>Prepare inputs<a class="headerlink" href="#prepare-inputs" title="Permalink to this heading">¶</a></h3>
<p>Before running the benchmark, prepare the following inputs:</p>
<ul>
<li><p><em>your_model.so</em>.
See <a class="reference internal" href="overview.html#qnn-basic-workflow-figure"><span class="std std-ref">QNN Integration Workflow</span></a> for the model.so creation workflow.</p></li>
<li><p>A text file listing all of your input data.
For an example, see: <code class="docutils literal notranslate"><span class="pre">$QNN_SDK_ROOT/examples/Models/InceptionV3/data/target_raw_list.txt</span></code>.</p></li>
<li><p>All of the input data that is listed in the above text file.
For an example, refer to the <code class="docutils literal notranslate"><span class="pre">$QNN_SDK_ROOT/examples/Models/InceptionV3/data/cropped</span></code> directory.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">target_raw_list.txt</span></code> must exactly match the structure of your input directory.</p>
</div>
</li>
</ul>
</div>
</div>
<div class="section" id="create-a-run-configuration">
<h2>Create a run configuration<a class="headerlink" href="#create-a-run-configuration" title="Permalink to this heading">¶</a></h2>
<div class="section" id="configuration-structure">
<h3>Configuration structure<a class="headerlink" href="#configuration-structure" title="Permalink to this heading">¶</a></h3>
<p>The configuration file is a JSON file with a predefined structure.
Refer to <code class="docutils literal notranslate"><span class="pre">$QNN_SDK_ROOT/benchmarks/QNN/inceptionV3_sample.json</span></code> as an example.</p>
<p>Required fields:</p>
<ul>
<li><p><strong>Name</strong> – Name of the configuration, e.g., InceptionV3.</p></li>
<li><p><strong>HostRootPath</strong> – Top level output folder on the host. This can be an absolute path or a relative
path to the current working directory.</p></li>
<li><p><strong>HostResultDir</strong> – Folder on the host where all benchmark results are put. This can be an absolute
path or a relative path to the current working directory.</p></li>
<li><p><strong>DevicePath</strong> – Folder on the device where all benchmark-related data and artifacts are put,
e.g., /data/local/tmp/qnnbm.repo.</p></li>
<li><p><strong>Devices</strong> – Serial number of the device on which the benchmark runs. Only one device is
currently supported.</p></li>
<li><p><strong>Runs</strong> – Number of times that the benchmark runs for each of the “Backend” and “Measurements”
run combinations.</p></li>
<li><p><strong>Model</strong></p>
<blockquote>
<div><ul class="simple">
<li><p><strong>Name</strong> – Name of the DNN model, e.g., InceptionV3.</p></li>
<li><p><strong>qnn_model</strong> – Folder where the compiled ‘’model.so’’ file is located on the host. This can be
an absolute path or a relative path to the current working directory.</p></li>
<li><p><strong>InputList</strong> – Text filepath that lists all of the input data. This can be an absolute path
or a relative path to the current working directory.</p></li>
<li><p><strong>Data</strong> – A list of data files or folders that are listed in the InputList file. This can be an absolute
path or a relative path to the current working directory. If the path is a folder, all contents
of that folder will be pushed to the device.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Backends</strong> – Possible values are “GPU”, “DSP”, and “CPU”. Any combination of these can be used.</p></li>
<li><p><strong>Measurements</strong> – Possible value is “timing”. Measurement type is measured alone for each run.</p></li>
</ul>
<p>Optional fields:</p>
<ul class="simple">
<li><p><strong>HostName</strong> – Hostname/IP of the remote machine to which devices are connected. The default value is
‘localhost’.</p></li>
<li><p><strong>PerfProfile</strong> – Performance mode to enable. The default is ‘high_performance’.</p></li>
<li><p><strong>ProfilingLevel</strong> – Profiling level to enable. The default is ‘basic’.</p></li>
</ul>
</div>
<div class="section" id="architecture-support">
<h3>Architecture support<a class="headerlink" href="#architecture-support" title="Permalink to this heading">¶</a></h3>
<p>Android AARCH 64-bit is supported.</p>
<div class="line-block">
<div class="line">Backend and measurement are concatenated to make a full run combination name, e.g.,</div>
<div class="line">“GPU_timing”: GPU backend, timing measurement</div>
</div>
</div>
</div>
<div class="section" id="run-the-benchmark">
<h2>Run the benchmark<a class="headerlink" href="#run-the-benchmark" title="Permalink to this heading">¶</a></h2>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span><span class="w"> </span><span class="n">$QNN_SDK_ROOT</span><span class="o">/</span><span class="n">benchmarks</span><span class="o">/</span><span class="n">QNN</span>
<span class="n">python3</span><span class="mf">.10</span><span class="w"> </span><span class="n">qnn_bench</span><span class="p">.</span><span class="n">py</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">yourmodel</span><span class="p">.</span><span class="n">json</span>
</pre></div>
</div>
<p>The benchmark will perform an md5sum on the host files (those specified in the JSON configuration) and
on the device files. Because of the md5sum check, the files needed for running the benchmark must be
available on the host.</p>
<p>For any file that exists both on the host and on the device with mismatch md5, the benchmark will copy
the file from the host to the target and issue a warning message notifying that the local files do
not match the device files. This is done to be sure that the results received from a
benchmark run accurately reflect the files specified in the JSON file.</p>
<p><strong>Other options</strong></p>
<div class="line-block">
<div class="line"><strong>-v option</strong></div>
<div class="line">Allows user to override the device ID specified in the configuration file, so that the same configuration file</div>
<div class="line">can be used across multiple devices.</div>
</div>
<div class="line-block">
<div class="line"><strong>-o option</strong></div>
<div class="line">Result output base directory override applies only if the relative paths are specified for HostRootPath</div>
<div class="line">and HostResultsDir. It allows pooling the output regardless of from where the benchmark is run.</div>
</div>
<div class="line-block">
<div class="line"><strong>-t option</strong></div>
<div class="line">OS Type override currently supports Android aarch64 (arm64-v8a) devices.</div>
</div>
<div class="line-block">
<div class="line"><strong>-n option</strong></div>
<div class="line">Allows user to specify the number of times to repeat the runs to calculate the performance metrics.</div>
</div>
<div class="line-block">
<div class="line"><strong>-p option</strong></div>
<div class="line">Allows user to profile performance in different operating modes.</div>
</div>
<div class="line-block">
<div class="line"><strong>-l option</strong></div>
<div class="line">Allows user to specify the level of performance profiling.</div>
</div>
<div class="line-block">
<div class="line"><strong>-json option</strong></div>
<div class="line">Allows user to generate the result in JSON format along with default CSV format.</div>
</div>
<div class="line-block">
<div class="line"><strong>-be option</strong></div>
<div class="line">Allows user to set the backend to use.</div>
</div>
<div class="line-block">
<div class="line"><strong>--dsp_type option</strong></div>
<div class="line">Allows user to mention the dsp_type of the device.</div>
</div>
<div class="line-block">
<div class="line"><strong>--htp_serialized option</strong></div>
<div class="line">Allows user to prepare graph using HTP emulator on x86 and execute on the target.</div>
</div>
<div class="line-block">
<div class="line"><strong>--shared_buffer option</strong></div>
<div class="line">Specifies using shared buffers for a zero-copy usecase between the application and device/co-processor</div>
<div class="line">associated with the backend.</div>
</div>
<div class="line-block">
<div class="line"><strong>--arm_prepare option</strong></div>
<div class="line">Allows user to prepare graph on arm and execute on the target.</div>
</div>
<div class="line-block">
<div class="line"><strong>--backend_config option</strong></div>
<div class="line">Allows user to specify context priority or provide backend extensions related parameters or htp specific linting profile.</div>
</div>
<div class="line-block">
<div class="line"><strong>Reading the results</strong></div>
<div class="line">Open the results (CSV file or JSON file) in the <code class="docutils literal notranslate"><span class="pre">&lt;HostResultsDir&gt;/latest_results</span></code> folder to view</div>
<div class="line">the results. (<code class="docutils literal notranslate"><span class="pre">&lt;HostResultsDir&gt;</span></code> is what is specified in the JSON configuration file.)</div>
</div>
</div>
<div class="section" id="measurement-methodology">
<h2>Measurement methodology<a class="headerlink" href="#measurement-methodology" title="Permalink to this heading">¶</a></h2>
<p>In all cases, the <code class="docutils literal notranslate"><span class="pre">qnn-net-run</span></code> executable is used to load a model and run inputs through the model.</p>
<div class="section" id="performance-timing">
<h3>Performance (“timing”)<a class="headerlink" href="#performance-timing" title="Permalink to this heading">¶</a></h3>
<p>Timing measurements are taken using internal timing utilities inside the QNN libraries.
When <code class="docutils literal notranslate"><span class="pre">qnn-net-run</span></code> is executed, the libraries will log timing information to a file. This file is then parsed
offline to retrieve the total inference times and per-layer times.</p>
<p>The total inference times include both the per-layer computation times plus overhead, such as data
movements between layers, as well as into and out of backend. The per-layer times are
strictly computational times for each layer. For smaller networks, the overhead can be
significant relative to the computational time, particularly when offloading the networks to run on GPU
or DSP.</p>
<p>Further optimizations present on the GPU/DSP may cause layer times to be misattributed,
in the case of neuron conv-neuron or fc-neuron pairs. When executing on GPU, the total time of the
pairs would be assigned to convs, whereas for DSP, they would be assigned to the neurons.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Detailed and Linting Profiling will cause performance impact.</p>
</div>
</div>
<div class="section" id="benchmark-dependencies">
<h3>Benchmark dependencies<a class="headerlink" href="#benchmark-dependencies" title="Permalink to this heading">¶</a></h3>
<p>Binaries that the benchmark script depends on are in the following configuration files (depending on
the target architecture, compiler, and STL library):</p>
<ul>
<li><p><strong>Android 64-bit</strong></p>
<blockquote>
<div><ul class="simple">
<li><p><strong>clang</strong> - libc++: <code class="docutils literal notranslate"><span class="pre">bm_utils/qnnbm_artifacts_android_aarch64.json</span></code></p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="operations.html" class="btn btn-neutral float-right" title="Operations" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="tutorials.html" class="btn btn-neutral float-left" title="Tutorials" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020-2024, Qualcomm Technologies, Inc..

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>