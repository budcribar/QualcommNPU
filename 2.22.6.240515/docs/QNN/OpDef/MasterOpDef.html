

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>QNN Operation Definitions &mdash; Qualcomm® AI Engine Direct</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom_css.css" type="text/css" />
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CPU Backend Op Definition Supplement" href="CpuOpDefSupplement.html" />
    <link rel="prev" title="Common Terminology" href="../general/terminology.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Qualcomm® AI Engine Direct
          

          
          </a>

          
            
            
              <div class="version">
                v2.22.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../general/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/backend.html">Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/op_packages.html">Op Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../general/operations.html">Operations</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="SupportedOps.html">Supported Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="opdef_version_history.html">Op Definition Revision History</a></li>
<li class="toctree-l2"><a class="reference internal" href="opdef_version_history.html#backend-specific-revision-history">Backend Specific Revision History</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../general/operations.html#operation-definitions">Operation Definitions</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../general/terminology.html">Common Terminology</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Master Definitions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#argbtorgb">ArgbToRgb</a></li>
<li class="toctree-l4"><a class="reference internal" href="#argmax">Argmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="#argmin">Argmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="#axisalignedbboxtransform">AxisAlignedBboxTransform</a></li>
<li class="toctree-l4"><a class="reference internal" href="#batchnorm">Batchnorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="#batchpermutation">BatchPermutation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#batchtospace">BatchToSpace</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bboxtransform">BboxTransform</a></li>
<li class="toctree-l4"><a class="reference internal" href="#boxwithnmslimit">BoxWithNmsLimit</a></li>
<li class="toctree-l4"><a class="reference internal" href="#buffer">Buffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cast">Cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="#channelshuffle">ChannelShuffle</a></li>
<li class="toctree-l4"><a class="reference internal" href="#collectrpnproposals">CollectRpnProposals</a></li>
<li class="toctree-l4"><a class="reference internal" href="#concat">Concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="#constantofshape">ConstantOfShape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conv1d">Conv1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conv2d">Conv2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conv3d">Conv3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#convert">Convert</a></li>
<li class="toctree-l4"><a class="reference internal" href="#correlation1d">Correlation1D</a></li>
<li class="toctree-l4"><a class="reference internal" href="#createsparse">CreateSparse</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cropandresize">CropAndResize</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cumulativesum">CumulativeSum</a></li>
<li class="toctree-l4"><a class="reference internal" href="#depthtospace">DepthToSpace</a></li>
<li class="toctree-l4"><a class="reference internal" href="#depthwiseconv1d">DepthWiseConv1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#depthwiseconv2d">DepthWiseConv2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dequantize">Dequantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="#detectionoutput">DetectionOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="#distributefpnproposals">DistributeFpnProposals</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseabs">ElementWiseAbs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseadd">ElementWiseAdd</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseand">ElementWiseAnd</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseasin">ElementWiseAsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseatan">ElementWiseAtan</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisebinary">ElementWiseBinary</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseceil">ElementWiseCeil</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisecos">ElementWiseCos</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisedivide">ElementWiseDivide</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseequal">ElementWiseEqual</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseexp">ElementWiseExp</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisefloor">ElementWiseFloor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisefloordiv">ElementWiseFloorDiv</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisefmod">ElementWiseFmod</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisegreater">ElementWiseGreater</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisegreaterequal">ElementWiseGreaterEqual</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseless">ElementWiseLess</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiselessequal">ElementWiseLessEqual</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiselog">ElementWiseLog</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisemaximum">ElementWiseMaximum</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseminimum">ElementWiseMinimum</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisemod">ElementWiseMod</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisemultiply">ElementWiseMultiply</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseneg">ElementWiseNeg</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseneuron">ElementWiseNeuron</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisenot">ElementWiseNot</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisenotequal">ElementWiseNotEqual</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseor">ElementWiseOr</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisepower">ElementWisePower</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseround">ElementWiseRound</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisersqrt">ElementWiseRsqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseselect">ElementWiseSelect</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisesign">ElementWiseSign</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisesin">ElementWiseSin</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisesoftplus">ElementWiseSoftplus</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisesquareddifference">ElementWiseSquaredDifference</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisesquareroot">ElementWiseSquareRoot</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisesubtract">ElementWiseSubtract</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwiseunary">ElementWiseUnary</a></li>
<li class="toctree-l4"><a class="reference internal" href="#elementwisexor">ElementWiseXor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id593">Elu</a></li>
<li class="toctree-l4"><a class="reference internal" href="#expanddims">ExpandDims</a></li>
<li class="toctree-l4"><a class="reference internal" href="#extractglimpse">ExtractGlimpse</a></li>
<li class="toctree-l4"><a class="reference internal" href="#extractpatches">ExtractPatches</a></li>
<li class="toctree-l4"><a class="reference internal" href="#fullyconnected">FullyConnected</a></li>
<li class="toctree-l4"><a class="reference internal" href="#gather">Gather</a></li>
<li class="toctree-l4"><a class="reference internal" href="#gatherelements">GatherElements</a></li>
<li class="toctree-l4"><a class="reference internal" href="#gathernd">GatherNd</a></li>
<li class="toctree-l4"><a class="reference internal" href="#gelu">Gelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generateproposals">GenerateProposals</a></li>
<li class="toctree-l4"><a class="reference internal" href="#getsparseindices">GetSparseIndices</a></li>
<li class="toctree-l4"><a class="reference internal" href="#getsparsevalues">GetSparseValues</a></li>
<li class="toctree-l4"><a class="reference internal" href="#gridsample">GridSample</a></li>
<li class="toctree-l4"><a class="reference internal" href="#groupnorm">GroupNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="#gru">Gru</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hardswish">HardSwish</a></li>
<li class="toctree-l4"><a class="reference internal" href="#heatmapmaxkeypoint">HeatMapMaxKeyPoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="#if">If</a></li>
<li class="toctree-l4"><a class="reference internal" href="#imageprojectiontransform">ImageProjectionTransform</a></li>
<li class="toctree-l4"><a class="reference internal" href="#instancenorm">InstanceNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="#l2norm">L2Norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="#l2pool2d">L2Pool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#layernorm">LayerNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="#logsoftmax">LogSoftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="#lrn">Lrn</a></li>
<li class="toctree-l4"><a class="reference internal" href="#lstm">Lstm</a></li>
<li class="toctree-l4"><a class="reference internal" href="#maskedsoftmax">MaskedSoftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="#matmul">MatMul</a></li>
<li class="toctree-l4"><a class="reference internal" href="#moments">Moments</a></li>
<li class="toctree-l4"><a class="reference internal" href="#multiclassnms">MultiClassNms</a></li>
<li class="toctree-l4"><a class="reference internal" href="#nonmaxsuppression">NonMaxSuppression</a></li>
<li class="toctree-l4"><a class="reference internal" href="#nonzero">NonZero</a></li>
<li class="toctree-l4"><a class="reference internal" href="#nv12torgb">Nv12ToRgb</a></li>
<li class="toctree-l4"><a class="reference internal" href="#nv21torgb">Nv21ToRgb</a></li>
<li class="toctree-l4"><a class="reference internal" href="#onehot">OneHot</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pack">Pack</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pad">Pad</a></li>
<li class="toctree-l4"><a class="reference internal" href="#poolavg2d">PoolAvg2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#poolavg3d">PoolAvg3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#poolmax2d">PoolMax2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#poolmax3d">PoolMax3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#prelu">Prelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantize">Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reducemax">ReduceMax</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reducemean">ReduceMean</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reducemin">ReduceMin</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reduceprod">ReduceProd</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reducesum">ReduceSum</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reducesumsquare">ReduceSumSquare</a></li>
<li class="toctree-l4"><a class="reference internal" href="#relu">Relu</a></li>
<li class="toctree-l4"><a class="reference internal" href="#relu1">Relu1</a></li>
<li class="toctree-l4"><a class="reference internal" href="#relu6">Relu6</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reluminmax">ReluMinMax</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reshape">Reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#resize">Resize</a></li>
<li class="toctree-l4"><a class="reference internal" href="#resizebilinear">ResizeBilinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="#resizenearestneighbor">ResizeNearestNeighbor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#roialign">RoiAlign</a></li>
<li class="toctree-l4"><a class="reference internal" href="#roipooling">RoiPooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="#scatterelements">ScatterElements</a></li>
<li class="toctree-l4"><a class="reference internal" href="#scatternd">ScatterNd</a></li>
<li class="toctree-l4"><a class="reference internal" href="#shape">Shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#sigmoid">Sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="#softmax">Softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="#spacetobatch">SpaceToBatch</a></li>
<li class="toctree-l4"><a class="reference internal" href="#spacetodepth">SpaceToDepth</a></li>
<li class="toctree-l4"><a class="reference internal" href="#sparsetodense">SparseToDense</a></li>
<li class="toctree-l4"><a class="reference internal" href="#split">Split</a></li>
<li class="toctree-l4"><a class="reference internal" href="#squeeze">Squeeze</a></li>
<li class="toctree-l4"><a class="reference internal" href="#stridedslice">StridedSlice</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tanh">Tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tile">Tile</a></li>
<li class="toctree-l4"><a class="reference internal" href="#topk">TopK</a></li>
<li class="toctree-l4"><a class="reference internal" href="#transpose">Transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="#transposeconv1d">TransposeConv1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#transposeconv2d">TransposeConv2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#transposeconv3d">TransposeConv3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="#unpack">UnPack</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../general/operations.html#backend-supplements">Backend Supplements</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../general/api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/glossary.html">Glossary</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Qualcomm® AI Engine Direct</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../general/operations.html">Operations</a> &raquo;</li>
        
      <li>QNN Operation Definitions</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="qnn-operation-definitions">
<h1>QNN Operation Definitions<a class="headerlink" href="#qnn-operation-definitions" title="Permalink to this heading">¶</a></h1>
<p>This document defines operations supported by QNN. Per backend specific information is referenced as needed.</p>
<div class="section" id="argbtorgb">
<span id="id1"></span><h2>ArgbToRgb<a class="headerlink" href="#argbtorgb" title="Permalink to this heading">¶</a></h2>
<p>Transform ARGB or RGBA to RGB. Refer to input_order and reverse_output
below for control of the input/output order.</p>
<div class="section" id="inputs">
<h3>Inputs<a class="headerlink" href="#inputs" title="Permalink to this heading">¶</a></h3>
<div class="section" id="in-0">
<h4>in[0]<a class="headerlink" href="#in-0" title="Permalink to this heading">¶</a></h4>
<p>Input tensor</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [b,h,w,4]</p></li>
</ul>
</div>
</div>
<div class="section" id="parameters">
<h3>Parameters<a class="headerlink" href="#parameters" title="Permalink to this heading">¶</a></h3>
<div class="section" id="input-order">
<h4>input_order<a class="headerlink" href="#input-order" title="Permalink to this heading">¶</a></h4>
<p>Controls the order of the input tensor. If QNN_OP_ARGB_TO_RGB_INPUT_ORDER
is QNN_OP_ARGB_TO_RGB_INPUT_ORDER_ARGB the input order is ARGB;
if QNN_OP_ARGB_TO_RGB_INPUT_ORDER_RGBA is selected then the input order is RGBA.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>ARGB = 0,</p></li>
<li><p>RGBA = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="reverse-output">
<h4>reverse_output<a class="headerlink" href="#reverse-output" title="Permalink to this heading">¶</a></h4>
<p>Controls the order of the output tensor. Set to false the order of the input
tensor is maintained in the output tensor. Set to true, the order of the last
3 channels of the input tensor is reversed in the output tensor.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
</div>
<div class="section" id="outputs">
<h3>Outputs<a class="headerlink" href="#outputs" title="Permalink to this heading">¶</a></h3>
<div class="section" id="out-0">
<h4>out[0]<a class="headerlink" href="#out-0" title="Permalink to this heading">¶</a></h4>
<p>Output tensor</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [b,h,w,3]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="argmax">
<span id="id2"></span><h2>Argmax<a class="headerlink" href="#argmax" title="Permalink to this heading">¶</a></h2>
<p>Returns the index of the largest element along an axis.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ArgMax">ops::ArgMax</a></p></li>
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0af78048ff71a1e79bbc6034d30cad7cbc">ANEURALNETWORKS_ARGMAX</a></p></li>
<li><p>QNN: <a class="reference internal" href="#argmin">Argmin</a></p></li>
</ul>
<div class="section" id="id3">
<h3>Inputs<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id4">
<h4>in[0]<a class="headerlink" href="#id4" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: n-dimensional</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id5">
<h3>Parameters<a class="headerlink" href="#id5" title="Permalink to this heading">¶</a></h3>
<div class="section" id="axis">
<h4>axis<a class="headerlink" href="#axis" title="Permalink to this heading">¶</a></h4>
<p>Axis on which to reduce across.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [0, n-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="keep-dims">
<h4>keep_dims<a class="headerlink" href="#keep-dims" title="Permalink to this heading">¶</a></h4>
<p>If true, the resulting tensor has the same number of dimensions as the input tensor.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id6">
<h3>Outputs<a class="headerlink" href="#id6" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id7">
<h4>out[0]<a class="headerlink" href="#id7" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32, QNN_DATATYPE_UINT_32, backend specific</p></li>
<li><p>Shape: m-dimensional, where m = n if <em>keep_dims</em> is true and m = n - 1 otherwise.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="argmin">
<span id="id8"></span><h2>Argmin<a class="headerlink" href="#argmin" title="Permalink to this heading">¶</a></h2>
<p>Returns the index of the smallest element along an axis.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ArgMin">ops::ArgMin</a></p></li>
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a89be86ff36e83254e9b3d0954e7e0729">ANEURALNETWORKS_ARGMIN</a></p></li>
<li><p>QNN: <a class="reference internal" href="#argmax">Argmax</a></p></li>
</ul>
<div class="section" id="id9">
<h3>Inputs<a class="headerlink" href="#id9" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id10">
<h4>in[0]<a class="headerlink" href="#id10" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: n-dimensional</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id11">
<h3>Parameters<a class="headerlink" href="#id11" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id12">
<h4>axis<a class="headerlink" href="#id12" title="Permalink to this heading">¶</a></h4>
<p>Axis on which to reduce across.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [0, n-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id13">
<h4>keep_dims<a class="headerlink" href="#id13" title="Permalink to this heading">¶</a></h4>
<p>If true, the resulting tensor has the same number of dimensions as the input tensor.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id14">
<h3>Outputs<a class="headerlink" href="#id14" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id15">
<h4>out[0]<a class="headerlink" href="#id15" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32, QNN_DATATYPE_UINT_32, backend specific</p></li>
<li><p>Shape: m-dimensional, where m = n if <em>keep_dims</em> is true and m = n - 1 otherwise.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="axisalignedbboxtransform">
<span id="id16"></span><h2>AxisAlignedBboxTransform<a class="headerlink" href="#axisalignedbboxtransform" title="Permalink to this heading">¶</a></h2>
<p>Transform axis-aligned bounding box proposals into refined bounding boxes using
bounding box regression deltas for each class.</p>
<p>Notes:</p>
<ul class="simple">
<li><p>Bounding boxes are aligned to the image coordinate system (i.e. not rotated).</p></li>
<li><p>Axis-aligned bounding boxes are defined by the upper-left corner (x1, y1) and
lower-right corner (x2, y2).</p></li>
<li><p>Valid bounding boxes are such that x1 &lt;= x2 and y1 &lt;= y2.</p></li>
<li><p>Resulting bounding boxes are clipped against the edges of the image.</p></li>
<li><p>The number of regions of interest (num_rois) is in the range [0, N] where N is
the maximum set by the underlying tensor.</p></li>
</ul>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0afd7603dd54060e6a52f5861674448528">ANEURALNETWORKS_AXIS_ALIGNED_BBOX_TRANSFORM</a></p></li>
<li><p>QNN: <a class="reference internal" href="#bboxtransform">BboxTransform</a></p></li>
</ul>
<div class="section" id="id17">
<h3>Inputs<a class="headerlink" href="#id17" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id18">
<h4>in[0]<a class="headerlink" href="#id18" title="Permalink to this heading">¶</a></h4>
<p>Bounding box proposal locations</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois, 4] each line with format [x1, y1, x2, y2]</p></li>
</ul>
</div>
<div class="section" id="in-1">
<h4>in[1]<a class="headerlink" href="#in-1" title="Permalink to this heading">¶</a></h4>
<p>Bounding box deltas for each region of interest and each class</p>
<p>Bounding box deltas are organized in the following order [dx, dy, dw, dh] where:</p>
<ul class="simple">
<li><p>dx and dy are the relative correction factors for the center position of
the bounding box</p></li>
<li><p>dw and dh are the log-scale relative correction factors for the width and
height the bounding box</p></li>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois, num_classes * 4]</p></li>
</ul>
</div>
<div class="section" id="in-2">
<h4>in[2]<a class="headerlink" href="#in-2" title="Permalink to this heading">¶</a></h4>
<p>Batch index of each bounding box. Boxes with the same batch index are grouped together.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [num_rois]</p></li>
</ul>
</div>
<div class="section" id="in-3">
<h4>in[3]<a class="headerlink" href="#in-3" title="Permalink to this heading">¶</a></h4>
<p>Specifies image size. Image size is the same for all images in the batch.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batches, 2] with format [image_height, image_width] per batch</p></li>
</ul>
</div>
</div>
<div class="section" id="id19">
<h3>Parameters<a class="headerlink" href="#id19" title="Permalink to this heading">¶</a></h3>
<div class="section" id="weights">
<h4>weights<a class="headerlink" href="#weights" title="Permalink to this heading">¶</a></h4>
<p>Weights applied to each of the bounding boxes deltas in in[1].</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: [4] with format [wx, wy, ww, wh]</p></li>
<li><p>Default: [1.0, 1.0, 1.0, 1.0]</p></li>
</ul>
</div>
</div>
<div class="section" id="id20">
<h3>Outputs<a class="headerlink" href="#id20" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id21">
<h4>out[0]<a class="headerlink" href="#id21" title="Permalink to this heading">¶</a></h4>
<p>Coordinates of refined bounding boxes</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois, num_classes * 4] with format [x1, y1, x2, y2]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="out-1">
<h4>out[1]<a class="headerlink" href="#out-1" title="Permalink to this heading">¶</a></h4>
<p>batch_splits : Specifies the number of RoIs/boxes belonging to the
corresponding image in batch. Note that the sum of values
should add up to a total of num_rois.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [batches]</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="batchnorm">
<span id="id22"></span><h2>Batchnorm<a class="headerlink" href="#batchnorm" title="Permalink to this heading">¶</a></h2>
<p>Normalizes the activations of the previous layer at each batch,
i.e. applies a transformation that maintains the mean activation close to 0
and the activation standard deviation close to 1.</p>
<p>See Batchnorm backend definition for supported datatypes and constraints per backend.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization">Batch Normalization</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BatchNormalization">BatchNormalization</a></p></li>
</ul>
<div class="section" id="id23">
<h3>Inputs<a class="headerlink" href="#id23" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id24">
<h4>in[0]<a class="headerlink" href="#id24" title="Permalink to this heading">¶</a></h4>
<p>Input tensor from the previous operator</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: n-dimensional, note that the last dimension in the input is the channel, […,channel].</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id25">
<h4>in[1]<a class="headerlink" href="#id25" title="Permalink to this heading">¶</a></h4>
<p>Weights</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [channel]</p></li>
</ul>
</div>
<div class="section" id="id26">
<h4>in[2]<a class="headerlink" href="#id26" title="Permalink to this heading">¶</a></h4>
<p>Biases</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [channel]</p></li>
<li><p>Default: [0, Ellipsis, 0]</p></li>
</ul>
</div>
</div>
<div class="section" id="id27">
<h3>Parameters<a class="headerlink" href="#id27" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id28">
<h3>Outputs<a class="headerlink" href="#id28" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id29">
<h4>out[0]<a class="headerlink" href="#id29" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: n-dimensional</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
<li><p>Must have same data format as in[0] (e.g. both sparse or both dense)</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="batchpermutation">
<span id="id30"></span><h2>BatchPermutation<a class="headerlink" href="#batchpermutation" title="Permalink to this heading">¶</a></h2>
<p>Generates a batch permutation of the input in[0]. The output out[0] may have the
same shape as in[0] with the exception of the batch dimension which is the shape of
in[1]. Data is re-ordered according to the indices provided.</p>
<p>Example of batch permutation on a 3-D tensor with batch size 4:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">input</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">]],</span>
<span class="p">[[</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">]],</span>
<span class="p">[[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">]],</span>
<span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">]]</span>
<span class="p">]</span>

<span class="n">indices</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">]</span>

<span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="p">[[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">]],</span>
<span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">]],</span>
<span class="p">[[</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">]],</span>
<span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">]]</span>
<span class="p">]</span>
</pre></div>
</div>
<div class="section" id="id31">
<h3>Inputs<a class="headerlink" href="#id31" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id32">
<h4>in[0]<a class="headerlink" href="#id32" title="Permalink to this heading">¶</a></h4>
<p>Input tensor</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: tensor of rank N where dim[0] equals <em>batch</em></p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id33">
<h4>in[1]<a class="headerlink" href="#id33" title="Permalink to this heading">¶</a></h4>
<p>indices : indices of batch to permute. Valid index values should be in range
[0, batch - 1], otherwise they are ignored.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32, QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: 1D of shape [M], where M &lt;= batch</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Valid index values must be unique.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id34">
<h3>Parameters<a class="headerlink" href="#id34" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id35">
<h3>Outputs<a class="headerlink" href="#id35" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id36">
<h4>out[0]<a class="headerlink" href="#id36" title="Permalink to this heading">¶</a></h4>
<p>Output permuted tensor. Note that out[0] is ordered according to the indices
provided that are in the range [0, batch - 1] and then padded with zeros.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: tensor of rank N where shape is the same as in[0] with the exception of dim[0] which equals <em>M</em>.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="batchtospace">
<span id="id37"></span><h2>BatchToSpace<a class="headerlink" href="#batchtospace" title="Permalink to this heading">¶</a></h2>
<p>A type of tensor realignment operation that rearranges data from the
batch dimension into blocks of spatial data, followed by cropping.</p>
<p>The op moves blocks of data of size (block_size[0] * block_size[1]) from the
batch dimension of the input tensor into the spatial dimensions of the
output tensor followed by cropping along the spatial dimensions.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/batch-to-space">ops::BatchToSpace</a></p></li>
</ul>
<div class="section" id="id38">
<h3>Inputs<a class="headerlink" href="#id38" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id39">
<h4>in[0]<a class="headerlink" href="#id39" title="Permalink to this heading">¶</a></h4>
<p>Input Activation.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D tensor of shape [batch, height, width, depth]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: batch must be divisible by (block_size[0] * block_size[1])</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id40">
<h3>Parameters<a class="headerlink" href="#id40" title="Permalink to this heading">¶</a></h3>
<div class="section" id="block-size">
<h4>block_size<a class="headerlink" href="#block-size" title="Permalink to this heading">¶</a></h4>
<p>Vector that represents block size along the <em>height</em> and <em>width</em>
dimensions respectively.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] with format [block_height, block_width]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Elements must be &gt;=1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="crops">
<h4>crops<a class="headerlink" href="#crops" title="Permalink to this heading">¶</a></h4>
<p>Crop region that specifies how many elements to crop from the
intermediate result across the spatial dimensions.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2,2] with format [[crop_top, crop_bottom], [crop_left, crop_right]]</p></li>
<li><p>Default: [[0, 0], [0, 0]]</p></li>
</ul>
</div>
</div>
<div class="section" id="id41">
<h3>Outputs<a class="headerlink" href="#id41" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id42">
<h4>out[0]<a class="headerlink" href="#id42" title="Permalink to this heading">¶</a></h4>
<p>Output Activation.</p>
<p>Permuted output tensor with new spatial dimensions
[<em>output_height</em>, <em>output_width</em>] defined by</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">height</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">crop_top</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">crop_bottom</span>
<span class="n">output_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">crop_left</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">crop_right</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D tensor of shape [batch / (block_size[0] * block_size[1]), output_height, output_width, depth]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="bboxtransform">
<span id="id43"></span><h2>BboxTransform<a class="headerlink" href="#bboxtransform" title="Permalink to this heading">¶</a></h2>
<p>Transform bounding box proposals into refined bounding boxes using bounding
box regression deltas for each class.</p>
<p>Notes:</p>
<ul class="simple">
<li><p>Bounding boxes can be rotated.</p></li>
<li><p>Resulting bounding boxes are clipped against the edges of the image.</p></li>
<li><p>The number of regions of interest (num_rois) is in the range [0, N] where
N is the maximum set by the underlying tensor.</p></li>
</ul>
<p>References:</p>
<ul class="simple">
<li><p>QNN: <a class="reference internal" href="#axisalignedbboxtransform">AxisAlignedBboxTransform</a></p></li>
</ul>
<div class="section" id="id44">
<h3>Inputs<a class="headerlink" href="#id44" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id45">
<h4>in[0]<a class="headerlink" href="#id45" title="Permalink to this heading">¶</a></h4>
<p>Bounding box proposal locations.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois, 5] each line with format [center_x, center_y, width, height, angle]</p></li>
</ul>
</div>
<div class="section" id="id46">
<h4>in[1]<a class="headerlink" href="#id46" title="Permalink to this heading">¶</a></h4>
<p>Bounding box deltas for each region of interest and each class.</p>
<p>Bounding box deltas are organized in the following format [dx, dy, dw, dh, da].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois, num_classes * 5]</p></li>
</ul>
</div>
<div class="section" id="id47">
<h4>in[2]<a class="headerlink" href="#id47" title="Permalink to this heading">¶</a></h4>
<p>Specifies image size. Image size is same for all images in a batch.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batches, 3] with format [image_height, image_width, image_scale]</p></li>
</ul>
</div>
<div class="section" id="id48">
<h4>in[3]<a class="headerlink" href="#id48" title="Permalink to this heading">¶</a></h4>
<p>Batch index of each bounding box.</p>
<p>Batches with the same index are grouped together.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [num_rois]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
</div>
<div class="section" id="id49">
<h3>Parameters<a class="headerlink" href="#id49" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id50">
<h4>weights<a class="headerlink" href="#id50" title="Permalink to this heading">¶</a></h4>
<p>Weights applied to each of the bounding boxes deltas in in[1] in
the form of (wx, wy, ww, wh).</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: [4]</p></li>
</ul>
</div>
<div class="section" id="apply-scale">
<h4>apply_scale<a class="headerlink" href="#apply-scale" title="Permalink to this heading">¶</a></h4>
<p>Set QNN_OP_BBOX_TRANSFORM_APPLY_SCALE to true to transform the boxes to the
scaled image space after applying the bounding box deltas, or
QNN_OP_BBOX_TRANSFORM_APPLY_SCALE to false not apply scale.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="angle-bounds">
<h4>angle_bounds<a class="headerlink" href="#angle-bounds" title="Permalink to this heading">¶</a></h4>
<p>Limits the bounding box angle to be within the range
[angle_bound_low, angle_bound_high].</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [2] with format [angle_bound_low, angle_bound_high]</p></li>
<li><p>Default: parameter not used unless set</p></li>
</ul>
</div>
<div class="section" id="angle-clip-threshold">
<h4>angle_clip_threshold<a class="headerlink" href="#angle-clip-threshold" title="Permalink to this heading">¶</a></h4>
<p>Implements:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">angle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">angle</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="n">angle_clip_threshold</span><span class="p">,</span><span class="w"> </span><span class="mf">0.0</span><span class="p">))</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="p">(</span><span class="n">angle</span><span class="p">)</span>
</pre></div>
</div>
<p>Set to negative to disable.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: -1.0</p></li>
</ul>
</div>
</div>
<div class="section" id="id51">
<h3>Outputs<a class="headerlink" href="#id51" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id52">
<h4>out[0]<a class="headerlink" href="#id52" title="Permalink to this heading">¶</a></h4>
<p>Coordinates of refined bounding boxes.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois, num_classes * 5]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: same as in[1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id53">
<h4>out[1]<a class="headerlink" href="#id53" title="Permalink to this heading">¶</a></h4>
<p>Number of RoIs per batch.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batches]</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="boxwithnmslimit">
<span id="id54"></span><h2>BoxWithNmsLimit<a class="headerlink" href="#boxwithnmslimit" title="Permalink to this heading">¶</a></h2>
<p>Greedily selects a subset of bounding boxes in descending order of score.</p>
<p>This op applies NMS algorithm to each class. In each loop of execution,
the box with maximum score is selected and removed from the pending set. The scores
of the rest of boxes are lowered according to the intersection-over-union (IOU)
overlapping with the previously selected boxes and a specified NMS kernel method.
Any boxes with score less than a threshold are removed from the pending set.</p>
<p>Three NMS kernels are supported:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="nl">Hard</span><span class="p">:</span><span class="w"> </span><span class="n">score_new</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">score_old</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">IoU</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">threshold</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
<span class="nl">Linear</span><span class="p">:</span><span class="w"> </span><span class="n">score_new</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">score_old</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">IoU</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">threshold</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">IoU</span><span class="p">)</span>
<span class="nl">Gaussian</span><span class="p">:</span><span class="w"> </span><span class="n">score_new</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">score_old</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="w"> </span><span class="n">IoU</span><span class="o">^</span><span class="mi">2</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sigma</span><span class="p">)</span>
</pre></div>
</div>
<p>Axis-aligned bounding boxes are represented by its upper-left corner coordinate
(x1,y1) and lower-right corner coordinate (x2,y2). A valid bounding box should
satisfy x1 &lt;= x2 and y1 &lt;= y2.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a2d81e878c19e15700dad111ba6c0be89">ANEURALNETWORKS_BOX_WITH_NMS_LIMIT</a></p></li>
</ul>
<div class="section" id="id55">
<h3>Inputs<a class="headerlink" href="#id55" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id56">
<h4>in[0]<a class="headerlink" href="#id56" title="Permalink to this heading">¶</a></h4>
<p>Bounding box proposals. Elements can be understood as 4-tuples of bounding
box coordinates given in the form (x1,y1,x2,y2). Boxes pertaining to a given
batch element are grouped consecutively.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois, num_classes*4]</p></li>
</ul>
</div>
<div class="section" id="id57">
<h4>in[1]<a class="headerlink" href="#id57" title="Permalink to this heading">¶</a></h4>
<p>Bounding box scores. The element at position [<em>roi</em>, <em>class</em>] can be understood
as the score for the bounding box at the same position in in[0].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois, num_classes]</p></li>
</ul>
</div>
<div class="section" id="id58">
<h4>in[2]<a class="headerlink" href="#id58" title="Permalink to this heading">¶</a></h4>
<p>Bounding box batch indices. Specifies the batch index of each box.
Boxes pertaining to a given batch element are grouped consecutively.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [num_rois]</p></li>
</ul>
</div>
<div class="section" id="id59">
<h4>in[3]<a class="headerlink" href="#id59" title="Permalink to this heading">¶</a></h4>
<p>batch splits : Specifies the number of RoIs/boxes belonging to the corresponding
image in batch. Note that the sum of values should add up to a total of num_rois.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [batch]</p></li>
</ul>
</div>
</div>
<div class="section" id="id60">
<h3>Parameters<a class="headerlink" href="#id60" title="Permalink to this heading">¶</a></h3>
<div class="section" id="nms-kernel-method">
<h4>nms_kernel_method<a class="headerlink" href="#nms-kernel-method" title="Permalink to this heading">¶</a></h4>
<p>Determines the NMS kernel method, options are 0:hard, 1:linear, 2:gaussian.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>hard = 0,</p></li>
<li><p>linear = 1,</p></li>
<li><p>gaussian = 2</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="nms-score-threshold">
<h4>nms_score_threshold<a class="headerlink" href="#nms-score-threshold" title="Permalink to this heading">¶</a></h4>
<p>Boxes with scores lower than the threshold are dropped during the
score updating phase in soft NMS.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="score-threshold">
<h4>score_threshold<a class="headerlink" href="#score-threshold" title="Permalink to this heading">¶</a></h4>
<p>Boxes with scores lower than the threshold are filtered before sending to the
NMS algorithm.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.0</p></li>
</ul>
</div>
<div class="section" id="pre-nms-limit">
<h4>pre_nms_limit<a class="headerlink" href="#pre-nms-limit" title="Permalink to this heading">¶</a></h4>
<p>Specifies a maximum number of boxes for each image which will be sent to NMS.
Set to a negative value for unlimited number of output bounding boxes.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: -1</p></li>
</ul>
</div>
<div class="section" id="iou-threshold">
<h4>iou_threshold<a class="headerlink" href="#iou-threshold" title="Permalink to this heading">¶</a></h4>
<p>Specifies the IoU threshold in hard and linear NMS kernel. This parameter is
ignored if gaussian kernel is selected.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="sigma">
<h4>sigma<a class="headerlink" href="#sigma" title="Permalink to this heading">¶</a></h4>
<p>Specifies the sigma value in gaussian NMS kernel. This parameter is ignored if
the gaussian kernel is not selected.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
</div>
<div class="section" id="id61">
<h3>Outputs<a class="headerlink" href="#id61" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id62">
<h4>out[0]<a class="headerlink" href="#id62" title="Permalink to this heading">¶</a></h4>
<p>Output boxes. Each element can be understood as a 4-tuple with the same
meaning as in[0]. Boxes are grouped by batch, but order within each batch is
not guaranteed.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_output_rois, 4]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id63">
<h4>out[1]<a class="headerlink" href="#id63" title="Permalink to this heading">¶</a></h4>
<p>Output box scores. Gives the score for the box in the corresponding position in out[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_output_rois]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="out-2">
<h4>out[2]<a class="headerlink" href="#out-2" title="Permalink to this heading">¶</a></h4>
<p>Output box classes. Gives the class index (with respect to <em>num_classes</em> in in[0])
with the maximum score for the box in the corresponding position in out[0].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [num_output_rois]</p></li>
</ul>
</div>
<div class="section" id="out-3">
<h4>out[3]<a class="headerlink" href="#out-3" title="Permalink to this heading">¶</a></h4>
<p>Output box batch indices : Gives the batch index for the box in the
corresponding position in out[0].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [num_output_rois]</p></li>
</ul>
</div>
<div class="section" id="out-4">
<h4>out[4]<a class="headerlink" href="#out-4" title="Permalink to this heading">¶</a></h4>
<p>Output batch splits : Specifies the number of RoIs/boxes belonging to the
corresponding image in batch after applying NMS. Note that the sum of values
should add up to a total of num_output_rois.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [batch]</p></li>
</ul>
</div>
<div class="section" id="out-5">
<h4>out[5]<a class="headerlink" href="#out-5" title="Permalink to this heading">¶</a></h4>
<p>keeps : contains the indices of the selected boxes after performing NMS. The
values of the indices are in the order of the boxes in out[0] and correspond to
index position of the selected boxes in in[0].</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [num_output_rois]</p></li>
</ul>
</div>
<div class="section" id="out-6">
<h4>out[6]<a class="headerlink" href="#out-6" title="Permalink to this heading">¶</a></h4>
<p>keeps size : contains the number of selected boxes per class after NMS has been
applied.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [num_classes]</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="buffer">
<span id="id64"></span><h2>Buffer<a class="headerlink" href="#buffer" title="Permalink to this heading">¶</a></h2>
<p>Accumulates inputs across inferences into a buffer of size <em>buffer_size</em> and outputs
the buffer with the collected inputs. When the buffer is full the oldest existing
inputs in the buffer are removed to make space for the incoming new input. The
number of inputs to remove is determined by <em>stride</em>. The remaining inputs are
shifted in the buffer to maintain the order they were received.</p>
<div class="section" id="id65">
<h3>Inputs<a class="headerlink" href="#id65" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id66">
<h4>in[0]<a class="headerlink" href="#id66" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id67">
<h4>in[1]<a class="headerlink" href="#id67" title="Permalink to this heading">¶</a></h4>
<p>reset : Determines if the buffer should be reset. When set to true all inputs
in the buffer are removed.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: 0D containing scalar value</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id68">
<h3>Parameters<a class="headerlink" href="#id68" title="Permalink to this heading">¶</a></h3>
<div class="section" id="buffer-size">
<h4>buffer_size<a class="headerlink" href="#buffer-size" title="Permalink to this heading">¶</a></h4>
<p>Determines the number of inputs that a buffer can store.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="buffer-dim">
<h4>buffer_dim<a class="headerlink" href="#buffer-dim" title="Permalink to this heading">¶</a></h4>
<p>Determines the dimension that inputs are accumulated on.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [0, N-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="stride">
<h4>stride<a class="headerlink" href="#stride" title="Permalink to this heading">¶</a></h4>
<p>Determines the number of inputs to remove from the buffer when the buffer is
full to make space for the new incoming input. The oldest existing inputs which
reside at the beginning of the buffer are removed. After removal the remaining
inputs are kept in the order they were received.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [1, buffer_size]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="mode">
<h4>mode<a class="headerlink" href="#mode" title="Permalink to this heading">¶</a></h4>
<p>Determines blocking behavior. How the buffer is populated differs between the
modes when the buffer is not full. When the buffer is full eviction and
population behavior is the same for all modes. BLOCKING :0, NON_BLOCKING_LEFT: 1,
NON_BLOCKING_RIGHT: 2.</p>
<p>When mode is set to BLOCKING: Execution is stopped on the existing branch of the
graph if the buffer is not full. The buffer is populated from the beginning to the
end. For example, an empty buffer with 3 slots (0,1,2) will be populated from
slot 0 to slot 2.</p>
<p>When mode is set to NON_BLOCKING_LEFT: The existing branch of the graph will
always execute regardless if the buffer is full or not. The buffer is populated
from the beginning to the end. For example, an empty buffer with 3 slots (0,1,2)
will be populated from slot 0 to slot 2.</p>
<p>When mode is set to NON_BLOCKING_RIGHT: The existing branch of the graph will
always execute regardless if the buffer is full or not. The buffer is populated
from the end. For example, an empty buffer with 3 slots (0,1,2) the first
incoming input is placed at slot 2. For the next incoming input the previous
input at slot 2 is now at slot 1 and the new input is placed at slot 2.</p>
<p>When the buffer is full the number of inputs removed is determined by <em>stride</em>.
Eviction behavior is the same for all modes where the oldest existing inputs are
removed from the beginning of the buffer. Population behavior is also the same
for all modes when the buffer is full. For example, a fully populated buffer
with 3 slots (0,1,2) and a stride value of 2 will have the inputs at slot 0 and
slot 1 removed and the input at slot 2 will now be at slot 0. The incoming input
is then placed at slot 1. The next incoming input will then be placed at slot 2.
When the buffer is full again the same process is repeated.</p>
<p>Note that NON_BLOCKING_LEFT and NON_BLOCKING_RIGHT will be zero filled for the
output if the buffer is not completely full.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>BLOCKING = 0,</p></li>
<li><p>NON_BLOCKING_LEFT = 1,</p></li>
<li><p>NON_BLOCKING_RIGHT = 2</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id69">
<h3>Outputs<a class="headerlink" href="#id69" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id70">
<h4>out[0]<a class="headerlink" href="#id70" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Same shape as in[0] except where dim[buffer_dim] is equal to buffer_size.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same Datatype as in[0]</p></li>
<li><p>Datatype: Same Rank as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="cast">
<span id="id71"></span><h2>Cast<a class="headerlink" href="#cast" title="Permalink to this heading">¶</a></h2>
<p>Casts tensor data type to a new data type.
This operation ignores quantization parameters specified with Qnn_QuantizeParams_t for tensors of fixed point data types,
e.g. it treats a QNN_DATATYPE_UFIXED_POINT_8 tensor data type as a tensor of QNN_DATATYPE_UINT_8 data type.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a0a1bde5b34668d90eec4cfa4944e241d">ANEURALNETWORKS_CAST</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Cast">ops::Cast</a></p></li>
</ul>
<div class="section" id="id72">
<h3>Inputs<a class="headerlink" href="#id72" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id73">
<h4>in[0]<a class="headerlink" href="#id73" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id74">
<h3>Parameters<a class="headerlink" href="#id74" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id75">
<h3>Outputs<a class="headerlink" href="#id75" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id76">
<h4>out[0]<a class="headerlink" href="#id76" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="channelshuffle">
<span id="id77"></span><h2>ChannelShuffle<a class="headerlink" href="#channelshuffle" title="Permalink to this heading">¶</a></h2>
<p>This operation shuffles the channels of the input tensor, by dividing the <em>channel</em> dimension into <em>num_groups</em> groups,
and reorganizing the channels by grouping channels with the same index in each group.</p>
<p>Along the <em>channel</em> dimension, the output is calculated using this formula:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output_channel</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">num_groups</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">g</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_channel</span><span class="p">[</span><span class="n">g</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">group_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>
<p>where</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">num_channels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">channel</span><span class="p">]</span>
<span class="n">group_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_channels</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">num_groups</span>
<span class="n">g</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">group</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">num_groups</span><span class="mi">-1</span><span class="p">]</span>
<span class="n">i</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="n">within</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">group</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">group_size</span><span class="mi">-1</span><span class="p">]</span>
</pre></div>
</div>
<p>The <em>num_channels</em> must be evenly divisible by <em>num_groups</em>. <em>num_groups</em> = <em>num_channels</em> results in no-op.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a5b993c1211c4b1bc52fb595a3025251d">ANEURALNETWORKS_CHANNEL_SHUFFLE</a></p></li>
</ul>
<div class="section" id="id78">
<h3>Inputs<a class="headerlink" href="#id78" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id79">
<h4>in[0]<a class="headerlink" href="#id79" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id80">
<h3>Parameters<a class="headerlink" href="#id80" title="Permalink to this heading">¶</a></h3>
<div class="section" id="num-groups">
<h4>num_groups<a class="headerlink" href="#num-groups" title="Permalink to this heading">¶</a></h4>
<p>Number of groups to divide <em>channel</em> dimension into, &lt;= <em>num_channels</em>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="id81">
<h4>axis<a class="headerlink" href="#id81" title="Permalink to this heading">¶</a></h4>
<p>Axis on which channel shuffle will be performed</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: N-1</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [0,N-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id82">
<h3>Outputs<a class="headerlink" href="#id82" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id83">
<h4>out[0]<a class="headerlink" href="#id83" title="Permalink to this heading">¶</a></h4>
<p>output tensor with shuffled channels</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same rank as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="collectrpnproposals">
<span id="id84"></span><h2>CollectRpnProposals<a class="headerlink" href="#collectrpnproposals" title="Permalink to this heading">¶</a></h2>
<p>Collect RoIs and their scores, merge predictions across multiple FPN levels, and
retain the top scoring RoIs. Note that RoI elements can be understood as 5-tuples
with format (batch_idx, x1, y1, x2, y2) where batch_idx specifies the batch index of
each RoI, (x1,y1) represents the upper-left corner coordinate, and (x2,y2)
represents the lower-right corner coordinate.</p>
<div class="section" id="id85">
<h3>Inputs<a class="headerlink" href="#id85" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id86">
<h4>in[0]<a class="headerlink" href="#id86" title="Permalink to this heading">¶</a></h4>
<p>RoIs : RPN proposals for FPN level <em>rpm_min_level</em>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois, 5] each line with format [batch_idx, x1, y1, x2, y2]</p></li>
</ul>
</div>
<div class="section" id="in-1-4">
<h4>in[1..4]<a class="headerlink" href="#in-1-4" title="Permalink to this heading">¶</a></h4>
<p>RoIs : RPN proposals for FPN levels [<em>rpn_min_level</em> + 1, <em>rpn_max_level</em>].
Note that each input can have a different shape since <em>num_roi_i</em> can vary for
in[1..4].</p>
<p>This tensor is repeated, meaning the same definition can apply to multiple
tensors.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois_i, 5] each line with format [batch_idx, x1, y1, x2, y2]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Number: Number of in[1..4] provided must equal rpn_max_level - rpn_min_level</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="in-5">
<h4>in[5]<a class="headerlink" href="#in-5" title="Permalink to this heading">¶</a></h4>
<p>RoI probabilities : RPN scores for FPN level <em>rpn_min_level</em>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois]</p></li>
</ul>
</div>
<div class="section" id="in-6-9">
<h4>in[6..9]<a class="headerlink" href="#in-6-9" title="Permalink to this heading">¶</a></h4>
<p>RoI probabilities : RPN scores for FPN levels [<em>rpn_min_level</em> + 1,
<em>rpn_max_level</em>]. Note that each input can have a different shape since
<em>num_roi_i</em> can vary for in[6..9] but must be the same as the corresponding
<em>RoIs</em> in[1..4] provided for the same FPN level.</p>
<p>This tensor is repeated, meaning the same definition can apply to multiple
tensors.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois_i]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[5]</p></li>
<li><p>Shape: shape(in[i])[0] must equal shape(in[i+5])[0] for i=1..4</p></li>
<li><p>Number: Number of in[6..9] provided must equal rpn_max_level - rpn_min_level</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id87">
<h3>Parameters<a class="headerlink" href="#id87" title="Permalink to this heading">¶</a></h3>
<div class="section" id="rpn-min-level">
<h4>rpn_min_level<a class="headerlink" href="#rpn-min-level" title="Permalink to this heading">¶</a></h4>
<p>Sets the minimum FPN level to support RPN transform operations on multiple FPN
levels</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 2</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [2,6]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="rpn-max-level">
<h4>rpn_max_level<a class="headerlink" href="#rpn-max-level" title="Permalink to this heading">¶</a></h4>
<p>Sets the maximum FPN level to support RPN transform operations on multiple FPN
levels.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 6</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [2,6]</p></li>
<li><p>Value: Must be &gt;= rpn_min_level</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="post-nms-top">
<h4>post_nms_top<a class="headerlink" href="#post-nms-top" title="Permalink to this heading">¶</a></h4>
<p>Sets a maximum number of proposals. The proposals with the lowest scores will be
dropped to achieve this limit.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 2000</p></li>
</ul>
</div>
</div>
<div class="section" id="id88">
<h3>Outputs<a class="headerlink" href="#id88" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id89">
<h4>out[0]<a class="headerlink" href="#id89" title="Permalink to this heading">¶</a></h4>
<p>RoIs : Top proposals limited to <em>post_nms_top</em> total.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_proposals, 5] each line with format [batch_idx, x1, y1, x2, y2], where total_num_rois is the sum of all <em>num_rois</em> from in[0..4] and num_proposals = min(<em>total_num_rois</em>, <em>post_nms_top</em>).</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="concat">
<span id="id90"></span><h2>Concat<a class="headerlink" href="#concat" title="Permalink to this heading">¶</a></h2>
<p>Concatenates two or more input tensors along a provided axis</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a44cbea825c4b224dd3ea757e9b1f65ed">ANEURALNETWORKS_CONCATENATION</a></p></li>
</ul>
<div class="section" id="id91">
<h3>Inputs<a class="headerlink" href="#id91" title="Permalink to this heading">¶</a></h3>
<div class="section" id="in-0-m">
<h4>in[0..m]<a class="headerlink" href="#in-0-m" title="Permalink to this heading">¶</a></h4>
<p>input tensors. m &gt;=1</p>
<p>This tensor is repeated, meaning the same definition can apply to multiple tensors.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: N-dimensional. Must be the same for all inputs, except at position <em>axis</em>, which is permitted to vary across inputs.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Number: m &gt;= 1</p></li>
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id92">
<h3>Parameters<a class="headerlink" href="#id92" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id93">
<h4>axis<a class="headerlink" href="#id93" title="Permalink to this heading">¶</a></h4>
<p>Axis on which to concatenate input tensors</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: N-1</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [0,N-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id94">
<h3>Outputs<a class="headerlink" href="#id94" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id95">
<h4>out[0]<a class="headerlink" href="#id95" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Same rank as in[0], except at <em>axis</em>, where the value is sum(i, shape(in[i])[axis]).</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same rank as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="constantofshape">
<span id="id96"></span><h2>ConstantOfShape<a class="headerlink" href="#constantofshape" title="Permalink to this heading">¶</a></h2>
<p>Generates an output tensor with the given shape and value.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#ConstantOfShape">ops::ConstantOfShape</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.full.html">Full</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/fill">Fill</a></p></li>
</ul>
<div class="section" id="id97">
<h3>Inputs<a class="headerlink" href="#id97" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id98">
<h4>in[0]<a class="headerlink" href="#id98" title="Permalink to this heading">¶</a></h4>
<p>Input tensor : a 1D tensor specifying the shape of the expected output tensor.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: 1D of shape [N]</p></li>
</ul>
</div>
</div>
<div class="section" id="id99">
<h3>Parameters<a class="headerlink" href="#id99" title="Permalink to this heading">¶</a></h3>
<div class="section" id="value">
<h4>value<a class="headerlink" href="#value" title="Permalink to this heading">¶</a></h4>
<p>The value to fill the output tensor with.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
</div>
<div class="section" id="id100">
<h3>Outputs<a class="headerlink" href="#id100" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id101">
<h4>out[0]<a class="headerlink" href="#id101" title="Permalink to this heading">¶</a></h4>
<p>Output tensor with shape specified by in[0] and value specified by <em>value</em>.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as <em>value</em>.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="conv1d">
<span id="id102"></span><h2>Conv1d<a class="headerlink" href="#conv1d" title="Permalink to this heading">¶</a></h2>
<p>Performs 1D convolution: dot-product of a set of 1D filters with input activation,
producing output activation.</p>
<p>Application of the filters moves according to the specified stride. For backends
supporting quantized data types, clients can pass filters which are either quantized
per-tensor or per-axis with possible constraints on the axis value that is supported.
For regular convolution, <em>group</em> is 1. Group field greater than 1 implies a grouped
convolution where a group of different filters is applied to each input channel
group and the result is concatenated together.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/conv1d">Conv1D</a></p></li>
<li><p>Onnx: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Conv">Conv</a></p></li>
</ul>
<div class="section" id="id104">
<h3>Inputs<a class="headerlink" href="#id104" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id105">
<h4>in[0]<a class="headerlink" href="#id105" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, width, channel_in]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: channel_in must be evenly divisible by group</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id106">
<h4>in[1]<a class="headerlink" href="#id106" title="Permalink to this heading">¶</a></h4>
<p>filters</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [filter_width, channel_in / group, channel_out]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: channel_out must be evenly divisible by group</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id107">
<h4>in[2]<a class="headerlink" href="#id107" title="Permalink to this heading">¶</a></h4>
<p>biases</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [channel_out]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
</div>
<div class="section" id="id108">
<h3>Parameters<a class="headerlink" href="#id108" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id109">
<h4>stride<a class="headerlink" href="#id109" title="Permalink to this heading">¶</a></h4>
<p>Defines stride for 1D spatial axes of in[0]</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="pad-amount">
<h4>pad_amount<a class="headerlink" href="#pad-amount" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 1D spatial axes of in[0].
Pad value = 0.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] : [width_pad_before, width_pad_after]</p></li>
</ul>
</div>
<div class="section" id="group">
<h4>group<a class="headerlink" href="#group" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="dilation">
<h4>dilation<a class="headerlink" href="#dilation" title="Permalink to this heading">¶</a></h4>
<p>Dilation parameter for width dimension.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id110">
<h3>Outputs<a class="headerlink" href="#id110" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id111">
<h4>out[0]<a class="headerlink" href="#id111" title="Permalink to this heading">¶</a></h4>
<p>The output 1D spatial dimension is a function of the filter size, stride, and
pad_amount.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">dilated_filter_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dilation</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="n">width_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">dilated_filter_width</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, width_out, channel_out]</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="conv2d">
<span id="id112"></span><h2>Conv2d<a class="headerlink" href="#conv2d" title="Permalink to this heading">¶</a></h2>
<p>Performs 2D convolution: dot-product of a set of 2D filters with input activation,
producing output activation.</p>
<p>Application of the filter moves according to the specified strides. For backends
supporting quantized data types, clients can pass filters which are either quantized
per-tensor or per-axis with possible constraints on the axis value that is supported.
For regular convolution, <em>group</em> is 1. Group field greater than 1 implies a grouped
convolution where a group of different filters is applied to each input channel
group and the result is concatenated together.</p>
<p>Note that <em>channel_out</em> and <em>channel_in</em> must be evenly divisible by <em>group</em>.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a34a73b5eaf458b67db5eda71557d1d01">ANEURALNETWORKS_CONV_2D</a></p></li>
</ul>
<div class="section" id="id113">
<h3>Inputs<a class="headerlink" href="#id113" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id114">
<h4>in[0]<a class="headerlink" href="#id114" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height, width, channel_in]</p></li>
</ul>
</div>
<div class="section" id="id115">
<h4>in[1]<a class="headerlink" href="#id115" title="Permalink to this heading">¶</a></h4>
<p>filters</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [filter_height, filter_width, channel_in / group, channel_out]</p></li>
</ul>
</div>
<div class="section" id="id116">
<h4>in[2]<a class="headerlink" href="#id116" title="Permalink to this heading">¶</a></h4>
<p>biases</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [channel_out]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
</div>
<div class="section" id="id117">
<h3>Parameters<a class="headerlink" href="#id117" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id118">
<h4>stride<a class="headerlink" href="#id118" title="Permalink to this heading">¶</a></h4>
<p>Defines stride for 2D spatial axes of in[0]</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [height_stride, width_stride]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Strides must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id119">
<h4>pad_amount<a class="headerlink" href="#id119" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 2D spatial axes of in[0].
Pad value = 0.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2,2] with format [[height_pad_before, height_pad_after], [width_pad_before, width_pad_after]]</p></li>
</ul>
</div>
<div class="section" id="id120">
<h4>group<a class="headerlink" href="#id120" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="id121">
<h4>dilation<a class="headerlink" href="#id121" title="Permalink to this heading">¶</a></h4>
<p>Dilation parameter for height and width dimensions.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [height_dilation, width_dilation]</p></li>
<li><p>Default: [1, 1]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Dilations must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id122">
<h3>Outputs<a class="headerlink" href="#id122" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id123">
<h4>out[0]<a class="headerlink" href="#id123" title="Permalink to this heading">¶</a></h4>
<p>The output 2D spatial dimensions are functions of the filter size, stride, and pad_amount.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">dilated_filter_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dilation</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="n">dilated_filter_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dilation</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="n">height_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">dilated_filter_height</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">width_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">dilated_filter_width</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height_out, width_out, channel_out]</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="conv3d">
<span id="id124"></span><h2>Conv3d<a class="headerlink" href="#conv3d" title="Permalink to this heading">¶</a></h2>
<p>Performs 3D convolution: a spatial convolution over volumes using a set of 3D
filters with input activation, producing output activation.</p>
<p>Application of the filter moves according to the specified strides. For backends
supporting quantized data types, clients can pass filters which are either quantized
per-tensor or per-axis with possible constraints on the axis value that is supported.
For regular convolution, <em>group</em> is 1. Group field greater than 1 implies a grouped
convolution where a group of different filters is applied to each input channel
group and the result is concatenated together.</p>
<p>Note that <em>channel_out</em> and <em>channel_in</em> must be evenly divisible by <em>group</em>.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/conv3d">Conv3D</a></p></li>
<li><p>Onnx: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Conv">Conv</a></p></li>
</ul>
<div class="section" id="id127">
<h3>Inputs<a class="headerlink" href="#id127" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id128">
<h4>in[0]<a class="headerlink" href="#id128" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, depth, height, width, channel_in]</p></li>
</ul>
</div>
<div class="section" id="id129">
<h4>in[1]<a class="headerlink" href="#id129" title="Permalink to this heading">¶</a></h4>
<p>filters</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [filter_depth, filter_height, filter_width, channel_in / group, channel_out]</p></li>
</ul>
</div>
<div class="section" id="id130">
<h4>in[2]<a class="headerlink" href="#id130" title="Permalink to this heading">¶</a></h4>
<p>biases</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [channel_out]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
</div>
<div class="section" id="id131">
<h3>Parameters<a class="headerlink" href="#id131" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id132">
<h4>stride<a class="headerlink" href="#id132" title="Permalink to this heading">¶</a></h4>
<p>Defines stride for 3D spatial axes of in[0]</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3] : [depth_stride, height_stride, width_stride]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Strides must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id133">
<h4>pad_amount<a class="headerlink" href="#id133" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 3D spatial axes of in[0].
Pad value = 0.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3,2] with format [[depth_pad_before, depth_pad_after], [height_pad_before, height_pad_after], [width_pad_before, width_pad_after]]</p></li>
</ul>
</div>
<div class="section" id="id134">
<h4>group<a class="headerlink" href="#id134" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="id135">
<h4>dilation<a class="headerlink" href="#id135" title="Permalink to this heading">¶</a></h4>
<p>Dilation parameter for depth, height and width dimensions.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3] : [depth_dilation, height_dilation, width_dilation]</p></li>
<li><p>Default: [1, 1, 1]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Dilations must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="reuse-sparse-indicies">
<h4>reuse_sparse_indicies<a class="headerlink" href="#reuse-sparse-indicies" title="Permalink to this heading">¶</a></h4>
<p>Only for sparse input and output tensors. If true, the resulting convolution re-uses the input
indices for the output indices. Convolutions are only computed for the specified elements.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id136">
<h3>Outputs<a class="headerlink" href="#id136" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id137">
<h4>out[0]<a class="headerlink" href="#id137" title="Permalink to this heading">¶</a></h4>
<p>The output 3D spatial dimensions depth, height, and width are functions of the
<em>filters</em> size, <em>stride</em>, and <em>pad_amount</em>.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">dilated_filter_depth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">depth</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dilation</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="n">dilated_filter_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dilation</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="n">dilated_filter_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dilation</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="n">depth_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">depth</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">dilated_filter_depth</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">height_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">dilated_filter_height</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">width_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">dilated_filter_width</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, depth_out, height_out, width_out, channel_out]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Must have same data format as in[0] (e.g. both sparse or both dense)</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="convert">
<span id="id138"></span><h2>Convert<a class="headerlink" href="#convert" title="Permalink to this heading">¶</a></h2>
<p>This operation converts input activation tensor to output activation tensor
as per corresponding tensor data type. Unlike in <a class="reference internal" href="#cast">Cast</a> operation,
quantization parameters as specified with Qnn_QuantizeParams_t are obeyed
for fixed point data type conversions. The operation also provides optional
support for data type changes at runtime.</p>
<p>References:</p>
<ul class="simple">
<li><p>QNN: <a class="reference internal" href="#cast">Cast</a></p></li>
</ul>
<div class="section" id="id139">
<h3>Inputs<a class="headerlink" href="#id139" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id140">
<h4>in[0]<a class="headerlink" href="#id140" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id141">
<h3>Parameters<a class="headerlink" href="#id141" title="Permalink to this heading">¶</a></h3>
<div class="section" id="dynamic-input-data">
<h4>dynamic_input_data<a class="headerlink" href="#dynamic-input-data" title="Permalink to this heading">¶</a></h4>
<p>Set QNN_OP_CONVERT_PARAM_DYNAMIC_INPUT_DATA to <em>true</em> to indicate that in[0] data type
and associated buffer can change in between op execute invocations. It means that client
is allowed to change data type and associated buffer of adequate size before
QnnGraph_execute() call, subject to constraints and backend support.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: <em>true</em> is valid/allowed only for tensors of type QNN_TENSOR_TYPE_APP_WRITE or QNN_TENSOR_TYPE_APP_READWRITE.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="dynamic-output-data">
<h4>dynamic_output_data<a class="headerlink" href="#dynamic-output-data" title="Permalink to this heading">¶</a></h4>
<p>Set QNN_OP_CONVERT_PARAM_DYNAMIC_OUTPUT_DATA to <em>true</em> to indicate that out[0] data type
and associated buffer can change in between op execute invocations. It means that client
is allowed to change data type and associated buffer of adequate size before
QnnGraph_execute() call, subject to constraints and backend support.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: <em>true</em> is valid/allowed only for tensors of type QNN_TENSOR_TYPE_APP_READ or QNN_TENSOR_TYPE_APP_READWRITE.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id142">
<h3>Outputs<a class="headerlink" href="#id142" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id143">
<h4>out[0]<a class="headerlink" href="#id143" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="correlation1d">
<span id="id144"></span><h2>Correlation1D<a class="headerlink" href="#correlation1d" title="Permalink to this heading">¶</a></h2>
<p>Performs a depth-wise one-dimensional correlation along the width axis as shown:</p>
<div class="math notranslate nohighlight">
\[n \in [0,\mbox{batch})\]</div>
<div class="math notranslate nohighlight">
\[h \in [0,\mbox{height})\]</div>
<div class="math notranslate nohighlight">
\[w \in [0,\mbox{width})\]</div>
<div class="math notranslate nohighlight">
\[d \in [0,\mbox{depth})\]</div>
<div class="math notranslate nohighlight">
\[w' = w + d - (\mbox{displacement} - \mbox{shift})\]</div>
<div class="math notranslate nohighlight">
\[\mbox{When } w' &lt; 0 \mbox{ or } w' \ge \mbox{ width}: \mbox{out[0]}[n,h,w,d] = 0\]</div>
<div class="math notranslate nohighlight">
\[\mbox{Otherwise}: \mbox{out[0]}[n,h,w,d] = \frac{\sum^{\mbox{depth}-1}_{d'=0}\mbox{in[0]}[n,h,w,d']\cdot\mbox{in[1]}[n,h,w',d']}{\mbox{depth}}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>FlowNet 2.0: <a class="reference external" href="https://github.com/lmb-freiburg/flownet2/blob/master/src/caffe/layers/correlation_layer1d.cpp">Correlation 1D</a></p></li>
</ul>
<div class="section" id="id145">
<h3>Inputs<a class="headerlink" href="#id145" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id146">
<h4>in[0]<a class="headerlink" href="#id146" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height, width, depth]</p></li>
</ul>
</div>
<div class="section" id="id147">
<h4>in[1]<a class="headerlink" href="#id147" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height, width, depth]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id148">
<h3>Parameters<a class="headerlink" href="#id148" title="Permalink to this heading">¶</a></h3>
<div class="section" id="displacement">
<h4>displacement<a class="headerlink" href="#displacement" title="Permalink to this heading">¶</a></h4>
<p>Maximum searching pixels in the horizontal direction</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="shift">
<h4>shift<a class="headerlink" href="#shift" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
</div>
<div class="section" id="id149">
<h3>Outputs<a class="headerlink" href="#id149" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id150">
<h4>out[0]<a class="headerlink" href="#id150" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height, width, displacement*2 + 1]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="createsparse">
<span id="id151"></span><h2>CreateSparse<a class="headerlink" href="#createsparse" title="Permalink to this heading">¶</a></h2>
<p>Creates a sparse tensor from indices and values tensors.</p>
<p>Unspecified elements are considered to have a zero value. For quantized data types, this also implies
that the offset is zero.</p>
<p>Note that sparse tensors can be partially sparse. For example, we accommodate cases where spatial
dimensions are sparse, but the channel dimension is dense (e.g. RGB). We manage this with the definition
of K, which represents the number of sparse dimensions. Note that all K sparse dimensions must be the
outermost (slowest changing) dimensions. The N-K dense dimensions are the innermost (fastest changing)
dimensions.</p>
<p>References:</p>
<ul class="simple">
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/sparse.html">torch.sparse</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/sparse">tf.sparse</a></p></li>
<li><p>QNN: <a class="reference internal" href="#getsparseindices">GetSparseIndices</a></p></li>
<li><p>QNN: <a class="reference internal" href="#getsparsevalues">GetSparseValues</a></p></li>
<li><p>QNN: <a class="reference internal" href="#sparsetodense">SparseToDense</a></p></li>
</ul>
<div class="section" id="id152">
<h3>Inputs<a class="headerlink" href="#id152" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id153">
<h4>in[0]<a class="headerlink" href="#id153" title="Permalink to this heading">¶</a></h4>
<p>indices</p>
<p>The elements of the in[0] indices tensor correspond to the respective element of the in[1] values
tensor in the equivalent dense tensor.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32, QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [M, K] where 0 &lt; K &lt;= N. M may be dynamically sized and K is fixed.</p></li>
</ul>
</div>
<div class="section" id="id154">
<h4>in[1]<a class="headerlink" href="#id154" title="Permalink to this heading">¶</a></h4>
<p>values</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N-K+1 with shape <span class="math notranslate nohighlight">\([M,D_{K},...,D_{N-1}]\)</span></p></li>
</ul>
</div>
</div>
<div class="section" id="id155">
<h3>Parameters<a class="headerlink" href="#id155" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id156">
<h3>Outputs<a class="headerlink" href="#id156" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id157">
<h4>out[0]<a class="headerlink" href="#id157" title="Permalink to this heading">¶</a></h4>
<p>output</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N with shape <span class="math notranslate nohighlight">\([D_0,...,D_{N-1}]\)</span></p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[1]</p></li>
<li><p>Must be a sparse tensor.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="cropandresize">
<span id="id158"></span><h2>CropAndResize<a class="headerlink" href="#cropandresize" title="Permalink to this heading">¶</a></h2>
<p>Extract crops from the input batch of images and resize them to a common
specified output size. This operation may not preserve aspect ratio of the
input crops. The resizing is corner-aligned.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/image/crop_and_resize">crop_and_resize</a></p></li>
</ul>
<div class="section" id="id159">
<h3>Inputs<a class="headerlink" href="#id159" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id160">
<h4>in[0]<a class="headerlink" href="#id160" title="Permalink to this heading">¶</a></h4>
<p>Input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch,height,width,channel]</p></li>
</ul>
</div>
<div class="section" id="id161">
<h4>in[1]<a class="headerlink" href="#id161" title="Permalink to this heading">¶</a></h4>
<p>Crop boxes : Each box defines the crop zone
in one of the images in the input batch.
Elements may be interpreted as 4-tuples of (y1,x1,y2,x2) representing
normalized crop coordinates. A normalized coordinate value of y is mapped to
the image coordinate at y * (image_height - 1), so as the [0, 1] interval
of normalized image height is mapped to [0, image_height - 1] in
image height coordinates. The condition (y1 &gt; y2) is permitted, in which case
the sampled crop is an up-down flipped version of the original image.
The width dimension is treated similarly. Specifying coordinates
outside of the range [0, 1] result in extrapolation of
input image values.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_boxes,4]</p></li>
</ul>
</div>
<div class="section" id="id162">
<h4>in[2]<a class="headerlink" href="#id162" title="Permalink to this heading">¶</a></h4>
<p>Batch index in the input tensor to which each box corresponds.
Indices in in[2] indicate the images in the input batch that will be
cropped using box coordinates in the same position in in[1].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32, QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [num_boxes]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: in range [0, batch-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id163">
<h3>Parameters<a class="headerlink" href="#id163" title="Permalink to this heading">¶</a></h3>
<div class="section" id="resize-dims">
<h4>resize_dims<a class="headerlink" href="#resize-dims" title="Permalink to this heading">¶</a></h4>
<p>The dimensions to which input images are cropped and resized
to [resize_height, resize_width].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2]</p></li>
</ul>
</div>
<div class="section" id="interpolation-mode">
<h4>interpolation_mode<a class="headerlink" href="#interpolation-mode" title="Permalink to this heading">¶</a></h4>
<p>Determines the interpolation method. Supported values are
0: BILINEAR, 1: NEAREST_NEIGHBOR.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>BILINEAR = 0,</p></li>
<li><p>NEAREST_NEIGHBOR = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="extrapolation-value">
<h4>extrapolation_value<a class="headerlink" href="#extrapolation-value" title="Permalink to this heading">¶</a></h4>
<p>Value used for extrapolation during the resize operation when applicable.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id164">
<h3>Outputs<a class="headerlink" href="#id164" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id165">
<h4>out[0]<a class="headerlink" href="#id165" title="Permalink to this heading">¶</a></h4>
<p>Output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_boxes,resize_height,resize_width,channel].</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="cumulativesum">
<span id="id166"></span><h2>CumulativeSum<a class="headerlink" href="#cumulativesum" title="Permalink to this heading">¶</a></h2>
<p>Performs cumulative sum of the input elements along the given axis. By default, this
op performs the sum inclusively meaning the first element of the input is identical
to the first element of the output. An exclusive sum can be performed by setting the
<em>exclusive</em> parameter to true. It can also perform summation in the opposite
direction of the axis by setting the <em>reverse</em> parameter to true.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Default case</span>
<span class="n">When</span><span class="w"> </span><span class="n">QNN_OP_CUMULATIVE_SUM_PARAM_EXCLUSIVE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="n">AND</span><span class="w"> </span><span class="n">QNN_OP_CUMULATIVE_SUM_PARAM_REVERSE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">:</span>
<span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">always</span><span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="p">(</span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="p">(</span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>

<span class="c1">// Example</span>
<span class="n">input</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">exclusive</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">reverse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<span class="n">output</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">]</span>

<span class="n">input</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">exclusive</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">reverse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<span class="n">output</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">]</span>

<span class="n">input</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">exclusive</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">reverse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span>
<span class="n">output</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">]</span>

<span class="n">input</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">exclusive</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">reverse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span>
<span class="n">output</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#CumSum">CumSum</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/cumsum">ops::Cumsum</a></p></li>
</ul>
<div class="section" id="id167">
<h3>Inputs<a class="headerlink" href="#id167" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id168">
<h4>in[0]<a class="headerlink" href="#id168" title="Permalink to this heading">¶</a></h4>
<p>Input data</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of N dimension</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id169">
<h3>Parameters<a class="headerlink" href="#id169" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id170">
<h4>axis<a class="headerlink" href="#id170" title="Permalink to this heading">¶</a></h4>
<p>Dimension index, starts at 0.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [0, rank(in[0]) - 1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="exclusive">
<h4>exclusive<a class="headerlink" href="#exclusive" title="Permalink to this heading">¶</a></h4>
<p>If QNN_OP_CUMULATIVE_SUM_PARAM_EXCLUSIVE is set to true an exclusive sum is
performed where the i-th output element is the sum of the first (i - 1)
elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">When</span><span class="w"> </span><span class="n">QNN_OP_CUMULATIVE_SUM_PARAM_EXCLUSIVE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">AND</span><span class="w"> </span><span class="n">QNN_OP_CUMULATIVE_SUM_PARAM_REVERSE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">:</span>
<span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">always</span><span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="p">(</span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="p">(</span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="reverse">
<h4>reverse<a class="headerlink" href="#reverse" title="Permalink to this heading">¶</a></h4>
<p>If QNN_OP_CUMULATIVE_SUM_PARAM_REVERSE is set to true the sum is performed in
the reverse direction.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">When</span><span class="w"> </span><span class="n">QNN_OP_CUMULATIVE_SUM_PARAM_EXCLUSIVE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="n">AND</span><span class="w"> </span><span class="n">QNN_OP_CUMULATIVE_SUM_PARAM_REVERSE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">:</span>
<span class="n">output</span><span class="p">[</span><span class="n">K</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">K</span><span class="p">]</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">always</span><span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="p">(</span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">K</span><span class="p">,</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">.</span><span class="n">dim</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">K</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">K</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="p">(</span><span class="k">for</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">K</span><span class="p">)</span>

<span class="n">When</span><span class="w"> </span><span class="n">QNN_OP_CUMULATIVE_SUM_PARAM_EXCLUSIVE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">AND</span><span class="w"> </span><span class="n">QNN_OP_CUMULATIVE_SUM_PARAM_REVERSE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">:</span>
<span class="n">output</span><span class="p">[</span><span class="n">K</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">always</span><span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="p">(</span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">K</span><span class="p">,</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">.</span><span class="n">dim</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">K</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">K</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="p">(</span><span class="k">for</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">K</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id171">
<h3>Outputs<a class="headerlink" href="#id171" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id172">
<h4>out[0]<a class="headerlink" href="#id172" title="Permalink to this heading">¶</a></h4>
<p>Output data</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="depthtospace">
<span id="id173"></span><h2>DepthToSpace<a class="headerlink" href="#depthtospace" title="Permalink to this heading">¶</a></h2>
<p>A type of tensor realignment operation that rearranges depth data into
blocks of spatial data.</p>
<p>The op moves blocks of data of size (block_size[0] * block_size[1]) from the depth
dimension of the input tensor into the spatial dimensions of the output tensor.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a34253f8b844b4c143f0fa36be3ba3f7a">ANEURALNETWORKS_DEPTH_TO_SPACE</a></p></li>
</ul>
<div class="section" id="id174">
<h3>Inputs<a class="headerlink" href="#id174" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id175">
<h4>in[0]<a class="headerlink" href="#id175" title="Permalink to this heading">¶</a></h4>
<p>Input Activation.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D tensor of shape [batch, height, width, depth]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: depth must be divisible by (block_size[0] * block_size[1])</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id176">
<h3>Parameters<a class="headerlink" href="#id176" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id177">
<h4>block_size<a class="headerlink" href="#id177" title="Permalink to this heading">¶</a></h4>
<p>Vector that represents block size along the <em>height</em> and <em>width</em> dimensions
respectively.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] with format [block_height, block_width]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Elements must be &gt;=1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id178">
<h4>mode<a class="headerlink" href="#id178" title="Permalink to this heading">¶</a></h4>
<p>Specifies the order in which elements of in[0] are rearranged. If
QNN_OP_DEPTH_TO_SPACE_PARAM_MODE is set to QNN_OP_DEPTH_TO_SPACE_MODE_DCR then
elements along the depth dimension are rearranged in the order of depth, column,
and then row; if set to QNN_OP_DEPTH_TO_SPACE_MODE_CRD elements along the depth
dimension are rearranged in the order of column, row, and then depth.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>DCR = 0,</p></li>
<li><p>CRD = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id179">
<h3>Outputs<a class="headerlink" href="#id179" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id180">
<h4>out[0]<a class="headerlink" href="#id180" title="Permalink to this heading">¶</a></h4>
<p>Output Activation.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D tensor of shape [batch, (height * block_size[0]), (width * block_size[1]), depth / (block_size[0] * block_size[1])]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="depthwiseconv1d">
<span id="id181"></span><h2>DepthWiseConv1d<a class="headerlink" href="#depthwiseconv1d" title="Permalink to this heading">¶</a></h2>
<p>Performs depthwise 1D convolution: dot-product of a set of 1D filters with input
activation, producing output activation.
Depthwise 1D convolution applies a different filter to each input channel group,
then concatenates the results together.
Depthwise 1D convolution is functionally equivalent to Conv 1D where ‘group’
parameter value == channel_in and channel_out is a multiple of channel_in,
e.g. channel_out % channel_in == 0. Application of the filter moves according to
the specified stride. For backends supporting quantized data types, clients can
pass filters which are either quantized per-tensor or per-axis with possible
constraints on the axis value that is supported.</p>
<div class="section" id="id182">
<h3>Inputs<a class="headerlink" href="#id182" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id183">
<h4>in[0]<a class="headerlink" href="#id183" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, width, channel_in]</p></li>
</ul>
</div>
<div class="section" id="id184">
<h4>in[1]<a class="headerlink" href="#id184" title="Permalink to this heading">¶</a></h4>
<p>filters</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [filter_width, 1, channel_out]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Channel_out must be divisible by channel_in</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id185">
<h4>in[2]<a class="headerlink" href="#id185" title="Permalink to this heading">¶</a></h4>
<p>biases</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [channel_out]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
</div>
<div class="section" id="id186">
<h3>Parameters<a class="headerlink" href="#id186" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id187">
<h4>stride<a class="headerlink" href="#id187" title="Permalink to this heading">¶</a></h4>
<p>Defines stride for 1D spatial axes of in[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id188">
<h4>pad_amount<a class="headerlink" href="#id188" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 1D spatial axes in[0].
Pad value = 0.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] with format [width_pad_before, width_pad_after]</p></li>
</ul>
</div>
<div class="section" id="id189">
<h4>dilation<a class="headerlink" href="#id189" title="Permalink to this heading">¶</a></h4>
<p>Dilation parameter for width dimension of in[0].
If set to d &gt; 1, there will be d-1 skipped cells between each filter element
on corresponding dimension.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id190">
<h3>Outputs<a class="headerlink" href="#id190" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id191">
<h4>out[0]<a class="headerlink" href="#id191" title="Permalink to this heading">¶</a></h4>
<p>output activation : The output 1D spatial dimensions are functions of the
<em>filter_size</em>, <em>stride</em>, and <em>pad_amount</em>.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">dilated_filter_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dilation</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="n">width_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">dilated_filter_width</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, width_out, channel_out]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="depthwiseconv2d">
<span id="id192"></span><h2>DepthWiseConv2d<a class="headerlink" href="#depthwiseconv2d" title="Permalink to this heading">¶</a></h2>
<p>Performs depthwise 2D convolution: dot-product of a set of 2D filters with input
activation, producing output activation.
Depthwise 2D convolution applies a different filter to each input channel group,
then concatenates the results together.
Depthwise 2D convolution is functionally equivalent to Conv 2D where
‘group’ parameter value == channel_in and channel_out is a multiple of channel_in,
e.g. channel_out % channel_in == 0. Application of the filter moves according to
the specified strides. For backends supporting quantized data types, clients can
pass filters which are either quantized per-tensor or per-axis with possible
constraints on the axis value that is supported.</p>
<p>Refer to DepthWiseConv2d backend definition for supported data type and layouts for each backend.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a2b49a44b7ebba243fad01556c1f0392e">ANEURALNETWORKS_DEPTHWISE_CONV_2D</a></p></li>
</ul>
<div class="section" id="id193">
<h3>Inputs<a class="headerlink" href="#id193" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id194">
<h4>in[0]<a class="headerlink" href="#id194" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height, width, channel_in]</p></li>
</ul>
</div>
<div class="section" id="id195">
<h4>in[1]<a class="headerlink" href="#id195" title="Permalink to this heading">¶</a></h4>
<p>filters</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [filter_height, filter_width, 1, channel_out]</p></li>
</ul>
</div>
<div class="section" id="id196">
<h4>in[2]<a class="headerlink" href="#id196" title="Permalink to this heading">¶</a></h4>
<p>biases</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [channel_out]</p></li>
<li><p>Default: [0]</p></li>
</ul>
</div>
</div>
<div class="section" id="id197">
<h3>Parameters<a class="headerlink" href="#id197" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id198">
<h4>stride<a class="headerlink" href="#id198" title="Permalink to this heading">¶</a></h4>
<p>Defines stride for 2D spatial axes of in[0].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] : [height_stride, width_stride]</p></li>
</ul>
</div>
<div class="section" id="id199">
<h4>pad_amount<a class="headerlink" href="#id199" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 2D spatial axes in[0].
Pad value = 0.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2,2] with format [[height_pad_before, height_pad_after], [width_pad_before, width_pad_after]]</p></li>
</ul>
</div>
<div class="section" id="id200">
<h4>dilation<a class="headerlink" href="#id200" title="Permalink to this heading">¶</a></h4>
<p>Dilation parameter for height and width dimensions.
If set to d &gt; 1, there will be d-1 skipped cells between each filter element
on corresponding dimension.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [height_dilation, width_dilation]</p></li>
<li><p>Default: [1, 1]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Dilations must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id201">
<h3>Outputs<a class="headerlink" href="#id201" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id202">
<h4>out[0]<a class="headerlink" href="#id202" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<p>The output 2D spatial dimensions are functions of the filter size, stride, and pad_amount.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">dilated_filter_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dilation</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="n">dilated_filter_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dilation</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="n">height_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">dilated_filter_height</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">width_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">dilated_filter_width</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height_out, width_out, channel_out]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="dequantize">
<span id="id203"></span><h2>Dequantize<a class="headerlink" href="#dequantize" title="Permalink to this heading">¶</a></h2>
<p>Dequantizes the input tensor. Note that <em>scale</em> and <em>offset</em> are determined from in[0].</p>
<p>Implements:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">input</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">offset</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">scale</span><span class="p">.</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ad4c9300b061d9d14669bd5acdc7538e2">ANEURALNETWORKS_DEQUANTIZE</a></p></li>
<li><p>QNN: <a class="reference internal" href="#quantize">Quantize</a></p></li>
</ul>
<div class="section" id="id204">
<h3>Inputs<a class="headerlink" href="#id204" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id205">
<h4>in[0]<a class="headerlink" href="#id205" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_SFIXED_POINT_4, QNN_DATATYPE_UFIXED_POINT_4, QNN_DATATYPE_SFIXED_POINT_8, QNN_DATATYPE_UFIXED_POINT_8, QNN_DATATYPE_SFIXED_POINT_16, QNN_DATATYPE_UFIXED_POINT_16, QNN_DATATYPE_SFIXED_POINT_32, QNN_DATATYPE_UFIXED_POINT_32, backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id206">
<h3>Parameters<a class="headerlink" href="#id206" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id207">
<h3>Outputs<a class="headerlink" href="#id207" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id208">
<h4>out[0]<a class="headerlink" href="#id208" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32, backend specific</p></li>
<li><p>Shape:</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="detectionoutput">
<span id="id209"></span><h2>DetectionOutput<a class="headerlink" href="#detectionoutput" title="Permalink to this heading">¶</a></h2>
<p>Decodes a set of bounding boxes from a set of pre-defined anchors, then filters
boxes using non-max-suppression (NMS).</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0abd6365933837275bb1f5cde1fd9b8234">ANEURALNETWORKS_DETECTION_POSTPROCESSING</a></p></li>
</ul>
<div class="section" id="id210">
<h3>Inputs<a class="headerlink" href="#id210" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id211">
<h4>in[0]<a class="headerlink" href="#id211" title="Permalink to this heading">¶</a></h4>
<p>Scores for each class at each pre-defined anchor.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, num_anchors, num_classes]</p></li>
</ul>
</div>
<div class="section" id="id212">
<h4>in[1]<a class="headerlink" href="#id212" title="Permalink to this heading">¶</a></h4>
<p>Input box locations. Elements may be interpreted as [ctr_y, ctr_x, h, w]
where ctr_y and ctr_x give the center position of the box, and h and w are
the height and width of the box.
The number of input boxes is computed as follows:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">num_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_anchors</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">share_location</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OP_DETECTION_OUTPUT_SHARE_LOCATION</span><span class="w"> </span><span class="nb">true</span>
<span class="n">num_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">num_anchors</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">num_classes</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">share_location</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OP_DETECTION_OUTPUT_SHARE_LOCATION</span><span class="w"> </span><span class="nb">false</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, num_boxes, 4]</p></li>
</ul>
</div>
<div class="section" id="id213">
<h4>in[2]<a class="headerlink" href="#id213" title="Permalink to this heading">¶</a></h4>
<p>Anchor positions. Elements may be interpreted as [ctr_y, ctr_x, h, w] where
ctr_y and ctr_x are the center position, and h and w are the
height and width of the anchor.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_anchors * batch, 4]</p></li>
</ul>
</div>
</div>
<div class="section" id="id214">
<h3>Parameters<a class="headerlink" href="#id214" title="Permalink to this heading">¶</a></h3>
<div class="section" id="delta-scaling-factors">
<h4>delta_scaling_factors<a class="headerlink" href="#delta-scaling-factors" title="Permalink to this heading">¶</a></h4>
<p>Multiplicative scaling factors applied to each of the bounding boxes in in[1]
in the form of (dy, dx, dh, dw), where dy and dx are linear-scale shifts
with respect to width and height, and dh and dw are log-scale scaling factors
with respect to the width and height of the boxes.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: [4]</p></li>
</ul>
</div>
<div class="section" id="confidence-threshold">
<h4>confidence_threshold<a class="headerlink" href="#confidence-threshold" title="Permalink to this heading">¶</a></h4>
<p>Boxes with scores lower than this threshold are filtered
prior to the application of NMS.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="id215">
<h4>iou_threshold<a class="headerlink" href="#id215" title="Permalink to this heading">¶</a></h4>
<p>IoU threshold for the NMS algorithm.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="nms-type">
<h4>nms_type<a class="headerlink" href="#nms-type" title="Permalink to this heading">¶</a></h4>
<p>Specifies which variant of NMS to use. Set QNN_OP_DETECTION_OUTPUT_NMS_TYPE_REGULAR
for regular multi-class NMS, or QNN_OP_DETECTION_OUTPUT_NMS_TYPE_FAST for a
faster variant which limits the number of classes to which NMS is applied.
REGULAR: 1, FAST: 0</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>FAST = 0,</p></li>
<li><p>REGULAR = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="background-class-idx">
<h4>background_class_idx<a class="headerlink" href="#background-class-idx" title="Permalink to this heading">¶</a></h4>
<p>The index in num_classes of the “background” class.
This class will be ignored by NMS.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="use-bg-in-nms">
<h4>use_bg_in_nms<a class="headerlink" href="#use-bg-in-nms" title="Permalink to this heading">¶</a></h4>
<p>Choose to include background class in computing NMS.
Set QNN_OP_DETECTION_OUTPUT_USE_BG_IN_NMS true to include the BG class,
or to false to ignore.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="output-background">
<h4>output_background<a class="headerlink" href="#output-background" title="Permalink to this heading">¶</a></h4>
<p>Set to QNN_OP_DETECTION_OUTPUT_OUTPUT_BACKGROUND true to include
the background class in the output, or false to exclude the class.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="share-location">
<h4>share_location<a class="headerlink" href="#share-location" title="Permalink to this heading">¶</a></h4>
<p>Set to QNN_OP_DETECTION_OUTPUT_SHARE_LOCATION true to indicate that
the classes all share a common set of initial bounding boxes, and
QNN_OP_DETECTION_OUTPUT_SHARE_LOCATION false to indicate that
they use different initial bounding boxes.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="nms-eta">
<h4>nms_eta<a class="headerlink" href="#nms-eta" title="Permalink to this heading">¶</a></h4>
<p>Adaptation factor for the NMS threshold.
This factor is applied when nms_type is set to
QNN_OP_DETECTION_OUTPUT_NMS_TYPE_REGULAR.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1.0</p></li>
</ul>
</div>
<div class="section" id="detection-limit">
<h4>detection_limit<a class="headerlink" href="#detection-limit" title="Permalink to this heading">¶</a></h4>
<p>Parameter that specifies:</p>
<p>(i) the maximum number of classes per detection when nms_type is set to
QNN_OP_DETECTION_OUTPUT_NMS_TYPE_FAST.</p>
<p>(ii) the maximum number of detections when applying NMS for each single class
when nms_type is set to QNN_OP_DETECTION_OUTPUT_NMS_TYPE_REGULAR.</p>
<p>Parameter is ignored if set to default value.
This parameter is similar to ‘nms_topK’ found in training frameworks like
Caffe which set nms_type to QNN_OP_DETECTION_OUTPUT_NMS_TYPE_REGULAR.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: -1</p></li>
</ul>
</div>
</div>
<div class="section" id="id216">
<h3>Outputs<a class="headerlink" href="#id216" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id217">
<h4>out[0]<a class="headerlink" href="#id217" title="Permalink to this heading">¶</a></h4>
<p>Detection scores.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, max_num_detections]. max_num_detections can be expressed by maxDimensions in Qnn_Tensor_t.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id218">
<h4>out[1]<a class="headerlink" href="#id218" title="Permalink to this heading">¶</a></h4>
<p>Detection locations. Elements specify the coordinates of the output bounding
boxes and can interpreted as 4-tuples with format (y1,x1,y2,x2) representing the
upper-left and lower-right corner coordinates. A valid bounding box should
satisfy x1 &lt;= x2 and y2 &lt;= y1. Note that quantized data types may provide output
box coordinates that are out of range.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: [batch, max_num_detections, 4]. max_num_detections can be expressed by maxDimensions in Qnn_Tensor_t.</p></li>
</ul>
</div>
<div class="section" id="id219">
<h4>out[2]<a class="headerlink" href="#id219" title="Permalink to this heading">¶</a></h4>
<p>Detection labels. Gives the class label for each detection.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [batch, max_num_detections]</p></li>
</ul>
</div>
<div class="section" id="id220">
<h4>out[3]<a class="headerlink" href="#id220" title="Permalink to this heading">¶</a></h4>
<p>Valid number of detections per batch.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [batch]</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="distributefpnproposals">
<span id="id221"></span><h2>DistributeFpnProposals<a class="headerlink" href="#distributefpnproposals" title="Permalink to this heading">¶</a></h2>
<p>Distribute RPN proposals to their appropriate FPN levels for Faster RCNN. Note that
RoI elements can be understood as 5-tuples with format (batch_idx, x1, y1, x2, y2)
where batch_idx specifies the batch index of each RoI, (x1,y1) represents the
upper-left corner coordinate, and (x2,y2) represents the lower-right corner
coordinate.</p>
<div class="section" id="id222">
<h3>Inputs<a class="headerlink" href="#id222" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id223">
<h4>in[0]<a class="headerlink" href="#id223" title="Permalink to this heading">¶</a></h4>
<p>RoIs : RPN proposals.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_proposals, 5] each line with format [batch_idx, x1, y1, x2, y2] or [num_proposals, 4] each line with format [x1, y1, x2, y2]</p></li>
</ul>
</div>
</div>
<div class="section" id="id224">
<h3>Parameters<a class="headerlink" href="#id224" title="Permalink to this heading">¶</a></h3>
<div class="section" id="roi-min-level">
<h4>roi_min_level<a class="headerlink" href="#roi-min-level" title="Permalink to this heading">¶</a></h4>
<p>Sets the maximum FPN level to support RoI transform operations on multiple FPN
levels.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 2</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [2,5]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="roi-max-level">
<h4>roi_max_level<a class="headerlink" href="#roi-max-level" title="Permalink to this heading">¶</a></h4>
<p>Sets the maximum FPN level to support RoI transform operations on multiple FPN
levels.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 5</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [2,5]</p></li>
<li><p>Value: Must be &gt;= roi_min_level</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="roi-canonical-scale">
<h4>roi_canonical_scale<a class="headerlink" href="#roi-canonical-scale" title="Permalink to this heading">¶</a></h4>
<p>Scaling factor used to compute which FPN level each RoI in a set of RoIs should
map to.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 224</p></li>
</ul>
</div>
<div class="section" id="roi-canonical-level">
<h4>roi_canonical_level<a class="headerlink" href="#roi-canonical-level" title="Permalink to this heading">¶</a></h4>
<p>Value to offset the computed FPN level for each RoI.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 4</p></li>
</ul>
</div>
</div>
<div class="section" id="id225">
<h3>Outputs<a class="headerlink" href="#id225" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id226">
<h4>out[0]<a class="headerlink" href="#id226" title="Permalink to this heading">¶</a></h4>
<p>rois_idx_restore : indices to restore the RoIs to their original order from
in[0]. Indices are in respect to the concatenation of the <em>RoIs
FPN</em> outputs in order from FPN level <em>roi_min_level</em> to FPN level
<em>roi_max_level</em>. For invalid RoIs having coordinate values (x2 - x1 = 0) and
(y2 - y1 = 0) the corresponding index value will be set to -1.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32, QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [num_proposals]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [0, num_proposals * (roi_max_level * roi_min_level + 1) - 1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id227">
<h4>out[1]<a class="headerlink" href="#id227" title="Permalink to this heading">¶</a></h4>
<p>RoIs FPN : RoIs mapped to FPN level <em>roi_min_level</em>.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois, 5] each line with format [batch_idx, x1, y1, x2, y2] or [num_rois, 4] each line with format [x1, y1, x2, y2]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: 0 &lt;= num_rois &lt;= num_proposals</p></li>
<li><p>Shape: shape(out[1])[1] must equal shape(in[0])[1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="out-2-4">
<h4>out[2..4]<a class="headerlink" href="#out-2-4" title="Permalink to this heading">¶</a></h4>
<p>RoIs FPN : RoIs mapped to FPN levels [<em>roi_min_level</em> + 1, <em>roi_max_level</em>].
Note that each output may have a different shape since <em>num_roi_i</em> can vary for
out[2..4].</p>
<p>This tensor is repeated, meaning the same definition can apply to multiple
tensors.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois_i, 5] each line with format [batch_idx, x1, y1, x2, y2] or [num_rois_i, 4] each line with format [x1, y1, x2, y2]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: 0 &lt;= num_rois_i &lt;= num_proposals</p></li>
<li><p>Datatype: Same datatype as out[1]</p></li>
<li><p>Number: Number of out[2..4] provided must equal <em>roi_max_level</em> - <em>roi_min_level</em></p></li>
<li><p>Value: The sum of <em>num_rois</em> across all <em>RoIs FPN</em> outputs must equal <em>num_proposals</em></p></li>
<li><p>Shape: shape(out[2..4])[1] must equal shape(in[0])[1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseabs">
<span id="id228"></span><h2>ElementWiseAbs<a class="headerlink" href="#elementwiseabs" title="Permalink to this heading">¶</a></h2>
<p>Computes absolute value of the input element-wise.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a8ecc424dd6710f89683edaf12ce38e39">ANEURALNETWORKS_ABS</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id229">
<h3>Inputs<a class="headerlink" href="#id229" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id230">
<h4>in[0]<a class="headerlink" href="#id230" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id231">
<h3>Parameters<a class="headerlink" href="#id231" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id232">
<h3>Outputs<a class="headerlink" href="#id232" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id233">
<h4>out[0]<a class="headerlink" href="#id233" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseadd">
<span id="id234"></span><h2>ElementWiseAdd<a class="headerlink" href="#elementwiseadd" title="Permalink to this heading">¶</a></h2>
<p>Adds two tensors element-wise. The output is the sum of input tensors.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>Refer to ElementWiseAdd backend definitions for supported data type
and layouts for each backend.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ad681988001e5f8ab73230a311f4ab034">ANEURALNETWORKS_ADD</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id236">
<h3>Inputs<a class="headerlink" href="#id236" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id237">
<h4>in[0]<a class="headerlink" href="#id237" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id238">
<h4>in[1]<a class="headerlink" href="#id238" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Rank &gt; 0</p></li>
<li><p>Must have same data format as in[0] (e.g. both sparse or both dense)</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id239">
<h3>Parameters<a class="headerlink" href="#id239" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id240">
<h3>Outputs<a class="headerlink" href="#id240" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id241">
<h4>out[0]<a class="headerlink" href="#id241" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Must have same data format as in[0] (e.g. both sparse or both dense)</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseand">
<span id="id242"></span><h2>ElementWiseAnd<a class="headerlink" href="#elementwiseand" title="Permalink to this heading">¶</a></h2>
<p>Logical ANDs two tensors element-wise:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>where non-zero values are treated as true and zero as false.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a3e5d914633b5520c00b1668d2244b911">ANEURALNETWORKS_LOGICAL_AND</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id245">
<h3>Inputs<a class="headerlink" href="#id245" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id246">
<h4>in[0]<a class="headerlink" href="#id246" title="Permalink to this heading">¶</a></h4>
<p>1st input tensor</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id247">
<h4>in[1]<a class="headerlink" href="#id247" title="Permalink to this heading">¶</a></h4>
<p>2nd input tensor</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id248">
<h3>Parameters<a class="headerlink" href="#id248" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id249">
<h3>Outputs<a class="headerlink" href="#id249" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id250">
<h4>out[0]<a class="headerlink" href="#id250" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseasin">
<span id="id251"></span><h2>ElementWiseAsin<a class="headerlink" href="#elementwiseasin" title="Permalink to this heading">¶</a></h2>
<p>Computes the arcsine of the input element-wise. Note that arcsine behavior is
undefined for input values outside the range [-1, 1].</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \arcsin{(\mbox{in[0]})}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Asin">ops::Asin</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.asin.html#torch.asin">Asin</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/asin">asin</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id254">
<h3>Inputs<a class="headerlink" href="#id254" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id255">
<h4>in[0]<a class="headerlink" href="#id255" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
</div>
<div class="section" id="id256">
<h3>Parameters<a class="headerlink" href="#id256" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id257">
<h3>Outputs<a class="headerlink" href="#id257" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id258">
<h4>out[0]<a class="headerlink" href="#id258" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseatan">
<span id="id259"></span><h2>ElementWiseAtan<a class="headerlink" href="#elementwiseatan" title="Permalink to this heading">¶</a></h2>
<p>Computes the arctangent of the input element-wise.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Atan">ops::Atan</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/atan">atan</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id261">
<h3>Inputs<a class="headerlink" href="#id261" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id262">
<h4>in[0]<a class="headerlink" href="#id262" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id263">
<h3>Parameters<a class="headerlink" href="#id263" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id264">
<h3>Outputs<a class="headerlink" href="#id264" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id265">
<h4>out[0]<a class="headerlink" href="#id265" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisebinary">
<span id="id266"></span><h2>ElementWiseBinary<a class="headerlink" href="#elementwisebinary" title="Permalink to this heading">¶</a></h2>
<p>Computes the specified binary <em>operation</em> on the input element-wise. Note that
operations can be classified as being Numerical, Comparison, or Logical.</p>
<p>Available element-wise operations:</p>
<p><strong>ADD</strong> - Adds two tensors element-wise. The output is the sum of input tensors.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \mbox{in[0]} + \mbox{in[1]}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ad681988001e5f8ab73230a311f4ab034">ANEURALNETWORKS_ADD</a></p></li>
</ul>
<p><strong>AND</strong> - Logical ANDs two tensors element-wise.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \mbox{in[0]}\ \&amp;\&amp;\ \mbox{in[1]}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a3e5d914633b5520c00b1668d2244b911">ANEURALNETWORKS_LOGICAL_AND</a></p></li>
</ul>
<p><strong>DIVIDE</strong> - Divides two tensors element-wise. The output is the result of dividing
first input tensor by the second one. Result is undefined for any 0 value in the
second input tensor.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \frac{\mbox{in[0]}}{\mbox{in[1]}}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a139794099b4137599bbc73af18b0d42a">ANEURALNETWORKS_DIV</a></p></li>
</ul>
<p><strong>EQUAL</strong> - Computes the equal logical operation element-wise on the two input
tensors.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mbox{out[0]} = \begin{cases}
\text{true}\ &amp; \text{if}\ \mbox{in[0]} == \mbox{in[1]}, \\
\text{false}\ &amp; \text{otherwise.}
\end{cases}\end{split}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a4af31ebf58c6845d36fe26cf1a794d2c">ANEURALNETWORKS_EQUAL</a></p></li>
</ul>
<p><strong>FLOOR_DIV</strong> - Divides two tensors element-wise and floor the result. Result is
undefined for any 0 value in the second input tensor. Rounds towards the lowest
integer. For Example: -2.3 rounds to -3 and 2.3 rounds to 2</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \text{floor}(\frac{\mbox{in[0]}}{\mbox{in[1]}})\]</div>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/floordiv">tf.math.floordiv</a></p></li>
</ul>
<p><strong>FMOD</strong> - Performs element-wise binary modulus. The sign of the remainder is the
same as that of the dividend (in[0]). Note that behavior is undefined when elements
from both in[0] and in[1] are 0.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \mbox{in[0]}\ \%\ \mbox{in[1]}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Mod">Mod</a></p></li>
</ul>
<p><strong>GREATER</strong> - Computes the greater than logical operation element-wise on the input
tensors.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mbox{out[0]} = \begin{cases}
\text{true}\ &amp; \text{if}\ \mbox{in[0]} &gt; \mbox{in[1]}, \\
\text{false}\ &amp; \text{otherwise.}
\end{cases}\end{split}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0afe61c7102e8fa16d19c2d7d8f4f15360">ANEURALNETWORKS_GREATER</a></p></li>
</ul>
<p><strong>GREATER_EQUAL</strong> - Computes the greater than or equal logical operation
element-wise on the input tensors.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mbox{out[0]} = \begin{cases}
\text{true}\ &amp; \text{if}\ \mbox{in[0]}\ &gt;=\ \mbox{in[1]}, \\
\text{false}\ &amp; \text{otherwise.}
\end{cases}\end{split}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a3327f787f234f2a21f1fe14876ba85aa">ANEURALNETWORKS_GREATER_EQUAL</a></p></li>
</ul>
<p><strong>LESS</strong> - Computes the less than logical operation element-wise on the input
tensors.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mbox{out[0]} = \begin{cases}
\text{true}\ &amp; \text{if}\ \mbox{in[0]} &lt; \mbox{in[1]}, \\
\text{false}\ &amp; \text{otherwise.}
\end{cases}\end{split}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a858bf52c76d31c41a8df611017a96db0">ANEURALNETWORKS_LESS</a></p></li>
</ul>
<p><strong>LESS_EQUAL</strong> - Computes the less than or equal logical operation element-wise on
the input tensors.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mbox{out[0]} = \begin{cases}
\text{true}\ &amp; \text{if}\ \mbox{in[0]}\ &lt;=\ \mbox{in[1]}, \\
\text{false}\ &amp; \text{otherwise.}
\end{cases}\end{split}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0acf4d4d24685a6267d28f4873e7a43ae1">ANEURALNETWORKS_LESS_EQUAL</a></p></li>
</ul>
<p><strong>MAXIMUM</strong> - Element-wise maximum of two tensors.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \text{max}(\mbox{in[0]}, \mbox{in[1]})\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0aad00698dac694a7c1233dede8e8de91e">ANEURALNETWORKS_MAXIMUM</a></p></li>
</ul>
<p><strong>MINIMUM</strong> - Element-wise minimum of two tensors.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \text{min}(\mbox{in[0]}, \mbox{in[1]})\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a8738794be11b7a43e5c83010f582e0a6">ANEURALNETWORKS_MINIMUM</a></p></li>
</ul>
<p><strong>MOD</strong> - Performs element-wise binary modulus. The sign of the remainder is the
same as that of the divisor (in[1]). Note that behavior is undefined when elements
from both in[0] and in[1] are 0. This operation does not support floating point
data types use FMOD instead.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \mbox{in[0]}\ \%\ \mbox{in[1]}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Mod">Mod</a></p></li>
</ul>
<p><strong>MULTIPLY</strong> - Multiplies two tensors element-wise. The output is the result of
multiplying first input tensor with the second one.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \mbox{in[0]} \times \mbox{in[1]}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ab34ca99890c827b536ce66256a803d7a">ANEURALNETWORKS_MUL</a></p></li>
</ul>
<p><strong>NOT_EQUAL</strong> - Computes the not equal logical operation element-wise on the input
tensors.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mbox{out[0]} = \begin{cases}
\text{true}\ &amp; \text{if}\ \mbox{in[0]}\ !=\ \mbox{in[1]}, \\
\text{false}\ &amp; \text{otherwise.}
\end{cases}\end{split}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a7b79220811dd60b3c9afaabdc6ea6842">ANEURALNETWORKS_NOT_EQUAL</a></p></li>
</ul>
<p><strong>OR</strong> - Logical ORs two tensors element-wise where non-zero values are treated as
true and zero as false.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \mbox{in[0]}\ \vert \vert\ \mbox{in[1]}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a132ac3197242be5700d62b0037701718">ANEURALNETWORKS_LOGICAL_OR</a></p></li>
</ul>
<p><strong>POWER</strong> - Given base and exponent in input tensors, computes the (base^exponent)
element-wise.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = (\mbox{in[0]})^{\mbox{in[1]}}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0af04a05fbde5ec0d2e4e088750a8451ad">ANEURALNETWORKS_POW</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pow">Pow</a></p></li>
</ul>
<p><strong>SQUARED_DIFFERENCE</strong> - Computes the element-wise difference between 2 tensors by
subtracting the second tensor from the first and squares the results element-wise.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = (\mbox{in[0]} - \mbox{in[1]}) \times (\mbox{in[0]} - \mbox{in[1]})\]</div>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/squared_difference">tf.math.squared_difference</a></p></li>
</ul>
<p><strong>SUBTRACT</strong> - Subtract two tensors element-wise. The output is the result of
subtracting second input tensor from the first one.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \mbox{in[0]} - \mbox{in[1]}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a06a4248fe5ec71820ab95b87613780be">ANEURALNETWORKS_SUB</a></p></li>
</ul>
<p><strong>XOR</strong> - Logical XORs two tensors element-wise where non-zero values are treated as
true and zero as false.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \mbox{in[0]}\ \text{^}\ \mbox{in[1]}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Xor">Xor</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.asin.html#torch.logical_xor">torch.logical_xor</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/logical_xor">tf.math.logical_xor</a></p></li>
</ul>
<p>References:</p>
<ul class="simple">
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id272">
<h3>Inputs<a class="headerlink" href="#id272" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id273">
<h4>in[0]<a class="headerlink" href="#id273" title="Permalink to this heading">¶</a></h4>
<p>Note that the data type supported depends on the classification of the
<em>operation</em> selected and can be categorized into one of the following:</p>
<ul class="simple">
<li><p>Numerical: BACKEND_SPECIFIC</p></li>
<li><p>Comparison: BACKEND_SPECIFIC</p></li>
<li><p>Logical: BACKEND_SPECIFIC, QNN_DATATYPE_BOOL_8</p></li>
</ul>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id274">
<h4>in[1]<a class="headerlink" href="#id274" title="Permalink to this heading">¶</a></h4>
<p>Note that the data type supported depends on the classification of the
<em>operation</em> selected and can be categorized into one of the following:</p>
<ul class="simple">
<li><p>Numerical: BACKEND_SPECIFIC</p></li>
<li><p>Comparison: BACKEND_SPECIFIC</p></li>
<li><p>Logical: BACKEND_SPECIFIC, QNN_DATATYPE_BOOL_8</p></li>
</ul>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0] for Numerical and Comparison operations with the exception of POWER.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id275">
<h3>Parameters<a class="headerlink" href="#id275" title="Permalink to this heading">¶</a></h3>
<div class="section" id="operation">
<h4>operation<a class="headerlink" href="#operation" title="Permalink to this heading">¶</a></h4>
<p>Specifies the binary element-wise operation to use.</p>
<p>Operations can be classified as one of the following:</p>
<ul class="simple">
<li><p>Numerical operations: ADD, DIVIDE, FMOD, FLOOR_DIV, MAXIMUM, MINIMUM, MOD, MULTIPLY, POWER, SQUARED_DIFFERENCE, SUBTRACT</p></li>
<li><p>Comparison operations: EQUAL, GREATER, GREATER_EQUAL, LESS, LESS_EQUAL, NOT_EQUAL</p></li>
<li><p>Logical operations: AND, OR, XOR</p></li>
</ul>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>ADD = 0,</p></li>
<li><p>AND = 1,</p></li>
<li><p>DIVIDE = 2,</p></li>
<li><p>EQUAL = 3,</p></li>
<li><p>FLOOR_DIV = 4,</p></li>
<li><p>FMOD = 5,</p></li>
<li><p>GREATER = 6,</p></li>
<li><p>GREATER_EQUAL = 7,</p></li>
<li><p>LESS = 8,</p></li>
<li><p>LESS_EQUAL = 9,</p></li>
<li><p>MAXIMUM = 10,</p></li>
<li><p>MINIMUM = 11,</p></li>
<li><p>MOD = 12,</p></li>
<li><p>MULTIPLY = 13,</p></li>
<li><p>NOT_EQUAL = 14,</p></li>
<li><p>OR = 15,</p></li>
<li><p>POWER = 16,</p></li>
<li><p>SQUARED_DIFFERENCE = 17,</p></li>
<li><p>SUBTRACT = 18,</p></li>
<li><p>XOR = 19</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id276">
<h3>Outputs<a class="headerlink" href="#id276" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id277">
<h4>out[0]<a class="headerlink" href="#id277" title="Permalink to this heading">¶</a></h4>
<p>Note that the data type supported depends on the classification of the
<em>operation</em> selected and can be categorized into one of the following:</p>
<ul class="simple">
<li><p>Numerical: BACKEND_SPECIFIC</p></li>
<li><p>Comparison: BACKEND_SPECIFIC, QNN_DATATYPE_BOOL_8</p></li>
<li><p>Logical: BACKEND_SPECIFIC, QNN_DATATYPE_BOOL_8</p></li>
</ul>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of Rank = max(N,M)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0] for Numerical operations</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseceil">
<span id="id278"></span><h2>ElementWiseCeil<a class="headerlink" href="#elementwiseceil" title="Permalink to this heading">¶</a></h2>
<p>Computes elementwise ceil on the input.
Returns elementwise smallest integer not less than the input.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Ceil">Ceil</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/math/ceil">Ceil</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id281">
<h3>Inputs<a class="headerlink" href="#id281" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id282">
<h4>in[0]<a class="headerlink" href="#id282" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32, QNN_DATATYPE_FLOAT_16, backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id283">
<h3>Parameters<a class="headerlink" href="#id283" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id284">
<h3>Outputs<a class="headerlink" href="#id284" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id285">
<h4>out[0]<a class="headerlink" href="#id285" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisecos">
<span id="id286"></span><h2>ElementWiseCos<a class="headerlink" href="#elementwisecos" title="Permalink to this heading">¶</a></h2>
<p>Computes the cosine of the input element-wise.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/cos">tf.math.cos</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id288">
<h3>Inputs<a class="headerlink" href="#id288" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id289">
<h4>in[0]<a class="headerlink" href="#id289" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32, QNN_DATATYPE_FLOAT_16</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id290">
<h3>Parameters<a class="headerlink" href="#id290" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id291">
<h3>Outputs<a class="headerlink" href="#id291" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id292">
<h4>out[0]<a class="headerlink" href="#id292" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisedivide">
<span id="id293"></span><h2>ElementWiseDivide<a class="headerlink" href="#elementwisedivide" title="Permalink to this heading">¶</a></h2>
<p>Divides two tensors element-wise. The output is the result of dividing first input
tensor by the second one. Result is undefined for any 0 value in the second input tensor.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>Refer to ElementWiseDivide backend definitions for supported data type and
layouts for each backend.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a139794099b4137599bbc73af18b0d42a">ANEURALNETWORKS_DIV</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id297">
<h3>Inputs<a class="headerlink" href="#id297" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id298">
<h4>in[0]<a class="headerlink" href="#id298" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id299">
<h4>in[1]<a class="headerlink" href="#id299" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id300">
<h3>Parameters<a class="headerlink" href="#id300" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id301">
<h3>Outputs<a class="headerlink" href="#id301" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id302">
<h4>out[0]<a class="headerlink" href="#id302" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseequal">
<span id="id303"></span><h2>ElementWiseEqual<a class="headerlink" href="#elementwiseequal" title="Permalink to this heading">¶</a></h2>
<p>Computes the equal logical operation elementwise on the two input tensors.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a4af31ebf58c6845d36fe26cf1a794d2c">ANEURALNETWORKS_EQUAL</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id306">
<h3>Inputs<a class="headerlink" href="#id306" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id307">
<h4>in[0]<a class="headerlink" href="#id307" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id308">
<h4>in[1]<a class="headerlink" href="#id308" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id309">
<h3>Parameters<a class="headerlink" href="#id309" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id310">
<h3>Outputs<a class="headerlink" href="#id310" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id311">
<h4>out[0]<a class="headerlink" href="#id311" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseexp">
<span id="id312"></span><h2>ElementWiseExp<a class="headerlink" href="#elementwiseexp" title="Permalink to this heading">¶</a></h2>
<p>Computes exponential of input element-wise.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a32bd40860ff7c3d91f5e62980bb52bc2">ANEURALNETWORKS_EXP</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id314">
<h3>Inputs<a class="headerlink" href="#id314" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id315">
<h4>in[0]<a class="headerlink" href="#id315" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32, QNN_DATATYPE_FLOAT_16, backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id316">
<h3>Parameters<a class="headerlink" href="#id316" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id317">
<h3>Outputs<a class="headerlink" href="#id317" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id318">
<h4>out[0]<a class="headerlink" href="#id318" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisefloor">
<span id="id319"></span><h2>ElementWiseFloor<a class="headerlink" href="#elementwisefloor" title="Permalink to this heading">¶</a></h2>
<p>Computes elementwise floor on the input.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0acdb4a57160153118dc6f87af0e4eccc5">ANEURALNETWORKS_FLOOR</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id321">
<h3>Inputs<a class="headerlink" href="#id321" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id322">
<h4>in[0]<a class="headerlink" href="#id322" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32, QNN_DATATYPE_FLOAT_16, backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id323">
<h3>Parameters<a class="headerlink" href="#id323" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id324">
<h3>Outputs<a class="headerlink" href="#id324" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id325">
<h4>out[0]<a class="headerlink" href="#id325" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisefloordiv">
<span id="id326"></span><h2>ElementWiseFloorDiv<a class="headerlink" href="#elementwisefloordiv" title="Permalink to this heading">¶</a></h2>
<p>Divides two tensors elementwise and floor the result. Result is undefined for any 0 value in the
second input tensor. Rounds towards the lowest integer.
For Example: -2.3 rounds to -3 and 2.3 rounds to 2</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/floordiv">tf.math.floordiv</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id329">
<h3>Inputs<a class="headerlink" href="#id329" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id330">
<h4>in[0]<a class="headerlink" href="#id330" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id331">
<h4>in[1]<a class="headerlink" href="#id331" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id332">
<h3>Parameters<a class="headerlink" href="#id332" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id333">
<h3>Outputs<a class="headerlink" href="#id333" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id334">
<h4>out[0]<a class="headerlink" href="#id334" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisefmod">
<span id="id335"></span><h2>ElementWiseFmod<a class="headerlink" href="#elementwisefmod" title="Permalink to this heading">¶</a></h2>
<p>Performs element-wise binary modulus. The sign of the output elements is the same as
elements in in[0]. Note that behavior is undefined when elements from both in[0] and
in[1] are 0.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \mbox{in[0]} \ \% \ \mbox{in[1]}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Mod">Mod</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id339">
<h3>Inputs<a class="headerlink" href="#id339" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id340">
<h4>in[0]<a class="headerlink" href="#id340" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id341">
<h4>in[1]<a class="headerlink" href="#id341" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id342">
<h3>Parameters<a class="headerlink" href="#id342" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id343">
<h3>Outputs<a class="headerlink" href="#id343" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id344">
<h4>out[0]<a class="headerlink" href="#id344" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisegreater">
<span id="id345"></span><h2>ElementWiseGreater<a class="headerlink" href="#elementwisegreater" title="Permalink to this heading">¶</a></h2>
<p>Computes the greater than logical operation elementwise on the input tensors.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0afe61c7102e8fa16d19c2d7d8f4f15360">ANEURALNETWORKS_GREATER</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id348">
<h3>Inputs<a class="headerlink" href="#id348" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id349">
<h4>in[0]<a class="headerlink" href="#id349" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id350">
<h4>in[1]<a class="headerlink" href="#id350" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id351">
<h3>Parameters<a class="headerlink" href="#id351" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id352">
<h3>Outputs<a class="headerlink" href="#id352" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id353">
<h4>out[0]<a class="headerlink" href="#id353" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisegreaterequal">
<span id="id354"></span><h2>ElementWiseGreaterEqual<a class="headerlink" href="#elementwisegreaterequal" title="Permalink to this heading">¶</a></h2>
<p>Computes the greater than or equal logical operation elementwise on the input tensors.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a3327f787f234f2a21f1fe14876ba85aa">ANEURALNETWORKS_GREATER_EQUAL</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id357">
<h3>Inputs<a class="headerlink" href="#id357" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id358">
<h4>in[0]<a class="headerlink" href="#id358" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id359">
<h4>in[1]<a class="headerlink" href="#id359" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id360">
<h3>Parameters<a class="headerlink" href="#id360" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id361">
<h3>Outputs<a class="headerlink" href="#id361" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id362">
<h4>out[0]<a class="headerlink" href="#id362" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseless">
<span id="id363"></span><h2>ElementWiseLess<a class="headerlink" href="#elementwiseless" title="Permalink to this heading">¶</a></h2>
<p>Computes the less than logical operation elementwise on the input tensors.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a858bf52c76d31c41a8df611017a96db0">ANEURALNETWORKS_LESS</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id367">
<h3>Inputs<a class="headerlink" href="#id367" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id368">
<h4>in[0]<a class="headerlink" href="#id368" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id369">
<h4>in[1]<a class="headerlink" href="#id369" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id370">
<h3>Parameters<a class="headerlink" href="#id370" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id371">
<h3>Outputs<a class="headerlink" href="#id371" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id372">
<h4>out[0]<a class="headerlink" href="#id372" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiselessequal">
<span id="id373"></span><h2>ElementWiseLessEqual<a class="headerlink" href="#elementwiselessequal" title="Permalink to this heading">¶</a></h2>
<p>Computes the less than or equal logical operation elementwise on the input tensors.
Tensors must have same rank and tensor dimensions must be compatible.
Two dimensions are compatible when they are equal or in[1] dimension is 1
(i.e. in[1] is broadcast across in[0]).</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0acf4d4d24685a6267d28f4873e7a43ae1">ANEURALNETWORKS_LESS_EQUAL</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id376">
<h3>Inputs<a class="headerlink" href="#id376" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id377">
<h4>in[0]<a class="headerlink" href="#id377" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id378">
<h4>in[1]<a class="headerlink" href="#id378" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id379">
<h3>Parameters<a class="headerlink" href="#id379" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id380">
<h3>Outputs<a class="headerlink" href="#id380" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id381">
<h4>out[0]<a class="headerlink" href="#id381" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiselog">
<span id="id382"></span><h2>ElementWiseLog<a class="headerlink" href="#elementwiselog" title="Permalink to this heading">¶</a></h2>
<p>Computes logarithm of input element-wise.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ad22137e675fafa6d72da7b52952cfb78">ANEURALNETWORKS_LOG</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id384">
<h3>Inputs<a class="headerlink" href="#id384" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id385">
<h4>in[0]<a class="headerlink" href="#id385" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32, QNN_DATATYPE_FLOAT_16</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id386">
<h3>Parameters<a class="headerlink" href="#id386" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id387">
<h3>Outputs<a class="headerlink" href="#id387" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id388">
<h4>out[0]<a class="headerlink" href="#id388" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisemaximum">
<span id="id389"></span><h2>ElementWiseMaximum<a class="headerlink" href="#elementwisemaximum" title="Permalink to this heading">¶</a></h2>
<p>Element-wise maximum of two tensors.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0aad00698dac694a7c1233dede8e8de91e">ANEURALNETWORKS_MAXIMUM</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id393">
<h3>Inputs<a class="headerlink" href="#id393" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id394">
<h4>in[0]<a class="headerlink" href="#id394" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id395">
<h4>in[1]<a class="headerlink" href="#id395" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id396">
<h3>Parameters<a class="headerlink" href="#id396" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id397">
<h3>Outputs<a class="headerlink" href="#id397" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id398">
<h4>out[0]<a class="headerlink" href="#id398" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseminimum">
<span id="id399"></span><h2>ElementWiseMinimum<a class="headerlink" href="#elementwiseminimum" title="Permalink to this heading">¶</a></h2>
<p>Element-wise minimum of two tensors.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a8738794be11b7a43e5c83010f582e0a6">ANEURALNETWORKS_MINIMUM</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id403">
<h3>Inputs<a class="headerlink" href="#id403" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id404">
<h4>in[0]<a class="headerlink" href="#id404" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id405">
<h4>in[1]<a class="headerlink" href="#id405" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id406">
<h3>Parameters<a class="headerlink" href="#id406" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id407">
<h3>Outputs<a class="headerlink" href="#id407" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id408">
<h4>out[0]<a class="headerlink" href="#id408" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisemod">
<span id="id409"></span><h2>ElementWiseMod<a class="headerlink" href="#elementwisemod" title="Permalink to this heading">¶</a></h2>
<p>Performs element-wise binary modulus. The sign of the output elements is the same as
elements in in[1]. Note that behavior is undefined when elements from both in[0] and
in[1] are 0.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \mbox{in[0]} \ \% \ \mbox{in[1]}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Mod">Mod</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id413">
<h3>Inputs<a class="headerlink" href="#id413" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id414">
<h4>in[0]<a class="headerlink" href="#id414" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Does not support floating point data types</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id415">
<h4>in[1]<a class="headerlink" href="#id415" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id416">
<h3>Parameters<a class="headerlink" href="#id416" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id417">
<h3>Outputs<a class="headerlink" href="#id417" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id418">
<h4>out[0]<a class="headerlink" href="#id418" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisemultiply">
<span id="id419"></span><h2>ElementWiseMultiply<a class="headerlink" href="#elementwisemultiply" title="Permalink to this heading">¶</a></h2>
<p>Multiplies two tensors element-wise. The output is the result of multiplying
first input tensor with the second one.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ab34ca99890c827b536ce66256a803d7a">ANEURALNETWORKS_MUL</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id423">
<h3>Inputs<a class="headerlink" href="#id423" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id424">
<h4>in[0]<a class="headerlink" href="#id424" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id425">
<h4>in[1]<a class="headerlink" href="#id425" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id426">
<h3>Parameters<a class="headerlink" href="#id426" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id427">
<h3>Outputs<a class="headerlink" href="#id427" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id428">
<h4>out[0]<a class="headerlink" href="#id428" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseneg">
<span id="id429"></span><h2>ElementWiseNeg<a class="headerlink" href="#elementwiseneg" title="Permalink to this heading">¶</a></h2>
<p>Computes numerical negative of input element-wise.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a3418665f9871dca43e3cb2efcac3990b">ANEURALNETWORKS_NEG</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id431">
<h3>Inputs<a class="headerlink" href="#id431" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id432">
<h4>in[0]<a class="headerlink" href="#id432" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id433">
<h3>Parameters<a class="headerlink" href="#id433" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id434">
<h3>Outputs<a class="headerlink" href="#id434" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id435">
<h4>out[0]<a class="headerlink" href="#id435" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseneuron">
<span id="id436"></span><h2>ElementWiseNeuron<a class="headerlink" href="#elementwiseneuron" title="Permalink to this heading">¶</a></h2>
<p>Computes the specified <em>operation</em> on the input element-wise.</p>
<p>Available element-wise operations:</p>
<p><strong>Elu</strong> - Computes the Exponential Linear Unit operation.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \max(0, \mbox{in[0]}) + \min(0, \alpha \times (e^{\mbox{in[0]}} - 1))\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a043a2da1768dd3441810b2033ededf29">ANEURALNETWORKS_ELU</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Elu">Elu</a></p></li>
</ul>
<p><strong>Gelu</strong> - Computes the Gaussian error linear unit operation.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \frac{\mbox{in[0]}}{2} \times (1 + \text{erf} (\frac{\mbox{in[0]}}{\sqrt{2}}))\]</div>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/activations/gelu">tf.keras.activations.gelu</a></p></li>
</ul>
<p><strong>HardSigmoid</strong> - Computes the HardSigmoid function element-wise on the input.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \max(0, \min(1, \alpha \times \mbox{in[0]} + \beta))\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#hardsigmoid">HardSigmoid</a></p></li>
</ul>
<p><strong>HardSwish</strong> - Computes the HardSwish operation.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \frac{\mbox{in[0]} \times \max(0, \min(6, \mbox{in[0]} + 3))}{6}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ac88e58ac12cdd6ef3e20d7204ec6f33e">ANEURALNETWORKS_HARD_SWISH</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://github.com/tensorflow/models/blob/master/official/modeling/activations/swish.py">hard_swish</a></p></li>
</ul>
<p><strong>Relu</strong> - Computes the Rectified Linear Unit operation.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \max(0, \mbox{in[0]})\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0abb2f979866b131c5089ba0caaecee656">ANEURALNETWORKS_RELU</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/relu">tf.nn.relu</a></p></li>
</ul>
<p><strong>ReluMinMax</strong> - Computes the Rectified Linear Unit Min Max operation.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \min(\text{max_value}, \max(\text{min_value}, \mbox{in[0]}))\]</div>
<p>where min_value &lt;= max_value.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a04a24c2d6f0aac4c3f5324c1d7764714">ANEURALNETWORKS_RELU6</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/relu6">tf.nn.relu6</a></p></li>
</ul>
<p><strong>Sigmoid</strong> - Computes the sigmoid activation function element-wise.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \frac{1}{1 + e^{(-1 \times \mbox{in[0]})}}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a82a340eb540933f638db420369650483">ANEURALNETWORKS_LOGISTIC</a></p></li>
</ul>
<p><strong>Softplus</strong> - Computes the softplus function to the input tensor element-wise. Note
that when <span class="math notranslate nohighlight">\((\mbox{in[0]} \times \beta)\)</span> &gt; <em>threshold</em> the implementation
reverts to a linear function to preserve numerical stability.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mbox{out[0]} = \begin{cases}
\mbox{in[0]} &amp; \text{if}\ \mbox{in[0]} \times \beta &gt; \text{threshold}, \\
\frac{1}{\beta} \times \ln{(e^{(\beta \times \mbox{in[0]})} + 1)} &amp; \text{otherwise}
\end{cases}\end{split}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Softplus">Softplus</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Softplus.html">torch.nn.Softplus</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/softplus">tf.math.softplus</a></p></li>
</ul>
<p><strong>Tanh</strong> - Computes the hyperbolic tangent function element-wise.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \tanh{(\mbox{in[0]})}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a4b63c9caab823f112d82d853a77381e5">ANEURALNETWORKS_TANH</a></p></li>
</ul>
<p>References:</p>
<ul class="simple">
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id438">
<h3>Inputs<a class="headerlink" href="#id438" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id439">
<h4>in[0]<a class="headerlink" href="#id439" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id440">
<h3>Parameters<a class="headerlink" href="#id440" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id441">
<h4>operation<a class="headerlink" href="#id441" title="Permalink to this heading">¶</a></h4>
<p>Specifies the element-wise operation to use.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>ELU = 0,</p></li>
<li><p>GELU = 1,</p></li>
<li><p>HARD_SIGMOID = 2,</p></li>
<li><p>HARD_SWISH = 3,</p></li>
<li><p>RELU = 4,</p></li>
<li><p>RELU_MIN_MAX = 5,</p></li>
<li><p>SIGMOID = 6,</p></li>
<li><p>SOFTPLUS = 7,</p></li>
<li><p>TANH = 8</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="alpha-alpha">
<h4>alpha (<span class="math notranslate nohighlight">\(\alpha\)</span>)<a class="headerlink" href="#alpha-alpha" title="Permalink to this heading">¶</a></h4>
<p>The alpha (<span class="math notranslate nohighlight">\(\alpha\)</span>) value for Elu and HardSigmoid function.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default:</p>
<blockquote>
<div><ul class="simple">
<li><p>1.0 for QNN_OP_ELEMENT_WISE_NEURON_OPERATION_ELU</p></li>
<li><p>0.2 for QNN_OP_ELEMENT_WISE_NEURON_OPERATION_HARD_SIGMOID</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Must have <em>operation</em> set to ELU or HARD_SIGMOID for this parameter to be valid.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="beta-beta">
<h4>beta (<span class="math notranslate nohighlight">\(\beta\)</span>)<a class="headerlink" href="#beta-beta" title="Permalink to this heading">¶</a></h4>
<p>The beta (<span class="math notranslate nohighlight">\(\beta\)</span>) value for HardSigmoid and Softplus functions.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default:</p>
<blockquote>
<div><ul class="simple">
<li><p>0.5 for QNN_OP_ELEMENT_WISE_NEURON_OPERATION_HARD_SIGMOID</p></li>
<li><p>1.0 for QNN_OP_ELEMENT_WISE_NEURON_OPERATION_SOFTPLUS</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Must have <em>operation</em> set to HARD_SIGMOID or SOFTPLUS for this parameter to be valid.</p></li>
<li><p>Value: beta provided for SOFTPLUS must be &gt; 0.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="min-value">
<h4>min_value<a class="headerlink" href="#min-value" title="Permalink to this heading">¶</a></h4>
<p>The minimum value in operation RELU_MIN_MAX</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: None</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Must have <em>operation</em> set to RELU_MIN_MAX for this parameter to be valid.</p></li>
<li><p>Must be provided when <em>operation</em> is set to RELU_MIN_MAX.</p></li>
<li><p>Value: min_value must be &lt;= max_value</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="max-value">
<h4>max_value<a class="headerlink" href="#max-value" title="Permalink to this heading">¶</a></h4>
<p>The maximum value in operation RELU_MIN_MAX</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: None</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Must have <em>operation</em> set to RELU_MIN_MAX for this parameter to be valid.</p></li>
<li><p>Must be provided when <em>operation</em> is set to RELU_MIN_MAX.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="threshold">
<h4>threshold<a class="headerlink" href="#threshold" title="Permalink to this heading">¶</a></h4>
<p>Values above the threshold revert to a linear function. Note that parameter is
disabled by default or when set to a negative.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: -1.0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Must have <em>operation</em> set to SOFTPLUS for this parameter to be valid.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id442">
<h3>Outputs<a class="headerlink" href="#id442" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id443">
<h4>out[0]<a class="headerlink" href="#id443" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisenot">
<span id="id444"></span><h2>ElementWiseNot<a class="headerlink" href="#elementwisenot" title="Permalink to this heading">¶</a></h2>
<p>Logical NOT of a tensor element-wise:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span>
<span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="n">otherwise</span>
</pre></div>
</div>
<p>where non-zero values are treated as true and zero as false.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0acb90aff5615d001708e9e4c6545b2b3c">ANEURALNETWORKS_LOGICAL_NOT</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id446">
<h3>Inputs<a class="headerlink" href="#id446" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id447">
<h4>in[0]<a class="headerlink" href="#id447" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id448">
<h3>Parameters<a class="headerlink" href="#id448" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id449">
<h3>Outputs<a class="headerlink" href="#id449" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id450">
<h4>out[0]<a class="headerlink" href="#id450" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisenotequal">
<span id="id451"></span><h2>ElementWiseNotEqual<a class="headerlink" href="#elementwisenotequal" title="Permalink to this heading">¶</a></h2>
<p>Computes the not equal logical operation elementwise on the input tensors.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a7b79220811dd60b3c9afaabdc6ea6842">ANEURALNETWORKS_NOT_EQUAL</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id454">
<h3>Inputs<a class="headerlink" href="#id454" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id455">
<h4>in[0]<a class="headerlink" href="#id455" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id456">
<h4>in[1]<a class="headerlink" href="#id456" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id457">
<h3>Parameters<a class="headerlink" href="#id457" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id458">
<h3>Outputs<a class="headerlink" href="#id458" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id459">
<h4>out[0]<a class="headerlink" href="#id459" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseor">
<span id="id460"></span><h2>ElementWiseOr<a class="headerlink" href="#elementwiseor" title="Permalink to this heading">¶</a></h2>
<p>Logical ORs two tensors element-wise:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>where non-zero values are treated as true and zero as false.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a132ac3197242be5700d62b0037701718">ANEURALNETWORKS_LOGICAL_OR</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id464">
<h3>Inputs<a class="headerlink" href="#id464" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id465">
<h4>in[0]<a class="headerlink" href="#id465" title="Permalink to this heading">¶</a></h4>
<p>1st input tensor</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id466">
<h4>in[1]<a class="headerlink" href="#id466" title="Permalink to this heading">¶</a></h4>
<p>2nd input tensor</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: A Tensor of rank M</p></li>
</ul>
</div>
</div>
<div class="section" id="id467">
<h3>Parameters<a class="headerlink" href="#id467" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id468">
<h3>Outputs<a class="headerlink" href="#id468" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id469">
<h4>out[0]<a class="headerlink" href="#id469" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisepower">
<span id="id470"></span><h2>ElementWisePower<a class="headerlink" href="#elementwisepower" title="Permalink to this heading">¶</a></h2>
<p>Given base and exponent in input tensors, computes the (base^exponent) element-wise.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">^</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0af04a05fbde5ec0d2e4e088750a8451ad">ANEURALNETWORKS_POW</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pow">Pow</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id475">
<h3>Inputs<a class="headerlink" href="#id475" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id476">
<h4>in[0]<a class="headerlink" href="#id476" title="Permalink to this heading">¶</a></h4>
<p>Tensor specifying the base.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id477">
<h4>in[1]<a class="headerlink" href="#id477" title="Permalink to this heading">¶</a></h4>
<p>Tensor specifying the exponent.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
</ul>
</div>
</div>
<div class="section" id="id478">
<h3>Parameters<a class="headerlink" href="#id478" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id479">
<h3>Outputs<a class="headerlink" href="#id479" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id480">
<h4>out[0]<a class="headerlink" href="#id480" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Shape: a tensor of rank = max(N,M)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseround">
<span id="id481"></span><h2>ElementWiseRound<a class="headerlink" href="#elementwiseround" title="Permalink to this heading">¶</a></h2>
<p>Computes elementwise rounding on the input.</p>
<p>The operation rounds the values in the input to the nearest integer.</p>
<p>Halfs are rounded to the nearest even integer.</p>
<p>E.g: 2.5 is rounded to 2.0; -3.5 is rounded to -4.0.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Round">Round</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/math/round">Round</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id484">
<h3>Inputs<a class="headerlink" href="#id484" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id485">
<h4>in[0]<a class="headerlink" href="#id485" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32, QNN_DATATYPE_FLOAT_16, backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id486">
<h3>Parameters<a class="headerlink" href="#id486" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id487">
<h3>Outputs<a class="headerlink" href="#id487" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id488">
<h4>out[0]<a class="headerlink" href="#id488" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisersqrt">
<span id="id489"></span><h2>ElementWiseRsqrt<a class="headerlink" href="#elementwisersqrt" title="Permalink to this heading">¶</a></h2>
<p>Computes reciprocal of the square root of the input tensor element-wise.
Negative elements are unsupported. If an element is negative, behaviour is undefined.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ac48dc0e528086e4d241d42d2923467da">ANEURALNETWORKS_RSQRT</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id491">
<h3>Inputs<a class="headerlink" href="#id491" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id492">
<h4>in[0]<a class="headerlink" href="#id492" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32, QNN_DATATYPE_FLOAT_16</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id493">
<h3>Parameters<a class="headerlink" href="#id493" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id494">
<h3>Outputs<a class="headerlink" href="#id494" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id495">
<h4>out[0]<a class="headerlink" href="#id495" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseselect">
<span id="id496"></span><h2>ElementWiseSelect<a class="headerlink" href="#elementwiseselect" title="Permalink to this heading">¶</a></h2>
<p>Given a boolean condition tensor, select value in first input tensor (if true) or
value in second input tensor (if false). Note that the three input tensors must be
either of the same shape or be able to broadcast to a common shape.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks.html#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a49b2dc37ea9219789a6d82f281499dbb">ANEURALNETWORKS_SELECT</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id499">
<h3>Inputs<a class="headerlink" href="#id499" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id500">
<h4>in[0]<a class="headerlink" href="#id500" title="Permalink to this heading">¶</a></h4>
<p>condition input</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id501">
<h4>in[1]<a class="headerlink" href="#id501" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id502">
<h4>in[2]<a class="headerlink" href="#id502" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank K</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id503">
<h3>Parameters<a class="headerlink" href="#id503" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id504">
<h3>Outputs<a class="headerlink" href="#id504" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id505">
<h4>out[0]<a class="headerlink" href="#id505" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N, M, K)</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisesign">
<span id="id506"></span><h2>ElementWiseSign<a class="headerlink" href="#elementwisesign" title="Permalink to this heading">¶</a></h2>
<p>Computes the sign of the input tensor element-wise.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mbox{out[0]} = \text{Sign}(\mbox{in[0]}) = \begin{cases}
1 &amp; \text{if}\ \mbox{in[0]} &gt; 0, \\
0 &amp; \text{if}\ \mbox{in[0]} = 0, \\
-1 &amp; \text{otherwise}
\end{cases}\end{split}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Sign">ops::Sign</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.sign.html">Sign</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/sign">Sign</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id509">
<h3>Inputs<a class="headerlink" href="#id509" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id510">
<h4>in[0]<a class="headerlink" href="#id510" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
</div>
<div class="section" id="id511">
<h3>Parameters<a class="headerlink" href="#id511" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id512">
<h3>Outputs<a class="headerlink" href="#id512" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id513">
<h4>out[0]<a class="headerlink" href="#id513" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisesin">
<span id="id514"></span><h2>ElementWiseSin<a class="headerlink" href="#elementwisesin" title="Permalink to this heading">¶</a></h2>
<p>Computes the sin of the input element-wise.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0af16ba8e2a692bce91fb53c0cd64eed11">ANEURALNETWORKS_SIN</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id516">
<h3>Inputs<a class="headerlink" href="#id516" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id517">
<h4>in[0]<a class="headerlink" href="#id517" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32, QNN_DATATYPE_FLOAT_16</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id518">
<h3>Parameters<a class="headerlink" href="#id518" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id519">
<h3>Outputs<a class="headerlink" href="#id519" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id520">
<h4>out[0]<a class="headerlink" href="#id520" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisesoftplus">
<span id="id521"></span><h2>ElementWiseSoftplus<a class="headerlink" href="#elementwisesoftplus" title="Permalink to this heading">¶</a></h2>
<p>Applies the softplus function to the input tensor element-wise to produce an output
tensor.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \frac{1}{\beta} * \ln{(e^{\beta * \mbox{in[0]}} + 1)}\]</div>
<p>Note that when in[0] * <span class="math notranslate nohighlight">\(\beta\)</span> &gt; <em>threshold</em> the implementation reverts to a
linear function to preserve numerical stability.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Softplus">ops::Softplus</a></p></li>
<li><p>Pytorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Softplus.html">Softplus</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/softplus">Softplus</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id525">
<h3>Inputs<a class="headerlink" href="#id525" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id526">
<h4>in[0]<a class="headerlink" href="#id526" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id527">
<h3>Parameters<a class="headerlink" href="#id527" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id528">
<h4>beta (<span class="math notranslate nohighlight">\(\beta\)</span>)<a class="headerlink" href="#id528" title="Permalink to this heading">¶</a></h4>
<p>The beta (<span class="math notranslate nohighlight">\(\beta\)</span>) value for the Softplus formulation.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1.0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: beta must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id529">
<h4>threshold<a class="headerlink" href="#id529" title="Permalink to this heading">¶</a></h4>
<p>Values above the threshold revert to a linear function. Note that parameter is
disabled by default or when set to a negative.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: -1.0</p></li>
</ul>
</div>
</div>
<div class="section" id="id530">
<h3>Outputs<a class="headerlink" href="#id530" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id531">
<h4>out[0]<a class="headerlink" href="#id531" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisesquareddifference">
<span id="id532"></span><h2>ElementWiseSquaredDifference<a class="headerlink" href="#elementwisesquareddifference" title="Permalink to this heading">¶</a></h2>
<p>Computes the element-wise difference between 2 tensors by subtracting the second
tensor from the first and squares the results element-wise.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/squared_difference">squared_difference</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id535">
<h3>Inputs<a class="headerlink" href="#id535" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id536">
<h4>in[0]<a class="headerlink" href="#id536" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id537">
<h4>in[1]<a class="headerlink" href="#id537" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id538">
<h3>Parameters<a class="headerlink" href="#id538" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id539">
<h3>Outputs<a class="headerlink" href="#id539" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id540">
<h4>out[0]<a class="headerlink" href="#id540" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisesquareroot">
<span id="id541"></span><h2>ElementWiseSquareRoot<a class="headerlink" href="#elementwisesquareroot" title="Permalink to this heading">¶</a></h2>
<p>Computes the square root of the input tensor element-wise.
Negative elements are unsupported. If an element is negative, behaviour is undefined.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0acf8329b28ec9fd0aa9d0e6a41aaba628">ANEURALNETWORKS_SQRT</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sqrt">Sqrt</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id543">
<h3>Inputs<a class="headerlink" href="#id543" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id544">
<h4>in[0]<a class="headerlink" href="#id544" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id545">
<h3>Parameters<a class="headerlink" href="#id545" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id546">
<h3>Outputs<a class="headerlink" href="#id546" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id547">
<h4>out[0]<a class="headerlink" href="#id547" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisesubtract">
<span id="id548"></span><h2>ElementWiseSubtract<a class="headerlink" href="#elementwisesubtract" title="Permalink to this heading">¶</a></h2>
<p>Subtract two tensors element-wise. The output is the result of subtracting second
input tensor from the first one.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a06a4248fe5ec71820ab95b87613780be">ANEURALNETWORKS_SUB</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id551">
<h3>Inputs<a class="headerlink" href="#id551" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id552">
<h4>in[0]<a class="headerlink" href="#id552" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id553">
<h4>in[1]<a class="headerlink" href="#id553" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id554">
<h3>Parameters<a class="headerlink" href="#id554" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id555">
<h3>Outputs<a class="headerlink" href="#id555" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id556">
<h4>out[0]<a class="headerlink" href="#id556" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwiseunary">
<span id="id557"></span><h2>ElementWiseUnary<a class="headerlink" href="#elementwiseunary" title="Permalink to this heading">¶</a></h2>
<p>Computes the specified unary <em>operation</em> on the input element-wise. Note that
operations can be classified as being Numerical or Logical.</p>
<p>Available element-wise operations:</p>
<p><strong>ABS</strong> - Computes the absolute value element-wise.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \lvert \mbox{in[0]} \rvert\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a8ecc424dd6710f89683edaf12ce38e39">ANEURALNETWORKS_ABS</a></p></li>
</ul>
<p><strong>ASIN</strong> - Computes the arcsine element-wise. Note that if elements are outside the
range [-1, 1] behavior is undefined.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \arcsin{(\mbox{in[0]})}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Asin">Asin</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.asin.html#torch.asin">torch.asin</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/asin">tf.math.asin</a></p></li>
</ul>
<p><strong>ATAN</strong> - Computes the arctangent element-wise.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \arctan{(\mbox{in[0]})}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Atan">Atan</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/atan">tf.math.atan</a></p></li>
</ul>
<p><strong>CEIL</strong> - Applies ceil() on the input element-wise. E.g. ceil([-1.5, 1.2, 2.0])
will output [-1.0, 2.0, 2.0].</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \text{ceil}(\mbox{in[0]})\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Ceil">Ceil</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/math/ceil">tf.math.ceil</a></p></li>
</ul>
<p><strong>COS</strong> - Computes the cosine of the input element-wise.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \cos{(\mbox{in[0]})}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/cos">tf.math.cos</a></p></li>
</ul>
<p><strong>EXP</strong> - Computes the exponential of the input element-wise.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = e^{(\mbox{in[0]})}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a32bd40860ff7c3d91f5e62980bb52bc2">ANEURALNETWORKS_EXP</a></p></li>
</ul>
<p><strong>FLOOR</strong> - Applies floor() on the input element-wise. E.g. floor([-1.5, 1.2, 2.0])
will output [-2.0, 1.0, 2.0].</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \text{floor}(\mbox{in[0]})\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0acdb4a57160153118dc6f87af0e4eccc5">ANEURALNETWORKS_FLOOR</a></p></li>
</ul>
<p><strong>LOG</strong> - Computes the logarithm of the input element-wise. Note that if an element
is 0 behavior is undefined.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \log{(\mbox{in[0]})}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ad22137e675fafa6d72da7b52952cfb78">ANEURALNETWORKS_LOG</a></p></li>
</ul>
<p><strong>NEG</strong> - Computes the numerical negative of the input element-wise.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = -1 \times \mbox{in[0]}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a3418665f9871dca43e3cb2efcac3990b">ANEURALNETWORKS_NEG</a></p></li>
</ul>
<p><strong>NOT</strong> - Applies logical NOT on the input element-wise.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mbox{out[0]} = \text{Not}(\mbox{in[0]}) = \begin{cases}
1 &amp; \text{if}\ \mbox{in[0]} = 0, \\
0 &amp; \text{otherwise.}
\end{cases}\end{split}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0acb90aff5615d001708e9e4c6545b2b3c">ANEURALNETWORKS_LOGICAL_NOT</a></p></li>
</ul>
<p><strong>RECIPROCAL</strong> - Computes the reciprocal of the input element-wise. Note that if an
element is 0 behavior is undefined.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \frac{1}{\mbox{in[0]}}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Reciprocal">Reciprocal</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.reciprocal.html">torch.reciprocal</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/reciprocal">tf.math.reciprocal</a></p></li>
</ul>
<p><strong>ROUND</strong> - Rounds to the nearest integer element-wise. Note that elements at
halves are rounded to the nearest even number. E.g. round([2.5, -4.5, 1.5]) will
output [2.0, -4.0, 2.0].</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \text{round}(\mbox{in[0]})\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Round">Round</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/math/round">tf.math.round</a></p></li>
</ul>
<p><strong>RSQRT</strong> - Computes the reciprocal of the square root element-wise. Negative
elements are unsupported. If an element is negative or 0, behavior is undefined.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \frac{1}{\sqrt{\mbox{in[0]}}}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ac48dc0e528086e4d241d42d2923467da">ANEURALNETWORKS_RSQRT</a></p></li>
</ul>
<p><strong>SIGN</strong> - Computes the sign of the input element-wise.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mbox{out[0]} = \text{sign}(\mbox{in[0]}) = \begin{cases}
1 &amp; \text{if}\ \mbox{in[0]} &gt; 0, \\
0 &amp; \text{if}\ \mbox{in[0]} = 0, \\
-1 &amp; \text{otherwise.}
\end{cases}\end{split}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Sign">Sign</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.sign.html">torch.sign</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/sign">tf.math.sign</a></p></li>
</ul>
<p><strong>SIN</strong> - Computes the sine of the input element-wise.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \sin{(\mbox{in[0]})}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0af16ba8e2a692bce91fb53c0cd64eed11">ANEURALNETWORKS_SIN</a></p></li>
</ul>
<p><strong>SQRT</strong> - Computes the square root of the input element-wise. Negative elements are
unsupported. If an element is negative, behavior is undefined.</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \sqrt{\mbox{in[0]}}\]</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetWorks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0acf8329b28ec9fd0aa9d0e6a41aaba628">ANEURALNETWORKS_SQRT</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Sqrt">Sqrt</a></p></li>
</ul>
<p>References:</p>
<ul class="simple">
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
</ul>
<div class="section" id="id575">
<h3>Inputs<a class="headerlink" href="#id575" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id576">
<h4>in[0]<a class="headerlink" href="#id576" title="Permalink to this heading">¶</a></h4>
<p>Note that the data type supported depends on the classification of the
<em>operation</em> selected and can be categorized into one of the following:</p>
<ul class="simple">
<li><p>Numerical: BACKEND_SPECIFIC</p></li>
<li><p>Logical: BACKEND_SPECIFIC, QNN_DATATYPE_BOOL_8</p></li>
</ul>
<p>See <em>operation</em> parameter for classification per operation.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id577">
<h3>Parameters<a class="headerlink" href="#id577" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id578">
<h4>operation<a class="headerlink" href="#id578" title="Permalink to this heading">¶</a></h4>
<p>Specifies the unary element-wise operation to use.</p>
<p>Operations can be classified as one of the following:</p>
<ul class="simple">
<li><p>Numerical operations: ABS, ASIN, ATAN, CEIL, COS, EXP, FLOOR, LOG, NEG, RECIPROCAL, ROUND, RSQRT, SIGN, SIN, and SQRT.</p></li>
<li><p>Logical operations: NOT.</p></li>
</ul>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>ABS = 0,</p></li>
<li><p>ASIN = 1,</p></li>
<li><p>ATAN = 2,</p></li>
<li><p>CEIL = 3,</p></li>
<li><p>COS = 4,</p></li>
<li><p>EXP = 5,</p></li>
<li><p>FLOOR = 6,</p></li>
<li><p>LOG = 7,</p></li>
<li><p>NEG = 8,</p></li>
<li><p>NOT = 9,</p></li>
<li><p>RECIPROCAL = 10,</p></li>
<li><p>ROUND = 11,</p></li>
<li><p>RSQRT = 12,</p></li>
<li><p>SIGN = 13,</p></li>
<li><p>SIN = 14,</p></li>
<li><p>SQRT = 15</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id579">
<h3>Outputs<a class="headerlink" href="#id579" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id580">
<h4>out[0]<a class="headerlink" href="#id580" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="elementwisexor">
<span id="id581"></span><h2>ElementWiseXor<a class="headerlink" href="#elementwisexor" title="Permalink to this heading">¶</a></h2>
<p>Logical XOR operation elementwise on two input tensors:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">^</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>where non-zero values are treated as true and zero as false.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Xor">Xor</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.asin.html#torch.logical_xor">torch.logical_xor</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/logical_xor">tf.math.logical_xor</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">ElementwiseRules</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#rank-matching-rules">RankMatchingRules</a></p></li>
</ul>
<div class="section" id="id587">
<h3>Inputs<a class="headerlink" href="#id587" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id588">
<h4>in[0]<a class="headerlink" href="#id588" title="Permalink to this heading">¶</a></h4>
<p>1st input tensor</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
</ul>
</div>
<div class="section" id="id589">
<h4>in[1]<a class="headerlink" href="#id589" title="Permalink to this heading">¶</a></h4>
<p>2nd input tensor</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: A Tensor of rank M</p></li>
</ul>
</div>
</div>
<div class="section" id="id590">
<h3>Parameters<a class="headerlink" href="#id590" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id591">
<h3>Outputs<a class="headerlink" href="#id591" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id592">
<h4>out[0]<a class="headerlink" href="#id592" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8, backend specific</p></li>
<li><p>Shape: a tensor of rank = max(N,M)</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="id593">
<span id="id594"></span><h2>Elu<a class="headerlink" href="#id593" title="Permalink to this heading">¶</a></h2>
<p>The Exponential Linear Unit operation computes:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="o">=</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">input</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">input</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a043a2da1768dd3441810b2033ededf29">ANEURALNETWORKS_ELU</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Elu">ops::Elu</a></p></li>
</ul>
<div class="section" id="id596">
<h3>Inputs<a class="headerlink" href="#id596" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id597">
<h4>in[0]<a class="headerlink" href="#id597" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id598">
<h3>Parameters<a class="headerlink" href="#id598" title="Permalink to this heading">¶</a></h3>
<div class="section" id="alpha">
<h4>alpha<a class="headerlink" href="#alpha" title="Permalink to this heading">¶</a></h4>
<p>Alpha parameter</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1.0</p></li>
</ul>
</div>
</div>
<div class="section" id="id599">
<h3>Outputs<a class="headerlink" href="#id599" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id600">
<h4>out[0]<a class="headerlink" href="#id600" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="expanddims">
<span id="id601"></span><h2>ExpandDims<a class="headerlink" href="#expanddims" title="Permalink to this heading">¶</a></h2>
<p>This operation inserts a dimension of size 1 at the dimension index <em>axis</em> of
<em>in[0]</em> tensor. The number of elements in output tensor remains the same as in
input tensor. This functionality can also be achieved using the <a class="reference internal" href="#reshape">Reshape</a> operation.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a2ac3c3daa1904f202589bef8c1c1860a">ANEURALNETWORKS_EXPAND_DIMS</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/expand_dims">expand_dims</a></p></li>
</ul>
<div class="section" id="id602">
<h3>Inputs<a class="headerlink" href="#id602" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id603">
<h4>in[0]<a class="headerlink" href="#id603" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank N &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id604">
<h3>Parameters<a class="headerlink" href="#id604" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id605">
<h4>axis<a class="headerlink" href="#id605" title="Permalink to this heading">¶</a></h4>
<p>Dimension index, starts at 0.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
</div>
<div class="section" id="id606">
<h3>Outputs<a class="headerlink" href="#id606" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id607">
<h4>out[0]<a class="headerlink" href="#id607" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = rank(in[0]) + 1</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="extractglimpse">
<span id="id608"></span><h2>ExtractGlimpse<a class="headerlink" href="#extractglimpse" title="Permalink to this heading">¶</a></h2>
<p>Extracts a set of windows called glimpses from the input tensor. If the window only
partially overlaps the input, the non-overlapping areas will be filled with noise.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/image/extract_glimpse">ops::ExtractGlimpse</a></p></li>
</ul>
<div class="section" id="id609">
<h3>Inputs<a class="headerlink" href="#id609" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id610">
<h4>in[0]<a class="headerlink" href="#id610" title="Permalink to this heading">¶</a></h4>
<p>Input data</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height, width, channel]</p></li>
</ul>
</div>
<div class="section" id="id611">
<h4>in[1]<a class="headerlink" href="#id611" title="Permalink to this heading">¶</a></h4>
<p>Glimpse offsets</p>
<ul class="simple">
<li><p>If <em>normalized</em> and <em>centered</em>, the offsets point to the center of the glimpse. Otherwise, the offsets point to the upper-left of the glimpse.</p></li>
</ul>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, 2] each batch with format [y, x]</p></li>
</ul>
</div>
</div>
<div class="section" id="id612">
<h3>Parameters<a class="headerlink" href="#id612" title="Permalink to this heading">¶</a></h3>
<div class="section" id="size">
<h4>size<a class="headerlink" href="#size" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [2] with format [glimpse_height, glimpse_width]</p></li>
</ul>
</div>
<div class="section" id="centered">
<h4>centered<a class="headerlink" href="#centered" title="Permalink to this heading">¶</a></h4>
<p>If true, offset coordinates are relative to the center of image.
Otherwise, offset coordinates are relative to the upper-left corner of the image.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="normalized">
<h4>normalized<a class="headerlink" href="#normalized" title="Permalink to this heading">¶</a></h4>
<p>If not <em>normalized</em> and not <em>centered</em>, the <em>offsets</em> are treated as the number
of pixels from the upper-left of the image.</p>
<ul class="simple">
<li><p>(0.0,0.0) corresponds to the image upper-left corner.</p></li>
<li><p>(height - 1.0,width - 1.0) corresponds to the image bottom-right corner.</p></li>
</ul>
<p>If not <em>normalized</em> and <em>centered</em>, the <em>offsets</em> are treated as the number
of pixels from the center of the image.</p>
<ul class="simple">
<li><p>(0.0,0.0) corresponds to the image center.</p></li>
<li><p>(height / 2.0,width / 2.0) corresponds to the image bottom-right corner.</p></li>
</ul>
<p>If <em>normalized</em> and not <em>centered</em>, normalized coordinates are in the range
[0.0,1.0] and correspond to the minimum and maximum of each height and width.</p>
<ul class="simple">
<li><p>(0.0,0.0) corresponds to the image upper-left corner.</p></li>
<li><p>(0.5,0.5) corresponds to the image center.</p></li>
<li><p>and (1.0,1.0) corresponds to the image bottom-right corner.</p></li>
</ul>
<p>If <em>normalized</em> and <em>centered</em>, normalized coordinates are in the range
[-1.0,1.0] where</p>
<ul class="simple">
<li><p>(-1.0,-1.0) corresponds to the image upper-left corner.</p></li>
<li><p>(0.0,0.0) corresponds to the image center.</p></li>
<li><p>and (1.0,1.0) corresponds to the image bottom-right corner.</p></li>
</ul>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="noise">
<h4>noise<a class="headerlink" href="#noise" title="Permalink to this heading">¶</a></h4>
<p>Indicates the noise distribution.</p>
<ul class="simple">
<li><p>0: Uniform</p></li>
<li><p>1: Gaussian</p></li>
<li><p>2: Zeroes</p></li>
</ul>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>Uniform = 0,</p></li>
<li><p>Gaussian = 1,</p></li>
<li><p>Zeroes = 2</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id613">
<h3>Outputs<a class="headerlink" href="#id613" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id614">
<h4>out[0]<a class="headerlink" href="#id614" title="Permalink to this heading">¶</a></h4>
<p>Output data</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, glimpse_height, glimpse_width, channel]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="extractpatches">
<span id="id615"></span><h2>ExtractPatches<a class="headerlink" href="#extractpatches" title="Permalink to this heading">¶</a></h2>
<p>Extracts patches from the input image in[0]. Patches are of shape <em>sizes</em> and are
<em>strides</em> apart in the input image. All extracted patches are flattened and
stacked in the <em>channel_out</em> dimension of out[0].</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/image/extract_patches">ops::ExtractPatches</a></p></li>
</ul>
<div class="section" id="id616">
<h3>Inputs<a class="headerlink" href="#id616" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id617">
<h4>in[0]<a class="headerlink" href="#id617" title="Permalink to this heading">¶</a></h4>
<p>Input data</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height, width, channel_in]</p></li>
</ul>
</div>
</div>
<div class="section" id="id618">
<h3>Parameters<a class="headerlink" href="#id618" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id619">
<h4>size<a class="headerlink" href="#id619" title="Permalink to this heading">¶</a></h4>
<p>The size of the extracted patches.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] with format [height_size, width_size]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Sizes must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id620">
<h4>stride<a class="headerlink" href="#id620" title="Permalink to this heading">¶</a></h4>
<p>Determines how far the centers of two consecutive patches are in the images.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] with format [height_stride, width_stride]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Strides must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="rate">
<h4>rate<a class="headerlink" href="#rate" title="Permalink to this heading">¶</a></h4>
<p>Specifies how far two consecutive patch samples are in the input.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] with format [height_rate, width_rate]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Rates must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="padding">
<h4>padding<a class="headerlink" href="#padding" title="Permalink to this heading">¶</a></h4>
<p>When set to QNN_OP_EXTRACT_PATCHES_PADDING_VALID:
Only patches which are fully contained in the input image are included.</p>
<p>When set to QNN_OP_EXTRACT_PATCHES_PADDING_SAME:
All patches with starting points inside the input are included and areas outside
the input default to zero.</p>
<p>Note that padding has no effect on the size of each patch and only determines
how many patches are extracted.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>VALID = 0,</p></li>
<li><p>SAME = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id621">
<h3>Outputs<a class="headerlink" href="#id621" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id622">
<h4>out[0]<a class="headerlink" href="#id622" title="Permalink to this heading">¶</a></h4>
<p>Output patches : contains image patches of size height_size * width_size *
channel_in flattened in the channel_out dimension. Spatial dimensions height_out
and width_out are functions of <em>sizes</em>, <em>strides</em>, <em>rates</em>, and <em>padding</em>.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// When padding is set to QNN_OP_EXTRACT_PATCHES_PADDING_VALID</span>
<span class="n">dilated_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">rate</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">dilated_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">rate</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">dilated_height</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">dilated_width</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>

<span class="c1">// When padding is set to QNN_OP_EXTRACT_PATCHES_PADDING_SAME</span>
<span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ceil</span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ceil</span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height_out, width_out, channel_out], where channel_out = height_size * width_size * channel_in.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="fullyconnected">
<span id="id623"></span><h2>FullyConnected<a class="headerlink" href="#fullyconnected" title="Permalink to this heading">¶</a></h2>
<p>The FullyConnected operation connects the all input elements with each output
element through weights and biases. The weights tensor has shape [m, n] where n is
the number of input elements and m is the units of weights, output and optional
biases. The input activation must be reshapable to [batch, n]
(see <a class="reference internal" href="#reshape">Reshape</a> operation definition) and the operation computes mathematically:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">outputVector</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="n">inputAsVector</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">weightsMatrix</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">biasesVector</span>
</pre></div>
</div>
<p>for one batch of input, where * denotes matrix multiply operation.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0aaada7a3dbaf4676aba560c933ff610c5">ANEURALNETWORKS_FULLY_CONNECTED</a></p></li>
</ul>
<div class="section" id="id624">
<h3>Inputs<a class="headerlink" href="#id624" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id625">
<h4>in[0]<a class="headerlink" href="#id625" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [n] or Rank &gt;= 2 reshapable to [batch, n]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt;= 2</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id626">
<h4>in[1]<a class="headerlink" href="#id626" title="Permalink to this heading">¶</a></h4>
<p>weights</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [m, n]</p></li>
</ul>
</div>
<div class="section" id="id627">
<h4>in[2]<a class="headerlink" href="#id627" title="Permalink to this heading">¶</a></h4>
<p>biases</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [m]</p></li>
<li><p>Default: [0]</p></li>
</ul>
</div>
</div>
<div class="section" id="id628">
<h3>Parameters<a class="headerlink" href="#id628" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id629">
<h4>keep_dims<a class="headerlink" href="#id629" title="Permalink to this heading">¶</a></h4>
<p>If true, the rank of in[0] and out[0] will remain the same, and all but the last
dimension will be equal in shape.</p>
<p>For dimensions to be preserved, the product of the batch dimensions of in[0]
(all but the last dimension) must be equal to batch, defined by in[0] above.
This is because:</p>
<p>total # of outputs = (total # of batches) * m</p>
<p>Since the total # of outputs and m are the same regardless of <em>keep_dims</em>, the
total # of batches must remain the same as well.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id630">
<h3>Outputs<a class="headerlink" href="#id630" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id631">
<h4>out[0]<a class="headerlink" href="#id631" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: If the rank of in[0] is 1: [m]. If the rank of in[0] is &gt; 1: [batch, m], unless <em>keep_dims</em> is true, then […, m] where … is all but the last dimension of in[0]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="gather">
<span id="id632"></span><h2>Gather<a class="headerlink" href="#gather" title="Permalink to this heading">¶</a></h2>
<p>Gather input data from the specified axis and indices.</p>
<p>See Gather backend definition for supported datatypes and constraints per backend</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a4bcb358f8c49e45e386a0a75405d5763">ANEURALNETWORKS_GATHER</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Gather">ops::Gather</a></p></li>
</ul>
<div class="section" id="id633">
<h3>Inputs<a class="headerlink" href="#id633" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id634">
<h4>in[0]<a class="headerlink" href="#id634" title="Permalink to this heading">¶</a></h4>
<p>Input activation, also known as table</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank n</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id635">
<h4>in[1]<a class="headerlink" href="#id635" title="Permalink to this heading">¶</a></h4>
<p>Indices in in[0] to extract based on axis. Note that negative index values wrap
around the dimension where -1 refers to the last element, -2 refers to the
second to last element, and so on.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32, QNN_DATATYPE_UINT_32, backend specific</p></li>
<li><p>Shape: a tensor of rank k</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Indices must be in range [-in[0].dim[axis], in[0].dim[axis] - 1]</p></li>
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id636">
<h3>Parameters<a class="headerlink" href="#id636" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id637">
<h4>axis<a class="headerlink" href="#id637" title="Permalink to this heading">¶</a></h4>
<p>axis : The axis to gather.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [0, n-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id638">
<h3>Outputs<a class="headerlink" href="#id638" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id639">
<h4>out[0]<a class="headerlink" href="#id639" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = n + k - 1</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="gatherelements">
<span id="id640"></span><h2>GatherElements<a class="headerlink" href="#gatherelements" title="Permalink to this heading">¶</a></h2>
<p>Gather input data from the specified axis and indices. Note that each index value
pertains to a single value from the input data.</p>
<p>The following example demonstrates how the output is produced in a 3D case (<em>n</em> = 3):</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="p">(</span><span class="k">if</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="p">(</span><span class="k">if</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]]</span><span class="w"> </span><span class="p">(</span><span class="k">if</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherElements">ops::GatherElements</a></p></li>
</ul>
<div class="section" id="id641">
<h3>Inputs<a class="headerlink" href="#id641" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id642">
<h4>in[0]<a class="headerlink" href="#id642" title="Permalink to this heading">¶</a></h4>
<p>Input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank n</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id643">
<h4>in[1]<a class="headerlink" href="#id643" title="Permalink to this heading">¶</a></h4>
<p>Index tensor : contains indices in in[0] to extract based on axis.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32, QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: a tensor of rank n</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Indices cannot be out of range of in[0][axis].</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id644">
<h3>Parameters<a class="headerlink" href="#id644" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id645">
<h4>axis<a class="headerlink" href="#id645" title="Permalink to this heading">¶</a></h4>
<p>axis : The axis of in[0] to gather on.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [0, n-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id646">
<h3>Outputs<a class="headerlink" href="#id646" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id647">
<h4>out[0]<a class="headerlink" href="#id647" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank n</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="gathernd">
<span id="id648"></span><h2>GatherNd<a class="headerlink" href="#gathernd" title="Permalink to this heading">¶</a></h2>
<p>Gather slices of input data from the specified indices. This is similar to Gather
operation, where indices define slices into the first dimension of the input data.
In GatherNd, indices define slices into the first N dimensions of the input data,
where N = Shape(in[1])[k-1].</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherND">ops::GatherND</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/gather_nd">gather_nd</a></p></li>
</ul>
<div class="section" id="id649">
<h3>Inputs<a class="headerlink" href="#id649" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id650">
<h4>in[0]<a class="headerlink" href="#id650" title="Permalink to this heading">¶</a></h4>
<p>Input activation, also known as table</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank n</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id651">
<h4>in[1]<a class="headerlink" href="#id651" title="Permalink to this heading">¶</a></h4>
<p>Indices in in[0] to extract. Note that when Shape(in[1])[k-1] is equal to
<em>n</em>, the indices provided index the full rank of in[0] and gather scalars.
Otherwise, when Shape(in[1])[k-1] is less than <em>n</em>, the indices provided refer to
row slices of in[0] to gather.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32, QNN_DATATYPE_UINT_32, backend specific</p></li>
<li><p>Shape: a tensor of rank k</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Shape(in[1])[k-1] must be &gt; 0 and &lt;= (<em>n</em> - <em>batch_dims</em>)</p></li>
<li><p>Value: Indices cannot be out of range of in[0]</p></li>
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id652">
<h3>Parameters<a class="headerlink" href="#id652" title="Permalink to this heading">¶</a></h3>
<div class="section" id="batch-dims">
<h4>batch_dims<a class="headerlink" href="#batch-dims" title="Permalink to this heading">¶</a></h4>
<p>The number of batch dimensions. Note that gather starts indexing from dimension
in[0][batch_dims:].</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: batch_dims &lt; min(<em>n</em>, <em>k</em>)</p></li>
<li><p>Shape: Shape(in[0])[:batch_dims] must equal Shape(in[1])[:batch_dims]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id653">
<h3>Outputs<a class="headerlink" href="#id653" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id654">
<h4>out[0]<a class="headerlink" href="#id654" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank = n + k - Shape(in[1])[k-1] - <em>batch_dims</em> - 1, where <em>n</em> is the rank of in[0] and <em>k</em> is the rank of in[1].</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="gelu">
<span id="id655"></span><h2>Gelu<a class="headerlink" href="#gelu" title="Permalink to this heading">¶</a></h2>
<p>The <strong>G</strong>aussian <strong>e</strong>rror <strong>l</strong>inear <strong>u</strong>nit operation computes:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">erf</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/activations/gelu">ops::gelu</a></p></li>
</ul>
<div class="section" id="id656">
<h3>Inputs<a class="headerlink" href="#id656" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id657">
<h4>in[0]<a class="headerlink" href="#id657" title="Permalink to this heading">¶</a></h4>
<p>Input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id658">
<h3>Parameters<a class="headerlink" href="#id658" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id659">
<h3>Outputs<a class="headerlink" href="#id659" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id660">
<h4>out[0]<a class="headerlink" href="#id660" title="Permalink to this heading">¶</a></h4>
<p>Output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="generateproposals">
<span id="id661"></span><h2>GenerateProposals<a class="headerlink" href="#generateproposals" title="Permalink to this heading">¶</a></h2>
<p>Generates bounding-box proposals from an input feature-map by applying a transform
to a set of predefined bounding-box anchors. The number of proposals is then limited
by applying hard non-max suppression (NMS).</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a72484020f2c41c814de0a7bf93dbbfd4">ANEURALNETWORKS_GENERATE_PROPOSALS</a></p></li>
</ul>
<div class="section" id="id662">
<h3>Inputs<a class="headerlink" href="#id662" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id663">
<h4>in[0]<a class="headerlink" href="#id663" title="Permalink to this heading">¶</a></h4>
<p>Input feature map</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch,height,width,num_anchors]</p></li>
</ul>
</div>
<div class="section" id="id664">
<h4>in[1]<a class="headerlink" href="#id664" title="Permalink to this heading">¶</a></h4>
<p>Transform tensor. Elements can be considered 4-tuples of (dx,dy,dw,dh),
as described in the reference.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch,height,width,num_anchors*4]</p></li>
</ul>
</div>
<div class="section" id="id665">
<h4>in[2]<a class="headerlink" href="#id665" title="Permalink to this heading">¶</a></h4>
<p>Anchor tensor. Elements can be considered 4-tuples of [x1,y1,x2,y2] coordinates
in the original image.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_anchors,4]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id666">
<h4>in[3]<a class="headerlink" href="#id666" title="Permalink to this heading">¶</a></h4>
<p>Image sizes tensor. Elements should be interpreted as [image_height,image_width]
for each image in the batch.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch,2]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[2]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id667">
<h3>Parameters<a class="headerlink" href="#id667" title="Permalink to this heading">¶</a></h3>
<div class="section" id="img-size-ratio">
<h4>img_size_ratio<a class="headerlink" href="#img-size-ratio" title="Permalink to this heading">¶</a></h4>
<p>Gives the ratio between the original image and the feature map,
in the form [height_ratio, width_ratio]</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: [2] with elements [height_ratio, width_ratio]</p></li>
</ul>
</div>
<div class="section" id="min-size">
<h4>min_size<a class="headerlink" href="#min-size" title="Permalink to this heading">¶</a></h4>
<p>Sets a minimum size for boxes before applying NMS. Boxes with width or height
smaller than this value will be filtered out.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="id668">
<h4>pre_nms_limit<a class="headerlink" href="#id668" title="Permalink to this heading">¶</a></h4>
<p>Sets a maximum number of boxes before applying NMS.
The boxes with the lowest scores will be dropped to achieve this limit.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: No limit is applied</p></li>
</ul>
</div>
<div class="section" id="post-nms-limit">
<h4>post_nms_limit<a class="headerlink" href="#post-nms-limit" title="Permalink to this heading">¶</a></h4>
<p>Sets a maximum number of boxes after applying NMS.
The boxes with the lowest scores will be dropped to achieve this limit.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: No limit is applied</p></li>
</ul>
</div>
<div class="section" id="id669">
<h4>iou_threshold<a class="headerlink" href="#id669" title="Permalink to this heading">¶</a></h4>
<p>IoU threshold for the NMS operation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="bbox-xform-clip">
<h4>bbox_xform_clip<a class="headerlink" href="#bbox-xform-clip" title="Permalink to this heading">¶</a></h4>
<p>When set to true bounding box are clipped to minimum bounding box height and
width after transformation. Otherwise, no clipping is done.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">bbox_xform_clip_value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log</span><span class="p">(</span><span class="mf">1000.0</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">16.0</span><span class="p">)</span>
<span class="n">dh</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="n">dh</span><span class="p">,</span><span class="w"> </span><span class="n">bbox_xform_clip_value</span><span class="p">)</span>
<span class="n">dw</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="n">dw</span><span class="p">,</span><span class="w"> </span><span class="n">bbox_xform_clip_value</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id670">
<h3>Outputs<a class="headerlink" href="#id670" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id671">
<h4>out[0]<a class="headerlink" href="#id671" title="Permalink to this heading">¶</a></h4>
<p>Gives the score for each bounding box.
Boxes corresponding to a given input batch element are grouped contiguously.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_boxes]. Max and current dimension value for <em>num_boxes</em> may differ, and current value will be updated by the backend.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id672">
<h4>out[1]<a class="headerlink" href="#id672" title="Permalink to this heading">¶</a></h4>
<p>Gives the position for each bounding box as a 4-tuple, (x1,y1,x2,y2).
Positions in this output correspond to the position of the same box in out[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_boxes,4]. Max and current dimension value for <em>num_boxes</em> may differ, and will be updated by the backend.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[3]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id673">
<h4>out[2]<a class="headerlink" href="#id673" title="Permalink to this heading">¶</a></h4>
<p>Gives the batch index of each bounding box. Positions in this output correspond
to the position of the same box in out[0].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [num_boxes]. Max and current dimension value for <em>num_boxes</em> may differ, and will be updated by the backend.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="getsparseindices">
<span id="id674"></span><h2>GetSparseIndices<a class="headerlink" href="#getsparseindices" title="Permalink to this heading">¶</a></h2>
<p>Gets the M specified indices from a sparse tensor.</p>
<p>See the CreateSparse op definition for a description of K and partially sparse tensors and a
description of the indices tensor.</p>
<p>References:</p>
<ul class="simple">
<li><p>QNN: <a class="reference internal" href="#createsparse">CreateSparse</a></p></li>
<li><p>QNN: <a class="reference internal" href="#getsparsevalues">GetSparseValues</a></p></li>
<li><p>QNN: <a class="reference internal" href="#sparsetodense">SparseToDense</a></p></li>
</ul>
<div class="section" id="id675">
<h3>Inputs<a class="headerlink" href="#id675" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id676">
<h4>in[0]<a class="headerlink" href="#id676" title="Permalink to this heading">¶</a></h4>
<p>input</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Must be a sparse tensor.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id677">
<h3>Parameters<a class="headerlink" href="#id677" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id678">
<h3>Outputs<a class="headerlink" href="#id678" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id679">
<h4>out[0]<a class="headerlink" href="#id679" title="Permalink to this heading">¶</a></h4>
<p>indices</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32, QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [M, K] where 0 &lt; K &lt;= N. M may be dynamically sized and K is fixed.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="getsparsevalues">
<span id="id680"></span><h2>GetSparseValues<a class="headerlink" href="#getsparsevalues" title="Permalink to this heading">¶</a></h2>
<p>Gets the M specified values from a sparse tensor.</p>
<p>See the CreateSparse op definition for a description of K and partially sparse tensors and a
description of the indices tensor.</p>
<p>References:</p>
<ul class="simple">
<li><p>QNN: <a class="reference internal" href="#createsparse">CreateSparse</a></p></li>
<li><p>QNN: <a class="reference internal" href="#getsparseindices">GetSparseIndices</a></p></li>
<li><p>QNN: <a class="reference internal" href="#sparsetodense">SparseToDense</a></p></li>
</ul>
<div class="section" id="id681">
<h3>Inputs<a class="headerlink" href="#id681" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id682">
<h4>in[0]<a class="headerlink" href="#id682" title="Permalink to this heading">¶</a></h4>
<p>input</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N with shape <span class="math notranslate nohighlight">\([D_0,...,D_{N-1}]\)</span></p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Must be a sparse tensor.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id683">
<h3>Parameters<a class="headerlink" href="#id683" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id684">
<h3>Outputs<a class="headerlink" href="#id684" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id685">
<h4>out[0]<a class="headerlink" href="#id685" title="Permalink to this heading">¶</a></h4>
<p>values</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N-K+1 with shape <span class="math notranslate nohighlight">\([M,D_{K},...,D_{N-1}]\)</span></p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="gridsample">
<span id="id686"></span><h2>GridSample<a class="headerlink" href="#gridsample" title="Permalink to this heading">¶</a></h2>
<p>Computes the output using input values and pixel locations from <em>grid</em>. For each
output location the <em>grid</em> specifies input pixel locations x and y for 4D case and
x, y, and z for 5D case, which are used to interpolate the output value.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#GridSample">GridSample</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.grid_sample.html">GridSample</a></p></li>
</ul>
<div class="section" id="id689">
<h3>Inputs<a class="headerlink" href="#id689" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id690">
<h4>in[0]<a class="headerlink" href="#id690" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D of shape: [batch, height, width, channel] or 5D of shape: [batch, depth, height, width, channel]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank(in[0]) must equal 4 or 5</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id691">
<h4>in[1]<a class="headerlink" href="#id691" title="Permalink to this heading">¶</a></h4>
<p>Grid : specifies the sampling pixel location normalized by the spatial
dimensions of in[0]. Therefore, most values should be in the range of [-1, 1].
For example, values x = -1, y = -1 is the left-top pixel of in[0] and x = 1, y =
1 is the right-bottom pixel of in[0]. Note if values are outside the range [-1,
1] then the corresponding outputs will be handled using the method specified by
<em>padding_mode</em>.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D of shape: [batch, height_out, width_out, 2] or 5D of shape: [batch, depth_out, height_out, width_out, 3]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same rank as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id692">
<h3>Parameters<a class="headerlink" href="#id692" title="Permalink to this heading">¶</a></h3>
<div class="section" id="align-corners">
<h4>align_corners<a class="headerlink" href="#align-corners" title="Permalink to this heading">¶</a></h4>
<p>If true, the maximum and minimum (1 and -1) are considered as referring to the
center points of in[0] corner pixels. Otherwise, the maximum and minimum refer
to the corner points of in[0] corner pixels. Note that pixels of in[0] are
considered as squares rather than points.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="id693">
<h4>mode<a class="headerlink" href="#id693" title="Permalink to this heading">¶</a></h4>
<p>Determines the interpolation method. Supported values are 0: BILINEAR, 1:
NEAREST. Note when inputs are 5D and <em>mode</em> is set to
QNN_OP_GRID_SAMPLE_MODE_BILINEAR the interpolation mode used internally will be
trilinear.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>BILINEAR = 0,</p></li>
<li><p>NEAREST = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="padding-mode">
<h4>padding_mode<a class="headerlink" href="#padding-mode" title="Permalink to this heading">¶</a></h4>
<p>Determines how the outputs are handled when <em>grid</em> has values outside the range
[-1 ,1].</p>
<p>When padding_mode == QNN_OP_GRID_SAMPLE_PADDING_MODE_ZEROS: use 0 for
out-of-bound grid locations.</p>
<p>When padding_mode == QNN_OP_GRID_SAMPLE_PADDING_MODE_BORDER: use border values
for out-of-bound grid locations.</p>
<p>When padding_mode == QNN_OP_GRID_SAMPLE_PADDING_MODE_REFLECTION: use values
reflected by the border for out-of-bound locations. Note for locations far away
from the border, it will keep reflecting until the location is in bounds of
[-1, 1]. For example, given a pixel location x = -3.5 this will be reflected by
the border at -1 and now becomes x’ = 1.5. Now this new pixel location will be
reflected by the border at 1 and becomes x’’ = 0.5.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>ZEROS = 0,</p></li>
<li><p>BORDER = 1,</p></li>
<li><p>REFLECTION = 2</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id694">
<h3>Outputs<a class="headerlink" href="#id694" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id695">
<h4>out[0]<a class="headerlink" href="#id695" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D of shape: [batch, height_out, width_out, channel] or 5D of shape: [batch, depth_out, height_out, width_out, channel]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same rank as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="groupnorm">
<span id="id696"></span><h2>GroupNorm<a class="headerlink" href="#groupnorm" title="Permalink to this heading">¶</a></h2>
<p>Applies group normalization to the input tensor. The operation divides the channels
into groups and computes within each group the mean (<span class="math notranslate nohighlight">\(\mu\)</span>) and variance
(<span class="math notranslate nohighlight">\(\sigma\)</span>) for normalization.</p>
<p>The values in the output tensor are computed as</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]}[b,h,w,c] = \frac{(\mbox{in[0]}[b,h,w,c] - \mu)}{\sqrt{\sigma^2 + \epsilon}} *
\gamma + \beta\]</div>
<p>where gamma (<span class="math notranslate nohighlight">\(\gamma\)</span>), beta (<span class="math notranslate nohighlight">\(\beta\)</span>) and epsilon (<span class="math notranslate nohighlight">\(\epsilon\)</span>) are
parameters.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#GroupNormalization">GroupNormalization</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html#torch.nn.GroupNorm">torch.nn.GroupNorm</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/GroupNormalization">tf.keras.layers.GroupNormalization</a></p></li>
</ul>
<div class="section" id="id697">
<h3>Inputs<a class="headerlink" href="#id697" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id698">
<h4>in[0]<a class="headerlink" href="#id698" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N, note that the last dimension in the input is the channel i.e. […, channel].</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
<li><p>Shape: channel must be evenly divisible by group</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id699">
<h4>in[1]<a class="headerlink" href="#id699" title="Permalink to this heading">¶</a></h4>
<p>gamma (<span class="math notranslate nohighlight">\(\gamma\)</span>)</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [channel]</p></li>
<li><p>Default: [1, Ellipsis, 1]</p></li>
</ul>
</div>
<div class="section" id="id700">
<h4>in[2]<a class="headerlink" href="#id700" title="Permalink to this heading">¶</a></h4>
<p>beta (<span class="math notranslate nohighlight">\(\beta\)</span>)</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [channel]</p></li>
<li><p>Default: [0, Ellipsis, 0]</p></li>
</ul>
</div>
</div>
<div class="section" id="id701">
<h3>Parameters<a class="headerlink" href="#id701" title="Permalink to this heading">¶</a></h3>
<div class="section" id="epsilon-epsilon">
<h4>epsilon (<span class="math notranslate nohighlight">\(\epsilon\)</span>)<a class="headerlink" href="#epsilon-epsilon" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="id702">
<h4>group<a class="headerlink" href="#id702" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
</div>
<div class="section" id="id703">
<h3>Outputs<a class="headerlink" href="#id703" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id704">
<h4>out[0]<a class="headerlink" href="#id704" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="gru">
<span id="id705"></span><h2>Gru<a class="headerlink" href="#gru" title="Permalink to this heading">¶</a></h2>
<p>Performs a single Gated Recurrent Unit (GRU) layer.</p>
<p>The GRU operation is described by the following equations:</p>
<div class="math notranslate nohighlight">
\[\begin{split}{\Large r_{t}} &amp;= {\Large \sigma(W_{xr} x_{t} + W_{hr} h_{t-1} + b_{xr} + b_{hr})} \\ \\
{\Large z_{t}} &amp;= {\Large \sigma(W_{xz} x_{t} + W_{hz} h_{t-1} + b_{xz} + b_{hz})} \\ \\
{\Large n_{t}} &amp;= \begin{cases}
{\Large \phi(W_{xn} x_{t} + (r_{t} \odot h_{t-1}) W_{hn} + b_{xn} + b_{hn})} &amp; {\Large \text{if linear_before_reset = 0;}}, \\ \\
{\Large \phi(W_{xn} x_{t} + (r_{t} \odot (W_{hn} h_{t-1} + b_{hn})) + b_{xn})} &amp; {\Large \text{otherwise.}} \\
\end{cases} \\ \\
{\Large h_{t}} &amp;= {\Large (1 - z_{t}) \odot n_{t} + z_{t} \odot h_{t-1}} \\ \\\end{split}\]</div>
<p>where</p>
<p><span class="math notranslate nohighlight">\(x_{t}\)</span> is the input,</p>
<p><span class="math notranslate nohighlight">\(r_{t}\)</span> is the reset gate,</p>
<p><span class="math notranslate nohighlight">\(z_{t}\)</span> is the update gate,</p>
<p><span class="math notranslate nohighlight">\(n_{t}\)</span> is the new gate,</p>
<p><span class="math notranslate nohighlight">\(h_{t}\)</span> is the output state,</p>
<p><span class="math notranslate nohighlight">\(\sigma\)</span> is the logistic sigmoid function,</p>
<p><span class="math notranslate nohighlight">\(\phi\)</span> is the tanh activation function,</p>
<p><span class="math notranslate nohighlight">\(\odot\)</span> is the element-wise product of two vectors.</p>
<p><span class="math notranslate nohighlight">\(W_{xr}\)</span> is the input-to-reset weight matrix,</p>
<p><span class="math notranslate nohighlight">\(W_{hr}\)</span> is the recurrent-to-reset weight matrix,</p>
<p><span class="math notranslate nohighlight">\(b_{xr}\)</span> is the input-reset gate bias,</p>
<p><span class="math notranslate nohighlight">\(b_{hr}\)</span> is the recurrent-reset gate bias,</p>
<p><span class="math notranslate nohighlight">\(W_{xz}\)</span> is the input-to-update weight matrix,</p>
<p><span class="math notranslate nohighlight">\(W_{hz}\)</span> is the recurrent-to-update weight matrix,</p>
<p><span class="math notranslate nohighlight">\(b_{xz}\)</span> is the input-update gate bias,</p>
<p><span class="math notranslate nohighlight">\(b_{hz}\)</span> is the recurrent-update gate bias,</p>
<p><span class="math notranslate nohighlight">\(W_{xn}\)</span> is the input-to-new weight matrix,</p>
<p><span class="math notranslate nohighlight">\(W_{hn}\)</span> is the recurrent-to-new weight matrix,</p>
<p><span class="math notranslate nohighlight">\(b_{xn}\)</span> is the input-new gate bias,</p>
<p><span class="math notranslate nohighlight">\(b_{hn}\)</span> is the recurrent-new gate bias.</p>
<p>The output state is maintained internal to the operation across multiple time-steps
and inferences. This internal state can be reset at each inference by reading from
in[13]. The decision whether or not to reset the internal state is made based on the
value of the reset signal in[14]. If the value of this input is non-zero the internal
state is reset from the output state input, or set to all zero values if the optional
state input is not connected.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#GRU">ops::GRU</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html">GRU</a></p></li>
</ul>
<div class="section" id="id707">
<h3>Inputs<a class="headerlink" href="#id707" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id708">
<h4>in[0]<a class="headerlink" href="#id708" title="Permalink to this heading">¶</a></h4>
<p>X : The input <span class="math notranslate nohighlight">\(x_{t}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 3D of shape [seq_length, batch_size, input_size] if time_major equals true or 3D of shape [batch_size, seq_length, input_size] if time_major equals false.</p></li>
</ul>
</div>
<div class="section" id="id709">
<h4>in[1]<a class="headerlink" href="#id709" title="Permalink to this heading">¶</a></h4>
<p>input-to-update weights <span class="math notranslate nohighlight">\(W_{xz}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [hidden_size, input_size]</p></li>
</ul>
</div>
<div class="section" id="id710">
<h4>in[2]<a class="headerlink" href="#id710" title="Permalink to this heading">¶</a></h4>
<p>input-to-reset weights <span class="math notranslate nohighlight">\(W_{xr}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [hidden_size, input_size]</p></li>
</ul>
</div>
<div class="section" id="id711">
<h4>in[3]<a class="headerlink" href="#id711" title="Permalink to this heading">¶</a></h4>
<p>input-to-new weights <span class="math notranslate nohighlight">\(W_{xn}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [hidden_size, input_size]</p></li>
</ul>
</div>
<div class="section" id="in-4">
<h4>in[4]<a class="headerlink" href="#in-4" title="Permalink to this heading">¶</a></h4>
<p>recurrent-to-update weights <span class="math notranslate nohighlight">\(W_{hz}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [hidden_size, hidden_size]</p></li>
</ul>
</div>
<div class="section" id="id712">
<h4>in[5]<a class="headerlink" href="#id712" title="Permalink to this heading">¶</a></h4>
<p>recurrent-to-reset weights <span class="math notranslate nohighlight">\(W_{hr}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [hidden_size, hidden_size]</p></li>
</ul>
</div>
<div class="section" id="in-6">
<h4>in[6]<a class="headerlink" href="#in-6" title="Permalink to this heading">¶</a></h4>
<p>recurrent-to-new weights <span class="math notranslate nohighlight">\(W_{hn}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [hidden_size, hidden_size]</p></li>
</ul>
</div>
<div class="section" id="in-7">
<h4>in[7]<a class="headerlink" href="#in-7" title="Permalink to this heading">¶</a></h4>
<p>input-to-update gate bias <span class="math notranslate nohighlight">\(b_{xz}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [hidden_size]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
<div class="section" id="in-8">
<h4>in[8]<a class="headerlink" href="#in-8" title="Permalink to this heading">¶</a></h4>
<p>input-to-reset gate bias <span class="math notranslate nohighlight">\(b_{xr}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [hidden_size]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
<div class="section" id="in-9">
<h4>in[9]<a class="headerlink" href="#in-9" title="Permalink to this heading">¶</a></h4>
<p>input-to-new gate bias <span class="math notranslate nohighlight">\(b_{xn}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [hidden_size]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
<div class="section" id="in-10">
<h4>in[10]<a class="headerlink" href="#in-10" title="Permalink to this heading">¶</a></h4>
<p>recurrent-to-update gate bias <span class="math notranslate nohighlight">\(b_{hz}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [hidden_size]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
<div class="section" id="in-11">
<h4>in[11]<a class="headerlink" href="#in-11" title="Permalink to this heading">¶</a></h4>
<p>recurrent-to-reset gate bias <span class="math notranslate nohighlight">\(b_{hr}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [hidden_size]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
<div class="section" id="in-12">
<h4>in[12]<a class="headerlink" href="#in-12" title="Permalink to this heading">¶</a></h4>
<p>recurrent-to-new gate bias <span class="math notranslate nohighlight">\(b_{hn}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [hidden_size]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
<div class="section" id="in-13">
<h4>in[13]<a class="headerlink" href="#in-13" title="Permalink to this heading">¶</a></h4>
<p>initial_h : Initial value of the output state (<span class="math notranslate nohighlight">\(h_{t}\)</span>). When not specified
it is assumed to be 0.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [1, batch_size, hidden_size]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
<div class="section" id="in-14">
<h4>in[14]<a class="headerlink" href="#in-14" title="Permalink to this heading">¶</a></h4>
<p>reset : Determines if the internal state should be reset. When set to true the
internal state is reset by the input in[13] if it is provided, otherwise it is
set to all zero values.</p>
<p>Note that reset is used to indicate the reset of the internal state at the
beginning of an inference pass across all batch elements at time-step 0.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: 0D containing scalar value</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
</div>
<div class="section" id="id713">
<h3>Parameters<a class="headerlink" href="#id713" title="Permalink to this heading">¶</a></h3>
<div class="section" id="direction">
<h4>direction<a class="headerlink" href="#direction" title="Permalink to this heading">¶</a></h4>
<p>Specifies if the RNN is 0 : FORWARD or 1 : REVERSE.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>FORWARD = 0,</p></li>
<li><p>REVERSE = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="linear-before-reset">
<h4>linear_before_reset<a class="headerlink" href="#linear-before-reset" title="Permalink to this heading">¶</a></h4>
<p>During the computation of the output from the new gate, if <em>linear_before_reset</em>
== 0 then the linear transformation is applied before multiplying by the output
of the reset gate. Otherwise, the output from the new gate is multiplied by the
output of the reset gate before applying the linear transformation.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="time-major">
<h4>time_major<a class="headerlink" href="#time-major" title="Permalink to this heading">¶</a></h4>
<p>Determines the dimension order of the 3D main input and output. When time_major
is true, the 1st dimension of in[0] and out[0] corresponds to seq_length
dimension while the 2nd dimension is batch. When time_major is false, the two
dimensions are reversed.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
</div>
<div class="section" id="id714">
<h3>Outputs<a class="headerlink" href="#id714" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id715">
<h4>out[0]<a class="headerlink" href="#id715" title="Permalink to this heading">¶</a></h4>
<p><span class="math notranslate nohighlight">\(Y\)</span> : A tensor that concatenates all the intermediate output values of the
output state (<span class="math notranslate nohighlight">\(h_{t}\)</span>).</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 3D of shape [seq_length, batch_size, hidden_size] if time_major equals true or 3D of shape [batch_size, seq_length, hidden_size] if time_major equals false.</p></li>
</ul>
</div>
<div class="section" id="id716">
<h4>out[1]<a class="headerlink" href="#id716" title="Permalink to this heading">¶</a></h4>
<p><span class="math notranslate nohighlight">\(Y_{h}\)</span> : the final output state (<span class="math notranslate nohighlight">\(h_{t}\)</span>) of the input sequence.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [1, batch_size, hidden_size]</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="hardswish">
<span id="id717"></span><h2>HardSwish<a class="headerlink" href="#hardswish" title="Permalink to this heading">¶</a></h2>
<p>The hard swish operation computes:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">3</span><span class="p">)))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">6</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ac88e58ac12cdd6ef3e20d7204ec6f33e">ANEURALNETWORKS_HARD_SWISH</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://github.com/tensorflow/models/blob/master/official/modeling/activations/swish.py">hard_swish</a></p></li>
</ul>
<div class="section" id="id720">
<h3>Inputs<a class="headerlink" href="#id720" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id721">
<h4>in[0]<a class="headerlink" href="#id721" title="Permalink to this heading">¶</a></h4>
<p>input activation.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id722">
<h3>Parameters<a class="headerlink" href="#id722" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id723">
<h3>Outputs<a class="headerlink" href="#id723" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id724">
<h4>out[0]<a class="headerlink" href="#id724" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="heatmapmaxkeypoint">
<span id="id725"></span><h2>HeatMapMaxKeyPoint<a class="headerlink" href="#heatmapmaxkeypoint" title="Permalink to this heading">¶</a></h2>
<p>Localize the maximum keypoints from heatmaps.</p>
<p>This operation approximates the accurate maximum keypoint scores and indices after
bicubic upscaling by using Taylor expansion up to the quadratic term.</p>
<p>A bounding box is represented by its upper-left corner coordinate (x1,y1) and
lower-right corner coordinate (x2,y2) in the original image. A valid bounding box
should satisfy x1 &lt;= x2 and y1 &lt;= y2.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a5ffccf92d127766a741225ff7ad6f743">ANEURALNETWORKS_HEATMAP_MAX_KEYPOINT</a></p></li>
</ul>
<div class="section" id="id726">
<h3>Inputs<a class="headerlink" href="#id726" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id727">
<h4>in[0]<a class="headerlink" href="#id727" title="Permalink to this heading">¶</a></h4>
<p>Tensor representing the heatmaps.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D represented as [num_boxes, heatmap_height, heatmap_width, num_keypoints]</p></li>
</ul>
</div>
<div class="section" id="id728">
<h4>in[1]<a class="headerlink" href="#id728" title="Permalink to this heading">¶</a></h4>
<p>Bounding boxes</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D represented as [num_boxes, 4], each with format [x1, y1, x2, y2] representing bounding-box coordinates.</p></li>
</ul>
</div>
</div>
<div class="section" id="id729">
<h3>Parameters<a class="headerlink" href="#id729" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id730">
<h3>Outputs<a class="headerlink" href="#id730" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id731">
<h4>out[0]<a class="headerlink" href="#id731" title="Permalink to this heading">¶</a></h4>
<p>Keypoint scores</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_boxes, num_keypoints]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id732">
<h4>out[1]<a class="headerlink" href="#id732" title="Permalink to this heading">¶</a></h4>
<p>Keypoint locations</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_boxes, num_keypoints, 2], the second dimension organized as [keypoint_x, keypoint_y]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="if">
<span id="id733"></span><h2>If<a class="headerlink" href="#if" title="Permalink to this heading">¶</a></h2>
<p>If conditional operation.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#if">If</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://tensorflow.org/api_docs/python/tf/cond">Cond</a></p></li>
<li><p>Caffe2: <a class="reference external" href="https://caffe2.ai/docs/operators-catalogue.html#if">If</a></p></li>
</ul>
<div class="section" id="id736">
<h3>Inputs<a class="headerlink" href="#id736" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id737">
<h4>in[0]<a class="headerlink" href="#id737" title="Permalink to this heading">¶</a></h4>
<p>Condition indicating which branch to execute.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape:</p></li>
</ul>
</div>
</div>
<div class="section" id="id738">
<h3>Parameters<a class="headerlink" href="#id738" title="Permalink to this heading">¶</a></h3>
<div class="section" id="then-graph">
<h4>then_graph<a class="headerlink" href="#then-graph" title="Permalink to this heading">¶</a></h4>
<p>Name of the subgraph to execute when the condition is true.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_STRING</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="else-graph">
<h4>else_graph<a class="headerlink" href="#else-graph" title="Permalink to this heading">¶</a></h4>
<p>Name of the subgraph to execute when the condition is false.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_STRING</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: parameter not used unless set</p></li>
</ul>
</div>
</div>
<div class="section" id="id739">
<h3>Outputs<a class="headerlink" href="#id739" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
</div>
<div class="section" id="imageprojectiontransform">
<span id="id740"></span><h2>ImageProjectionTransform<a class="headerlink" href="#imageprojectiontransform" title="Permalink to this heading">¶</a></h2>
<p>Applies a projective transform to the image.</p>
<p>This operator produces an output that is the result of transforming the input image
based on the following definition, along with necessary interpolation:</p>
<p>For a 3x3 transform matrix expressed as below:
[a0, a1, a2, b0, b1, b2, c0, c1, 1 ]</p>
<p>the operation maps the output point (x, y) to a transformed input point (x’, y’)
expressed by (x’, y’) = ((a0 x + a1 y + a2) / k, (b0 x + b1 y + b2) / k),
where k = c0 x + c1 y + 1</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/addons/api_docs/python/tfa/image/transform">Image Transform</a></p></li>
</ul>
<div class="section" id="id741">
<h3>Inputs<a class="headerlink" href="#id741" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id742">
<h4>in[0]<a class="headerlink" href="#id742" title="Permalink to this heading">¶</a></h4>
<p>Input image.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D of shape [batch,height,width,depth]</p></li>
</ul>
</div>
<div class="section" id="id743">
<h4>in[1]<a class="headerlink" href="#id743" title="Permalink to this heading">¶</a></h4>
<p>Projective transform matrix.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: containing the non-unity elements of the 3x3 matrix expressed above.</p></li>
</ul>
</div>
</div>
<div class="section" id="id744">
<h3>Parameters<a class="headerlink" href="#id744" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id745">
<h4>interpolation_mode<a class="headerlink" href="#id745" title="Permalink to this heading">¶</a></h4>
<p>Determines the interpolation method. Supported values are 0: BILINEAR,
1: NEAREST_NEIGHBOR. Default: BILINEAR</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>BILINEAR = 0,</p></li>
<li><p>NEAREST_NEIGHBOR = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id746">
<h3>Outputs<a class="headerlink" href="#id746" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id747">
<h4>out[0]<a class="headerlink" href="#id747" title="Permalink to this heading">¶</a></h4>
<p>Transformed image of the Same shape and size as input.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D of shape [batch,height,width,depth]</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="instancenorm">
<span id="id748"></span><h2>InstanceNorm<a class="headerlink" href="#instancenorm" title="Permalink to this heading">¶</a></h2>
<p>Applies instance normalization to the input tensor.</p>
<p>If mode is MU_SIGMA, region ACROSS_SPATIAL, and normalize_variance is true, values in
the output tensor are computed as</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]}[b,h,w,c] = \frac{(\mbox{in[0]}[b,h,w,c] - \mu_{b,c})*\gamma}{\sqrt{\sigma_{b,c}^2 + \epsilon}} + \beta\]</div>
<p>else if mode is MU_SIGMA, region ACROSS_SPATIAL, and normalize_variance is false,
values in the output tensor are computed as</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]}[b,h,w,c] = \mbox{in[0]}[b,h,w,c] - \mu_{b,c}\]</div>
<p>where gamma (<span class="math notranslate nohighlight">\(\gamma\)</span>), beta (<span class="math notranslate nohighlight">\(\beta\)</span>), and epsilon (<span class="math notranslate nohighlight">\(\epsilon\)</span>) are parameters and the mean (<span class="math notranslate nohighlight">\(\mu_{b,c}\)</span>) is</p>
<div class="math notranslate nohighlight">
\[\mu_{b,c} = \frac{\sum_{h,w}\mbox{in[0]}[b,h,w,c]}{HW}\]</div>
<p>where H and W are</p>
<div class="math notranslate nohighlight">
\[H = \mbox{shape}(\mbox{in[0]})[h]\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[W = \mbox{shape}(\mbox{in[0]})[w]\]</div>
<p>and the variance (<span class="math notranslate nohighlight">\(\sigma_{b,c}^2\)</span>) is</p>
<div class="math notranslate nohighlight">
\[\sigma_{b,c}^2 = \frac{\sum_{h,w}(\mbox{in[0]}[b,h,w,c] - \mu_{b,c})^2}{HW} .\]</div>
<p>If mode is RMS with region ACROSS_ALL, values in the output tensor are computed as</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]}[b,h,w,c] = \frac{\mbox{in[0]}[b,h,w,c] *\gamma}{\sqrt{\mbox{RMS}_{b}}} + \beta\]</div>
<p>where <span class="math notranslate nohighlight">\(\mbox{RMS}_{b}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\mbox{RMS}_{b} = \sum_{h,w,c}(\mbox{in[0]}[b,h,w,c])^2 + \epsilon.\]</div>
<p>If mode is RMS with region ACROSS_CHANNEL, values in the output tensor are computed as</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]}[b,h,w,c] = \frac{\mbox{in[0]}[b,h,w,c] *\gamma}{\sqrt{\mbox{RMS}_{b,h,w}}} + \beta\]</div>
<p>where <span class="math notranslate nohighlight">\(\mbox{RMS}_{b,h,w}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\mbox{RMS}_{b,h,w} = \sum_{c}(\mbox{in[0]}[b,h,w,c])^2 + \epsilon.\]</div>
<p>and gamma (<span class="math notranslate nohighlight">\(\gamma\)</span>), beta (<span class="math notranslate nohighlight">\(\beta\)</span>), and epsilon (<span class="math notranslate nohighlight">\(\epsilon\)</span>) are parameters</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a1e47d64cc1ac622e6fc515d602e1cd55">ANEURALNETWORKS_INSTANCE_NORMALIZATION</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">BroadcastingRules</a></p></li>
</ul>
<div class="section" id="id749">
<h3>Inputs<a class="headerlink" href="#id749" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id750">
<h4>in[0]<a class="headerlink" href="#id750" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: n-dimensional, note that the last dimension in the input is the channel, […, channel].</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: rank n &gt; 2</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id751">
<h4>in[1]<a class="headerlink" href="#id751" title="Permalink to this heading">¶</a></h4>
<p>gamma (<span class="math notranslate nohighlight">\(\gamma\)</span>).</p>
<p>Is applied element-wise across the channel dimension
of the mean-subtracted input activation in[0].
This op supports Unidirectional broadcasting from in[1] to in[0].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [channel]</p></li>
</ul>
</div>
<div class="section" id="id752">
<h4>in[2]<a class="headerlink" href="#id752" title="Permalink to this heading">¶</a></h4>
<p>beta (<span class="math notranslate nohighlight">\(\beta\)</span>).</p>
<p>Is applied element-wise across the channel dimension
of the normalized input activation in[0].
This op supports Unidirectional broadcasting from in[2] to in[0].</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [channel]</p></li>
<li><p>Default: [0, Ellipsis, 0]</p></li>
</ul>
</div>
</div>
<div class="section" id="id753">
<h3>Parameters<a class="headerlink" href="#id753" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id754">
<h4>epsilon (<span class="math notranslate nohighlight">\(\epsilon\)</span>)<a class="headerlink" href="#id754" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1e-12</p></li>
</ul>
</div>
<div class="section" id="id755">
<h4>mode<a class="headerlink" href="#id755" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>MU_SIGMA = 0,</p></li>
<li><p>RMS = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="normalize-variance">
<h4>normalize_variance<a class="headerlink" href="#normalize-variance" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="region">
<h4>region<a class="headerlink" href="#region" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>ACROSS_SPATIAL = 0,</p></li>
<li><p>ACROSS_CHANNEL = 1,</p></li>
<li><p>ACROSS_ALL = 2</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id756">
<h3>Outputs<a class="headerlink" href="#id756" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id757">
<h4>out[0]<a class="headerlink" href="#id757" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: n-dimensional</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="l2norm">
<span id="id758"></span><h2>L2Norm<a class="headerlink" href="#l2norm" title="Permalink to this heading">¶</a></h2>
<p>Applies an L2 normalization on a tensor along the specified axis. For a 1-D tensor
with axis = 0, this computes</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]} = \frac{\mbox{in[0]}}{\mbox{max}(||\mbox{in[0]}||_2,\epsilon)}\]</div>
<p>For in[0] with more dimensions, this independently normalizes each 1-D slice along
the dimension <em>axis</em>.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0abf295dee59560ff29d435226ec4c24bd">ANEURALNETWORKS_L2_NORMALIZATION</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/l2_normalize">L2 Normalize</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LpNormalization">LpNormalization</a></p></li>
</ul>
<div class="section" id="id759">
<h3>Inputs<a class="headerlink" href="#id759" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id760">
<h4>in[0]<a class="headerlink" href="#id760" title="Permalink to this heading">¶</a></h4>
<p>Input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: N-dimensional</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id761">
<h3>Parameters<a class="headerlink" href="#id761" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id762">
<h4>axis<a class="headerlink" href="#id762" title="Permalink to this heading">¶</a></h4>
<p>Scalar index specifying dimension along which to normalize input.
Both scalar <em>axis</em> and its tensor counterpart <em>axes</em> are optional, but
at least one of them must be provided. However, if <em>axes</em> is non-empty,
the value of <em>axis</em> is ignored.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [0,N)</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="axes">
<h4>axes<a class="headerlink" href="#axes" title="Permalink to this heading">¶</a></h4>
<p>Dimensions along which to normalize input.
Each element must be in range [0,N) and must be unique.
Both scalar <em>axis</em> and its tensor counterpart <em>axes</em> are optional, but
at least one of them must be provided. When both are specified, values
of <em>axes</em> take precedence over scalar <em>axis</em>.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: 1D of shape [M]</p></li>
<li><p>Default: {0,..,0}</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: 0 &lt; M &lt;=N</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id763">
<h4>epsilon (<span class="math notranslate nohighlight">\(\epsilon\)</span>)<a class="headerlink" href="#id763" title="Permalink to this heading">¶</a></h4>
<p>Positive valued, L2 norm lower bound.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1e-12</p></li>
</ul>
</div>
</div>
<div class="section" id="id764">
<h3>Outputs<a class="headerlink" href="#id764" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id765">
<h4>out[0]<a class="headerlink" href="#id765" title="Permalink to this heading">¶</a></h4>
<p>Normalized Output</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: N-dimensional</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="l2pool2d">
<span id="id766"></span><h2>L2Pool2d<a class="headerlink" href="#l2pool2d" title="Permalink to this heading">¶</a></h2>
<p>Performs a 2D L2-pooling on the input activation tensor. The values in the output
tensor are computed as:</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]}[b,i,j,c] = \sqrt{\sum_{di,dj}(\mbox{in[0]}[b, \mbox{stride}[0] * i + di, \mbox{stride}[1] * j + dj, c])^2}\]</div>
<p>Pooling is performed over the 2D spatial shape of the input activation tensor,
i.e. over it’s [height, width] sub-shape.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a2fb636e30d8853f9fa1a395e30660e92">ANEURALNETWORKS_L2_POOL_2D</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LpPool">LpPool</a></p></li>
</ul>
<div class="section" id="id767">
<h3>Inputs<a class="headerlink" href="#id767" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id768">
<h4>in[0]<a class="headerlink" href="#id768" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height, width, channel]</p></li>
</ul>
</div>
</div>
<div class="section" id="id769">
<h3>Parameters<a class="headerlink" href="#id769" title="Permalink to this heading">¶</a></h3>
<div class="section" id="filter-size">
<h4>filter_size<a class="headerlink" href="#filter-size" title="Permalink to this heading">¶</a></h4>
<p>Defines the pool filter size for 2D spatial axes of in[0].
Number of elements to pool from = filter_size[0] * filter_size[1]</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] : [filter_height, filter_width]</p></li>
</ul>
</div>
<div class="section" id="id770">
<h4>stride<a class="headerlink" href="#id770" title="Permalink to this heading">¶</a></h4>
<p>Defines the pool stride size for 2D spatial axes of in[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] : [height_stride, width_stride]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Strides must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id771">
<h4>pad_amount<a class="headerlink" href="#id771" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 2D spatial axes in[0].
Pad value = 0.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2,2] with format [[height_pad_before, height_pad_after], [width_pad_before, width_pad_after]]</p></li>
</ul>
</div>
</div>
<div class="section" id="id772">
<h3>Outputs<a class="headerlink" href="#id772" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id773">
<h4>out[0]<a class="headerlink" href="#id773" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<p>The output 2D spatial dimensions are functions of the filter_size, stride,
and pad_amount.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filter_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filter_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height_out, width_out, channel]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="layernorm">
<span id="id774"></span><h2>LayerNorm<a class="headerlink" href="#layernorm" title="Permalink to this heading">¶</a></h2>
<p>Applies layer normalization to the input tensor along the specified <em>axes</em>.
For a ND input tensor, with a 1D <em>axes</em> parameter of length M, the operation computes
a ND mean tensor (<span class="math notranslate nohighlight">\(\mu\)</span>) and ND variance tensor (<span class="math notranslate nohighlight">\(\sigma\)</span>) with shapes
<em>moments_shape</em> whose <em>i-th</em> dimension is given by</p>
<div class="math notranslate nohighlight">
\[\mbox{shape}(\mbox{moments_shape})[\mbox{i}] = 1\]</div>
<p>if <em>i</em> is in <em>axes</em> and</p>
<div class="math notranslate nohighlight">
\[\mbox{shape}(\mbox{moments_shape})[\mbox{i}] = \mbox{shape}(\mbox{in[0]})[\mbox{i}]\]</div>
<p>otherwise. The values in the output tensor are computed as</p>
<div class="math notranslate nohighlight">
\[\mbox{out[0]}[b,h,w,c] = \frac{(\mbox{in[0]}[b,h,w,c] - \mu) *
\gamma}{\sqrt{\sigma^2 + \epsilon}} + \beta\]</div>
<p>where gamma (<span class="math notranslate nohighlight">\(\gamma\)</span>), beta (<span class="math notranslate nohighlight">\(\beta\)</span>) and epsilon (<span class="math notranslate nohighlight">\(\epsilon\)</span>) are
parameters.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">tf.keras.layers.LayerNormalization</a></p></li>
</ul>
<div class="section" id="id775">
<h3>Inputs<a class="headerlink" href="#id775" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id776">
<h4>in[0]<a class="headerlink" href="#id776" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id777">
<h4>in[1]<a class="headerlink" href="#id777" title="Permalink to this heading">¶</a></h4>
<p>gamma (<span class="math notranslate nohighlight">\(\gamma\)</span>)</p>
<p>Is applied element-wise across the normalization axes
of the mean-subtracted input activation in[0].
This op supports Unidirectional broadcasting from in[1] to in[0].
The <em>i-th</em> dimension of gamma (<span class="math notranslate nohighlight">\(\gamma\)</span>) is given by</p>
<div class="math notranslate nohighlight">
\[\mbox{shape}(\gamma)[\mbox{i}] = \mbox{shape}(\mbox{in[0]})[\mbox{axes[i]}]\]</div>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M, M = size(axes)</p></li>
<li><p>Default: [1, Ellipsis, 1]</p></li>
</ul>
</div>
<div class="section" id="id778">
<h4>in[2]<a class="headerlink" href="#id778" title="Permalink to this heading">¶</a></h4>
<p>beta (<span class="math notranslate nohighlight">\(\beta\)</span>)</p>
<p>Is applied element-wise across the normalization axes
of the normalized input activation in[0].
This op supports Unidirectional broadcasting from in[2] to in[0].
The <em>i-th</em> dimension of beta (<span class="math notranslate nohighlight">\(\beta\)</span>) is given by</p>
<div class="math notranslate nohighlight">
\[\mbox{shape}(\beta)[\mbox{i}] = \mbox{shape}(\mbox{in[0]})[\mbox{axes[i]}]\]</div>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M, M = size(axes)</p></li>
<li><p>Default: [0, Ellipsis, 0]</p></li>
</ul>
</div>
</div>
<div class="section" id="id779">
<h3>Parameters<a class="headerlink" href="#id779" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id780">
<h4>epsilon (<span class="math notranslate nohighlight">\(\epsilon\)</span>)<a class="headerlink" href="#id780" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.001</p></li>
</ul>
</div>
<div class="section" id="id781">
<h4>axes<a class="headerlink" href="#id781" title="Permalink to this heading">¶</a></h4>
<p>A list of dimensions along which to normalize. Each value must be in range
[0,N-1] and must be unique.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: 1D of shape [M]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: 0 &lt; M &lt;= N</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id782">
<h3>Outputs<a class="headerlink" href="#id782" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id783">
<h4>out[0]<a class="headerlink" href="#id783" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="logsoftmax">
<span id="id784"></span><h2>LogSoftmax<a class="headerlink" href="#logsoftmax" title="Permalink to this heading">¶</a></h2>
<p>Computes the log softmax of the input activations:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">beta</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">log</span><span class="p">(</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">in</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">beta</span><span class="p">),</span><span class="w"> </span><span class="n">axis</span><span class="p">))</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a9e6c534786db67a647aeefcdafc3af0e">ANEURALNETWORKS_LOG_SOFTMAX</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/log_softmax">ops::LogSoftmax</a></p></li>
<li><p>QNN: <a class="reference internal" href="#reducesum">ReduceSum</a></p></li>
</ul>
<div class="section" id="id785">
<h3>Inputs<a class="headerlink" href="#id785" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id786">
<h4>in[0]<a class="headerlink" href="#id786" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of N dimension</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id787">
<h3>Parameters<a class="headerlink" href="#id787" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id788">
<h4>axis<a class="headerlink" href="#id788" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: must be in range [0, N-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="beta">
<h4>beta<a class="headerlink" href="#beta" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1.0</p></li>
</ul>
</div>
</div>
<div class="section" id="id789">
<h3>Outputs<a class="headerlink" href="#id789" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id790">
<h4>out[0]<a class="headerlink" href="#id790" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of N dimension</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="lrn">
<span id="id791"></span><h2>Lrn<a class="headerlink" href="#lrn" title="Permalink to this heading">¶</a></h2>
<p>Performs Local Response Normalization on input data over
the local regions defined below.</p>
<p>A square sum is computed over a region of size <em>2R + 1</em>, where <em>R</em> is the radius.
Let</p>
<div class="math notranslate nohighlight">
\[\begin{split}M_1(x) &amp;= \mbox{max}(0, x - R) \newline \\
M_2(d,x) &amp;= \mbox{min}(\mbox{shape}(\mbox{in[0]})[d], x + R). \newline \\\end{split}\]</div>
<p>Note that <em>N</em> is the rank of in[0]. For across channel LRN, the square sum, <em>S</em>,
is computed using this formula:</p>
<div class="math notranslate nohighlight">
\[S[n,...,c] = \sum_{j=M_1(c)}^{M_2(N-1,c)}(\mbox{in[0]}[n,...,j])^2.\]</div>
<p>For within channel LRN, the square sum, <em>S</em>, is computed over the spatial dimensions as</p>
<div class="math notranslate nohighlight">
\[S[n,h,w,c] = \sum_{i=M_1(h)}^{M_2(1,h)}\sum_{j=M_1(w)}^{M_2(2,w)}(\mbox{in[0]}[n,i,j,c])^2.\]</div>
<p>The output is computed using</p>
<div class="math notranslate nohighlight">
\[\mbox{out}[0] = \frac{\mbox{in}[0]}{(B + \alpha S)^\beta}.\]</div>
<p>where <em>B</em> is the bias.
Note that some frameworks scale <span class="math notranslate nohighlight">\(\alpha\)</span> based upon a given size.
The QNN definition does not scale <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p>References:</p>
<ul class="simple">
<li><p>AlexNet: <a class="reference external" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">AlexNet</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LRN">ops::LRN</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/local_response_normalization">Local Response Normalization</a></p></li>
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a876ccb0f3e6555637c5e278a7715fc05">ANEURALNETWORKS_LOCAL_RESPONSE_NORMALIZATION</a></p></li>
</ul>
<div class="section" id="id792">
<h3>Inputs<a class="headerlink" href="#id792" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id793">
<h4>in[0]<a class="headerlink" href="#id793" title="Permalink to this heading">¶</a></h4>
<p>Input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
<li><p>Shape: Rank N == 4 for within channel LRN</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id794">
<h3>Parameters<a class="headerlink" href="#id794" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id795">
<h4>alpha (<span class="math notranslate nohighlight">\(\alpha\)</span>)<a class="headerlink" href="#id795" title="Permalink to this heading">¶</a></h4>
<p>Scaling parameter</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="id796">
<h4>beta (<span class="math notranslate nohighlight">\(\beta\)</span>)<a class="headerlink" href="#id796" title="Permalink to this heading">¶</a></h4>
<p>Exponent value</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.5</p></li>
</ul>
</div>
<div class="section" id="bias">
<h4>bias<a class="headerlink" href="#bias" title="Permalink to this heading">¶</a></h4>
<p>An offset usually positive to avoid division by zero</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="radius">
<h4>radius<a class="headerlink" href="#radius" title="Permalink to this heading">¶</a></h4>
<p>Radius of the normalization window</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="id797">
<h4>region<a class="headerlink" href="#id797" title="Permalink to this heading">¶</a></h4>
<p>Set to QNN_OP_LRN_REGION_ACROSS_CHANNEL to perform across channel LRN.
Set to QNN_OP_LRN_REGION_WITHIN_CHANNEL to perform within channel LRN.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>ACROSS_CHANNEL = 0,</p></li>
<li><p>WITHIN_CHANNEL = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id798">
<h3>Outputs<a class="headerlink" href="#id798" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id799">
<h4>out[0]<a class="headerlink" href="#id799" title="Permalink to this heading">¶</a></h4>
<p>Normalized Output</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="lstm">
<span id="id800"></span><h2>Lstm<a class="headerlink" href="#lstm" title="Permalink to this heading">¶</a></h2>
<p>Performs one or more time steps in a Long Short-Term Memory (LSTM) layer.</p>
<p>The LSTM operation is described by the following equations:</p>
<div class="math notranslate nohighlight">
\[\begin{split}{\Large i_{t}} &amp;= {\Large \sigma_(W_{xi}x_{t}+W_{hi}h_{t-1}+W_{ci}C_{t-1}+b_i)} \\ \\
{\Large f_{t}} &amp;= {\Large \sigma_(W_{xf}x_{t}+W_{hf}h_{t-1}+W_{cf}C_{t-1}+b_f)} \\ \\
{\Large C_{t}} &amp;= {\Large clip(f_{t} \odot C_{t-1} + i_{t} \odot \phi(W_{xc}x_{t}+W_{hc}h_{t-1}+b_c),\ t_{cell})} \\ \\
{\Large o_{t}} &amp;= {\Large \sigma_(W_{xo}x_{t}+W_{ho}h_{t-1}+W_{co}C_{t}+b_o)} \\ \\
{\Large h_{t}} &amp;= \begin{cases}
{\Large clip(W_{proj}(o_t \odot \phi(C_t))+b_{proj},\ t_{proj})} &amp; {\Large \text{if there is a projection;}} \\ \\
{\Large o_{t} \odot \phi(C_{t})} &amp; {\Large \text{otherwise.}} \\
\end{cases} \\ \\\end{split}\]</div>
<p>where</p>
<p><span class="math notranslate nohighlight">\(x_{t}\)</span> is the input,</p>
<p><span class="math notranslate nohighlight">\(i_{t}\)</span> is the input gate,</p>
<p><span class="math notranslate nohighlight">\(f_{t}\)</span> is the forget gate,</p>
<p><span class="math notranslate nohighlight">\(C_{t}\)</span> is the cell state,</p>
<p><span class="math notranslate nohighlight">\(o_{t}\)</span> is the output gate,</p>
<p><span class="math notranslate nohighlight">\(h_{t}\)</span> is the output state,</p>
<p><span class="math notranslate nohighlight">\(\sigma\)</span> is the logistic sigmoid function,</p>
<p><span class="math notranslate nohighlight">\(\phi\)</span> is the tanh activation function,</p>
<p><span class="math notranslate nohighlight">\(W_{xi}\)</span> is the input-to-input weight matrix,</p>
<p><span class="math notranslate nohighlight">\(W_{hi}\)</span> is the recurrent-to-input weight matrix,</p>
<p><span class="math notranslate nohighlight">\(W_{ci}\)</span> is the cell-to-input weight matrix,</p>
<p><span class="math notranslate nohighlight">\(b_i\)</span> is the input gate bias,</p>
<p><span class="math notranslate nohighlight">\(W_{xf}\)</span> is the input-to-forget weight matrix,</p>
<p><span class="math notranslate nohighlight">\(W_{hf}\)</span> is the recurrent-to-forget weight matrix,</p>
<p><span class="math notranslate nohighlight">\(W_{cf}\)</span> is the cell-to-forget weight matrix,</p>
<p><span class="math notranslate nohighlight">\(b_f\)</span> is the forget gate bias,</p>
<p><span class="math notranslate nohighlight">\(W_{xc}\)</span> is the input-to-cell weight matrix,</p>
<p><span class="math notranslate nohighlight">\(W_{hc}\)</span> is the recurrent-to-cell weight matrix,</p>
<p><span class="math notranslate nohighlight">\(b_c\)</span> is the cell bias,</p>
<p><span class="math notranslate nohighlight">\(W_{xo}\)</span> is the input-to-output weight matrix,</p>
<p><span class="math notranslate nohighlight">\(W_{ho}\)</span> is the recurrent-to-output weight matrix,</p>
<p><span class="math notranslate nohighlight">\(W_{co}\)</span> is the cell-to-output weight matrix,</p>
<p><span class="math notranslate nohighlight">\(b_o\)</span> is the output gate bias,</p>
<p><span class="math notranslate nohighlight">\(W_{proj}\)</span> is the projection weight matrix,</p>
<p><span class="math notranslate nohighlight">\(b_{proj}\)</span> is the projection bias,</p>
<p><span class="math notranslate nohighlight">\(t_{cell}\)</span> is the threshold for clipping the cell state, and</p>
<p><span class="math notranslate nohighlight">\(t_{proj}\)</span> is the threshold for clipping the projected output.</p>
<p><span class="math notranslate nohighlight">\(\odot\)</span> is the element-wise product of two vectors.</p>
<p>The operation can be stateful or stateless depending on the dimensionality of the
<span class="math notranslate nohighlight">\(x_{t}\)</span> input. If the input is 2D, the operation is stateless and a single
time-step is executed. The initial output state and cell state are read from in[10]
and in[11] respectively.</p>
<p>If the input is 3D, the 2nd dimension represents the number of time-steps to be
executed if time_major is false. If time_major is true, then the 1st dimension of
the input represents the time-steps and the 2nd dimension is the batch dimension.
The output state and cell state are maintained internal to the operation across
multiple time-steps and inferences. These internal states can be reset at each
inference by reading from in[10] and in[11] respectively. The decision whether or
not to reset the internal state is made based on the value of the reset signal
in[24]. If the value of this input is non-zero the internal state is reset from the
state inputs, or set to all zero values if the optional state inputs are not connected.</p>
<p>The operation has the following independently optional inputs:</p>
<ul class="simple">
<li><p>The cell-to-input weights (<span class="math notranslate nohighlight">\(W_{ci}\)</span>), cell-to-forget weights (<span class="math notranslate nohighlight">\(W_{cf}\)</span>)
and cell-to-output weights (<span class="math notranslate nohighlight">\(W_{co}\)</span>) either all have values or neither of
them have values (i.e., all set to null). If they have values, the peephole
optimization is used.</p></li>
<li><p>The input-to-input weights (<span class="math notranslate nohighlight">\(W_{xi}\)</span>), recurrent-to-input weights
(<span class="math notranslate nohighlight">\(W_{hi}\)</span>) and input gate bias (<span class="math notranslate nohighlight">\(b_i\)</span>) either all have values, or none
of them have values. If they have no values, coupling of input and forget gates
(CIFG) is used, in which case the input gate (<span class="math notranslate nohighlight">\(i_{t}\)</span>) is calculated using
the following equation instead:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[{\Large i_{t} = 1 - f_{t}}\]</div>
<p>In case peephole optimization is used and CIFG is not used cell-to-input (<span class="math notranslate nohighlight">\(W_{ci}\)</span>)
weights must be present. Otherwise, the cell-to-input weights must have no value.</p>
<ul class="simple">
<li><p>The projection weights (<span class="math notranslate nohighlight">\(W_{proj}\)</span>) is required only for the recurrent
projection layer, and should otherwise have no value.</p></li>
<li><p>The projection bias (<span class="math notranslate nohighlight">\(b_{proj}\)</span>) may (but not required to) have a value if
the recurrent projection layer exists, and should otherwise have no value.</p></li>
<li><p>The four layer normalization weights either all have values or none of them have
values. Additionally, if CIFG is used, input layer normalization weights tensor is
omitted and the other layer normalization weights either all have values or none
of them have values. Layer normalization is used when the values of all the layer
normalization weights are present.</p></li>
</ul>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ad0377e8c305e596fb7f64ff896671fc5">ANEURALNETWORKS_LSTM</a></p></li>
</ul>
<div class="section" id="id801">
<h3>Inputs<a class="headerlink" href="#id801" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id802">
<h4>in[0]<a class="headerlink" href="#id802" title="Permalink to this heading">¶</a></h4>
<p>The input <span class="math notranslate nohighlight">\(x_{t}\)</span>.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [batch_size, input_size] or 3D of shape [batch_size, time_steps, input_size] if time_major equals false or 3D of shape [time_steps, batch_size, input_size] if time_major equals true.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank(in[0]) must equal 2 or 3</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id803">
<h4>in[1]<a class="headerlink" href="#id803" title="Permalink to this heading">¶</a></h4>
<p>input-to-forget weights <span class="math notranslate nohighlight">\(W_{xf}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [num_units, input_size]</p></li>
</ul>
</div>
<div class="section" id="id804">
<h4>in[2]<a class="headerlink" href="#id804" title="Permalink to this heading">¶</a></h4>
<p>input-to-cell weights <span class="math notranslate nohighlight">\(W_{xc}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [num_units, input_size]</p></li>
</ul>
</div>
<div class="section" id="id805">
<h4>in[3]<a class="headerlink" href="#id805" title="Permalink to this heading">¶</a></h4>
<p>input-to-output weights <span class="math notranslate nohighlight">\(W_{xo}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [num_units, input_size]</p></li>
</ul>
</div>
<div class="section" id="id806">
<h4>in[4]<a class="headerlink" href="#id806" title="Permalink to this heading">¶</a></h4>
<p>recurrent-to-forget weights <span class="math notranslate nohighlight">\(W_{hf}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [num_units, output_size]</p></li>
</ul>
</div>
<div class="section" id="id807">
<h4>in[5]<a class="headerlink" href="#id807" title="Permalink to this heading">¶</a></h4>
<p>recurrent-to-cell weights <span class="math notranslate nohighlight">\(W_{hc}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [num_units, output_size]</p></li>
</ul>
</div>
<div class="section" id="id808">
<h4>in[6]<a class="headerlink" href="#id808" title="Permalink to this heading">¶</a></h4>
<p>recurrent-to-output weights <span class="math notranslate nohighlight">\(W_{ho}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [num_units, output_size]</p></li>
</ul>
</div>
<div class="section" id="id809">
<h4>in[7]<a class="headerlink" href="#id809" title="Permalink to this heading">¶</a></h4>
<p>forget gate bias <span class="math notranslate nohighlight">\(b_f\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [num_units]</p></li>
</ul>
</div>
<div class="section" id="id810">
<h4>in[8]<a class="headerlink" href="#id810" title="Permalink to this heading">¶</a></h4>
<p>cell bias <span class="math notranslate nohighlight">\(b_c\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [num_units]</p></li>
</ul>
</div>
<div class="section" id="id811">
<h4>in[9]<a class="headerlink" href="#id811" title="Permalink to this heading">¶</a></h4>
<p>output gate bias <span class="math notranslate nohighlight">\(b_o\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [num_units]</p></li>
</ul>
</div>
<div class="section" id="id812">
<h4>in[10]<a class="headerlink" href="#id812" title="Permalink to this heading">¶</a></h4>
<p>output state (in) <span class="math notranslate nohighlight">\(h_{t-1}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [batch_size, output_size]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
<div class="section" id="id813">
<h4>in[11]<a class="headerlink" href="#id813" title="Permalink to this heading">¶</a></h4>
<p>cell state (in) <span class="math notranslate nohighlight">\(C_{t-1}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [batch_size, num_units]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
<div class="section" id="id814">
<h4>in[12]<a class="headerlink" href="#id814" title="Permalink to this heading">¶</a></h4>
<p>The input layer normalization weights. Used to rescale normalized inputs to
activation at input gate.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [num_units]</p></li>
</ul>
</div>
<div class="section" id="id815">
<h4>in[13]<a class="headerlink" href="#id815" title="Permalink to this heading">¶</a></h4>
<p>The forget layer normalization weights. Used to rescale normalized inputs to
activation at forget gate.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [num_units]</p></li>
</ul>
</div>
<div class="section" id="id816">
<h4>in[14]<a class="headerlink" href="#id816" title="Permalink to this heading">¶</a></h4>
<p>The cell layer normalization weights. Used to rescale normalized inputs to
activation at cell gate.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [num_units]</p></li>
</ul>
</div>
<div class="section" id="in-15">
<h4>in[15]<a class="headerlink" href="#in-15" title="Permalink to this heading">¶</a></h4>
<p>The output layer normalization weights. Used to rescale normalized inputs to
activation at output gate.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [num_units]</p></li>
</ul>
</div>
<div class="section" id="in-16">
<h4>in[16]<a class="headerlink" href="#in-16" title="Permalink to this heading">¶</a></h4>
<p>input-to-input weights <span class="math notranslate nohighlight">\(W_{xi}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [num_units, input_size], where “num_units” corresponds to the number of cell units.</p></li>
</ul>
</div>
<div class="section" id="in-17">
<h4>in[17]<a class="headerlink" href="#in-17" title="Permalink to this heading">¶</a></h4>
<p>recurrent-to-input weights <span class="math notranslate nohighlight">\(W_{hi}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [num_units, output_size] where “output_size” corresponds to either the number of cell units (i.e., “num_units”), or the first dimension of the “projection_weights”, if defined.</p></li>
</ul>
</div>
<div class="section" id="in-18">
<h4>in[18]<a class="headerlink" href="#in-18" title="Permalink to this heading">¶</a></h4>
<p>cell-to-input weights <span class="math notranslate nohighlight">\(W_{ci}\)</span>.
It is a diagonal matrix by definition, and is expressed as a 1D vector.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [num_units]</p></li>
</ul>
</div>
<div class="section" id="in-19">
<h4>in[19]<a class="headerlink" href="#in-19" title="Permalink to this heading">¶</a></h4>
<p>cell-to-forget weights <span class="math notranslate nohighlight">\(W_{cf}\)</span>.
It is a diagonal matrix by definition, and is expressed as a 1D vector.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [num_units]</p></li>
</ul>
</div>
<div class="section" id="in-20">
<h4>in[20]<a class="headerlink" href="#in-20" title="Permalink to this heading">¶</a></h4>
<p>cell-to-output weights <span class="math notranslate nohighlight">\(W_{co}\)</span>.
It is a diagonal matrix by definition, and is expressed as a 1D vector.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [num_units]</p></li>
</ul>
</div>
<div class="section" id="in-21">
<h4>in[21]<a class="headerlink" href="#in-21" title="Permalink to this heading">¶</a></h4>
<p>input gate bias <span class="math notranslate nohighlight">\(b_i\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [num_units]</p></li>
</ul>
</div>
<div class="section" id="in-22">
<h4>in[22]<a class="headerlink" href="#in-22" title="Permalink to this heading">¶</a></h4>
<p>projection weights <span class="math notranslate nohighlight">\(W_{proj}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [output_size, num_units]</p></li>
</ul>
</div>
<div class="section" id="in-23">
<h4>in[23]<a class="headerlink" href="#in-23" title="Permalink to this heading">¶</a></h4>
<p>projection bias <span class="math notranslate nohighlight">\(b_{proj}\)</span>.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 1D of shape [output_size]</p></li>
</ul>
</div>
<div class="section" id="in-24">
<h4>in[24]<a class="headerlink" href="#in-24" title="Permalink to this heading">¶</a></h4>
<p>reset : Determines if the internal state should be reset. When set to true the
internal states are reset by the inputs in[10] and in[11] if they are provided,
otherwise they are set to all zero values.</p>
<p>Note that reset is only applicable to a 3D input <span class="math notranslate nohighlight">\(x_{t}\)</span> and used to
indicate the reset of the internal states at the beginning of an inference pass
across all batch elements at time-step 0.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: 0D containing scalar value</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
</div>
<div class="section" id="id817">
<h3>Parameters<a class="headerlink" href="#id817" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id818">
<h4>direction<a class="headerlink" href="#id818" title="Permalink to this heading">¶</a></h4>
<p>The ‘direction’ of computation for the LSTM op. Used to achieve the functionality
of Bi-directional LSTM by using a combination of individual LSTM ops configured
in opposite directions.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>FORWARD = 0,</p></li>
<li><p>REVERSE = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="cell-clip-threshold">
<h4>cell_clip_threshold<a class="headerlink" href="#cell-clip-threshold" title="Permalink to this heading">¶</a></h4>
<p>The clipping threshold (<span class="math notranslate nohighlight">\(t_{cell}\)</span>) for the cell state, such that values
are bound within [-cell_clip, cell_clip]. If set to 0.0 clipping is disabled.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.0</p></li>
</ul>
</div>
<div class="section" id="output-clip-threshold">
<h4>output_clip_threshold<a class="headerlink" href="#output-clip-threshold" title="Permalink to this heading">¶</a></h4>
<p>The clipping threshold (<span class="math notranslate nohighlight">\(t_{proj}\)</span>) for the output from the projection
layer, such that values are bound within [-proj_clip, proj_clip].
If set to 0.0 clipping is disabled.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.0</p></li>
</ul>
</div>
<div class="section" id="id819">
<h4>time_major<a class="headerlink" href="#id819" title="Permalink to this heading">¶</a></h4>
<p>Determines the dimension order of the 3D main input and output. When equal to
true, the 1st dimension of in[0] and out[0] corresponds to time_step dimension
while the 2nd dimension is batch. When time_major is false, the two dimensions
are reversed.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="input-gate-qscale">
<h4>input_gate_qscale<a class="headerlink" href="#input-gate-qscale" title="Permalink to this heading">¶</a></h4>
<p>The quantization scale of the intermediate result of matrix multiplication, i.e
input to layer normalization at input gate <span class="math notranslate nohighlight">\(i_{t}\)</span>
realized by the following expression:</p>
<p><span class="math notranslate nohighlight">\((W_{xi}x_{t} + W_{hi}h_{t-1} + W_{ci}C_{t-1})\)</span></p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.0</p></li>
</ul>
</div>
<div class="section" id="forget-gate-qscale">
<h4>forget_gate_qscale<a class="headerlink" href="#forget-gate-qscale" title="Permalink to this heading">¶</a></h4>
<p>The quantization scale of the intermediate result of matrix multiplication, i.e
input to layer normalization at forget gate <span class="math notranslate nohighlight">\(f_{t}\)</span>
realized by the following expression:</p>
<p><span class="math notranslate nohighlight">\((W_{xf}x_{t} + W_{hf}h_{t-1} + W_{cf}C_{t-1})\)</span></p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.0</p></li>
</ul>
</div>
<div class="section" id="cell-gate-qscale">
<h4>cell_gate_qscale<a class="headerlink" href="#cell-gate-qscale" title="Permalink to this heading">¶</a></h4>
<p>The quantization scale of the intermediate result of matrix multiplication, i.e
input to layer normalization at cell gate <span class="math notranslate nohighlight">\(C_{t}\)</span>
realized by the following expression:</p>
<p><span class="math notranslate nohighlight">\((W_{xc}x_{t} + W_{hc}h_{t-1})\)</span></p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.0</p></li>
</ul>
</div>
<div class="section" id="output-gate-qscale">
<h4>output_gate_qscale<a class="headerlink" href="#output-gate-qscale" title="Permalink to this heading">¶</a></h4>
<p>The quantization scale of the intermediate result of matrix multiplication, i.e
input to layer normalization at output gate <span class="math notranslate nohighlight">\(o_{t}\)</span>
realized by the following expression:</p>
<p><span class="math notranslate nohighlight">\((W_{xo}x_{t} + W_{ho}h_{t-1} + W_{co}C_{t})\)</span></p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.0</p></li>
</ul>
</div>
<div class="section" id="hidden-state-offset">
<h4>hidden_state_offset<a class="headerlink" href="#hidden-state-offset" title="Permalink to this heading">¶</a></h4>
<p>The quantization offset of the hidden state <span class="math notranslate nohighlight">\(h_{t}\)</span>, i.e. input to projection
realized by the following expression:
<span class="math notranslate nohighlight">\((o_t \odot \phi(C_t))\)</span></p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.0</p></li>
</ul>
</div>
<div class="section" id="hidden-state-qscale">
<h4>hidden_state_qscale<a class="headerlink" href="#hidden-state-qscale" title="Permalink to this heading">¶</a></h4>
<p>The quantization scale of the hidden state <span class="math notranslate nohighlight">\(h_{t}\)</span>, i.e. input to projection
realized by the following expression:
<span class="math notranslate nohighlight">\((o_t \odot \phi(C_t))\)</span></p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.0</p></li>
</ul>
</div>
</div>
<div class="section" id="id820">
<h3>Outputs<a class="headerlink" href="#id820" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id821">
<h4>out[0]<a class="headerlink" href="#id821" title="Permalink to this heading">¶</a></h4>
<p>output state (out) (<span class="math notranslate nohighlight">\(h_{t}\)</span>).</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [batch_size, output_size] or 3D of shape [batch_size, time_steps, output_size] if time_major equals false, or 3D of shape [time_steps, batch_size, output_size] if time_major equals true.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same Rank as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id822">
<h4>out[1]<a class="headerlink" href="#id822" title="Permalink to this heading">¶</a></h4>
<p>cell state (out) (<span class="math notranslate nohighlight">\(C_{t}\)</span>).</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [batch_size, num_units]</p></li>
</ul>
</div>
<div class="section" id="id823">
<h4>out[2]<a class="headerlink" href="#id823" title="Permalink to this heading">¶</a></h4>
<p>output (<span class="math notranslate nohighlight">\(o_{t}\)</span>) : This is the the current “output state (out)” value. If
out[0] is 2D, it is identical to out[0]. If out[0] is 3D, it contains the values
of the final time-step.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [batch_size, output_size].</p></li>
</ul>
</div>
<div class="section" id="id824">
<h4>out[3]<a class="headerlink" href="#id824" title="Permalink to this heading">¶</a></h4>
<p>input_gate</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [batch_size, num_units].</p></li>
</ul>
</div>
<div class="section" id="id825">
<h4>out[4]<a class="headerlink" href="#id825" title="Permalink to this heading">¶</a></h4>
<p>forget_gate</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [batch_size, num_units].</p></li>
</ul>
</div>
<div class="section" id="id826">
<h4>out[5]<a class="headerlink" href="#id826" title="Permalink to this heading">¶</a></h4>
<p>cell_gate</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [batch_size, num_units].</p></li>
</ul>
</div>
<div class="section" id="id827">
<h4>out[6]<a class="headerlink" href="#id827" title="Permalink to this heading">¶</a></h4>
<p>output_gate</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [batch_size, output_size].</p></li>
</ul>
</div>
<div class="section" id="out-7">
<h4>out[7]<a class="headerlink" href="#out-7" title="Permalink to this heading">¶</a></h4>
<p>hidden_state</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [batch_size, output_size].</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="maskedsoftmax">
<span id="id828"></span><h2>MaskedSoftmax<a class="headerlink" href="#maskedsoftmax" title="Permalink to this heading">¶</a></h2>
<p>Applies a Softmax operation on masked portions of the input tensor. For each <em>batch</em>
the mask tensor is broadcast on the input before softmax computation. A mask tensor
must be provided in either an <em>UNCOMPRESSED</em> or <em>COMPRESSED</em> format depending on the
<em>mode</em> selected. See in[1] for details on how a boolean mask can be converted to an
<em>UNCOMPRESSED</em> or <em>COMPRESSED</em> mask tensor.</p>
<div class="section" id="id829">
<h3>Inputs<a class="headerlink" href="#id829" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id830">
<h4>in[0]<a class="headerlink" href="#id830" title="Permalink to this heading">¶</a></h4>
<p>Input data</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D of shape [batch, height, width, channel]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: When mode is set to COMPRESSED width == channel.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id831">
<h4>in[1]<a class="headerlink" href="#id831" title="Permalink to this heading">¶</a></h4>
<p>Mask tensor: The representation of this 2D tensor is determined by the <em>mode</em>
selected. When <em>mode</em> is set to <em>UNCOMPRESSED</em> M = channel or set to <em>COMPRESSED</em>
M = number of sequences.</p>
<p>Consider a boolean mask where a mask value of 1 indicates the dimension on which
Softmax should be performed and a mask value of 0 indicates the dimension that
Softmax will not be performed.</p>
<p>An uncompressed mask can be made from a boolean mask tensor by adding -1 or
subtracting by 1 element-wise and multiplying the intermediate result
element-wise by a large value.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">uncompressed_mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">mask</span><span class="w"> </span><span class="p">.</span><span class="o">+</span><span class="w"> </span><span class="mi">-1</span><span class="p">)</span><span class="w"> </span><span class="p">.</span><span class="o">*</span><span class="w"> </span><span class="mi">10000</span>
<span class="c1">// uncompressed_mask = [[0,0,0,-10000,0]]</span>
</pre></div>
</div>
<p>A compressed mask can be made from multiple boolean mask tensors of vector
lengths that are concatenated into a single batch and summed across the 2nd axis.</p>
<p>For Example:</p>
<p>Let there be 3 mask tensors that correspond to sequences of inputs that were
used to make in[0] where 0’s represent where padding was added to make them the
max sequence length.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">mask1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">mask2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">mask3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>The concatenated mask would then be the following:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">concatenated_mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span>
</pre></div>
</div>
<p>The compressed mask representation would be made from summing across the 2nd axis:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">compressed_mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]]</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 2D of shape [batch, M]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: When mode is set to COMPRESSED the sum of values in each batch must be &lt;= channel.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id832">
<h3>Parameters<a class="headerlink" href="#id832" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id833">
<h4>mode<a class="headerlink" href="#id833" title="Permalink to this heading">¶</a></h4>
<p>Determines the MaskedSoftmax Operation that is performed. See in[1] for details
on mask tensor format for each of the modes.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>UNCOMPRESSED = 0,</p></li>
<li><p>COMPRESSED = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id834">
<h3>Outputs<a class="headerlink" href="#id834" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id835">
<h4>out[0]<a class="headerlink" href="#id835" title="Permalink to this heading">¶</a></h4>
<p>Output Activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D of shape [batch, height, width, channel]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="matmul">
<span id="id836"></span><h2>MatMul<a class="headerlink" href="#matmul" title="Permalink to this heading">¶</a></h2>
<p>Performs a batched matrix multiplication on the innermost two dimensions of the
operands in[0] and in[1]. Batch dimensions of in[0] and in[1] will be broadcast
when possible. To be broadcast, the smaller dimension must be equal to 1, or omitted
if the ranks of the input tensors differ. Batch dimensions of out[0] must match the
batch dimensions of in[0] and in[1] after being broadcast. For example, if in[0] is
of shape [10, 256, 128] and in[1] is of shape [5, 1, 128, 64], the input batch
dimensions are [10] and [5, 1] respectively, and will be broadcast to [5, 10].
out[0] will be of shape [5, 10, 256, 64].</p>
<p>Let</p>
<div class="math notranslate nohighlight">
\[A = \mbox{in}[0], B = \mbox{in}[1], C = \mbox{out}[0], b = \mbox{in}[2].\]</div>
<p>When <span class="math notranslate nohighlight">\(\mbox{transpose_in0} = 0\)</span> and <span class="math notranslate nohighlight">\(\mbox{transpose_in1} = 0\)</span>, the operation satisfies</p>
<div class="math notranslate nohighlight">
\[C[..., i, j] = \sum^{m1}_{k=0}(A[..., i, k] * B[..., k, j] + b[j]), \forall i \in [0,m0], \forall j \in [0,n1].\]</div>
<p>When <span class="math notranslate nohighlight">\(\mbox{transpose_in0} = 0\)</span> and <span class="math notranslate nohighlight">\(\mbox{transpose_in1} = 1\)</span>, the operation satisfies</p>
<div class="math notranslate nohighlight">
\[C[..., i, j] = \sum^{m1}_{k=0}(A[..., i, k] * B[..., j, k] + b[j]), \forall i \in [0,m0], \forall j \in [0,m1].\]</div>
<p>When <span class="math notranslate nohighlight">\(\mbox{transpose_in0} = 1\)</span> and <span class="math notranslate nohighlight">\(\mbox{transpose_in1} = 0\)</span>, the operation satisfies</p>
<div class="math notranslate nohighlight">
\[C[..., i, j] = \sum^{n1}_{k=0}(A[..., k, i] * B[..., k, j] + b[j]), \forall i \in [0,n0], \forall j \in [0,n1].\]</div>
<p>When <span class="math notranslate nohighlight">\(\mbox{transpose_in0} = 1\)</span> and <span class="math notranslate nohighlight">\(\mbox{transpose_in1} = 1\)</span>, the operation satisfies</p>
<div class="math notranslate nohighlight">
\[C[..., i, j] = \sum^{n1}_{k=0}(A[..., k, i] * B[..., j, k] + b[j]), \forall i \in [0,n0], \forall j \in [0,m1].\]</div>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/batch-mat-mul-v2">BatchMatMulV2</a></p></li>
</ul>
<div class="section" id="id837">
<h3>Inputs<a class="headerlink" href="#id837" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id838">
<h4>in[0]<a class="headerlink" href="#id838" title="Permalink to this heading">¶</a></h4>
<p>Matrix operand: A</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: […, m0, n0] of rank N &gt;= 2</p></li>
</ul>
</div>
<div class="section" id="id839">
<h4>in[1]<a class="headerlink" href="#id839" title="Permalink to this heading">¶</a></h4>
<p>Matrix operand: B</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">When</span><span class="w"> </span><span class="n">transpose_in0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">transpose_in1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="o">:</span><span class="w"> </span><span class="n">m1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n0</span>
<span class="n">When</span><span class="w"> </span><span class="n">transpose_in0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">transpose_in1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="w"> </span><span class="n">n1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n0</span>
<span class="n">When</span><span class="w"> </span><span class="n">transpose_in0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">transpose_in1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="o">:</span><span class="w"> </span><span class="n">m1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">m0</span>
<span class="n">When</span><span class="w"> </span><span class="n">transpose_in0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">transpose_in1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="w"> </span><span class="n">n1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">m0</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: […, m1, n1] of rank N &gt;= 2</p></li>
</ul>
</div>
<div class="section" id="id840">
<h4>in[2]<a class="headerlink" href="#id840" title="Permalink to this heading">¶</a></h4>
<p>biases</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [n2]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
</div>
<div class="section" id="id841">
<h3>Parameters<a class="headerlink" href="#id841" title="Permalink to this heading">¶</a></h3>
<div class="section" id="transpose-in0">
<h4>transpose_in0<a class="headerlink" href="#transpose-in0" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="transpose-in1">
<h4>transpose_in1<a class="headerlink" href="#transpose-in1" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id842">
<h3>Outputs<a class="headerlink" href="#id842" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id843">
<h4>out[0]<a class="headerlink" href="#id843" title="Permalink to this heading">¶</a></h4>
<p>Matrix product: C</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">When</span><span class="w"> </span><span class="n">transpose_in0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">transpose_in1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="o">:</span><span class="w"> </span><span class="n">m2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">m0</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">n2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n1</span>
<span class="n">When</span><span class="w"> </span><span class="n">transpose_in0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">transpose_in1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="w"> </span><span class="n">m2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">m0</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">n2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">m1</span>
<span class="n">When</span><span class="w"> </span><span class="n">transpose_in0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">transpose_in1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="o">:</span><span class="w"> </span><span class="n">m2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n0</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">n2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n1</span>
<span class="n">When</span><span class="w"> </span><span class="n">transpose_in0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">transpose_in1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="w"> </span><span class="n">m2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n0</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">n2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">m1</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: […, m2, n2] of rank N &gt;= 2</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="moments">
<span id="id844"></span><h2>Moments<a class="headerlink" href="#moments" title="Permalink to this heading">¶</a></h2>
<p>Calculates the mean and variance of an input tensor.</p>
<p>See Moments backend definition for supported datatypes and constraints per backend</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/moments">ops::Moments</a></p></li>
</ul>
<div class="section" id="id845">
<h3>Inputs<a class="headerlink" href="#id845" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id846">
<h4>in[0]<a class="headerlink" href="#id846" title="Permalink to this heading">¶</a></h4>
<p>Input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: ND, of length &lt;= rank(in[0])</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: length &lt;= rank(in[0])</p></li>
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id847">
<h3>Parameters<a class="headerlink" href="#id847" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id848">
<h4>axes<a class="headerlink" href="#id848" title="Permalink to this heading">¶</a></h4>
<p>Axes along which to compute mean and variance</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: 1D. For batch normalization: Tensor of 1 element (batch only), or 3 elements for filters with shape [batch, height, width, depth] (e.g. pass axes=[0, 1, 2]).</p></li>
</ul>
</div>
<div class="section" id="id849">
<h4>keep_dims<a class="headerlink" href="#id849" title="Permalink to this heading">¶</a></h4>
<p>Produce moments with the same dimensionality as the input. Set to either
QNN_OP_MOMENTS_KEEP_DIM true or false.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
</div>
<div class="section" id="id850">
<h3>Outputs<a class="headerlink" href="#id850" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id851">
<h4>out[0]<a class="headerlink" href="#id851" title="Permalink to this heading">¶</a></h4>
<p>Mean</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: If keepdims = QNN_OP_MOMENTS_KEEP_DIMS true, specified axes dims of in[0] become 1, others are same as in[0]. For keepdims = QNN_OP_MOMENTS_KEEP_DIMS false, specified axes of in[0] are omitted and others are as in[0].</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id852">
<h4>out[1]<a class="headerlink" href="#id852" title="Permalink to this heading">¶</a></h4>
<p>Variance</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: If keepdims = QNN_OP_MOMENTS_KEEP_DIMS true, specified axes dims of in[0] become 1, others are same as in[0]. For keepdims = QNN_OP_MOMENTS_KEEP_DIMS false, specified axes of in[0] are omitted and others are as in[0]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="multiclassnms">
<span id="id853"></span><h2>MultiClassNms<a class="headerlink" href="#multiclassnms" title="Permalink to this heading">¶</a></h2>
<p>Filter bounding boxes across multiple classes in descending order of score
using Non maximum suppression.
Boxes that have a high IOU overlap with previously selected boxes are pruned.
Additionally, bounding boxes with scores less than a specific threshold are pruned.
The op also performs gather operation on any additional features corresponding to
the filtered boxes.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/non-max-suppression-v5">ops::NonMaxSuppressionV5</a></p></li>
</ul>
<div class="section" id="id854">
<h3>Inputs<a class="headerlink" href="#id854" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id855">
<h4>in[0]<a class="headerlink" href="#id855" title="Permalink to this heading">¶</a></h4>
<p>Bounding boxes. Elements can be understood as 4-tuples of bounding box
coordinates given in the form (y1,x1,y2,x2).</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, num_boxes, 4]</p></li>
</ul>
</div>
<div class="section" id="id856">
<h4>in[1]<a class="headerlink" href="#id856" title="Permalink to this heading">¶</a></h4>
<p>Bounding box scores. The element at position [<em>batch</em>, <em>box</em>, <em>class</em>]
is the score corresponding to <em>class</em> for the bounding box at the position
[<em>batch</em>, <em>box</em>] in in[0].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, num_boxes, num_classes]</p></li>
</ul>
</div>
<div class="section" id="in-2-m">
<h4>in[2..m]<a class="headerlink" href="#in-2-m" title="Permalink to this heading">¶</a></h4>
<p>Additional feature vectors where m &gt;=2. These features are also ‘filtered’
by performing ‘gather’ operations along the same indices as the filtered boxes.</p>
<p>This tensor is repeated, meaning the same definition can apply to multiple tensors.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: N-dimensional. dim[0] should match <em>batch</em>; dim[1] should match num_boxes.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Number: m &gt;= 2</p></li>
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id857">
<h3>Parameters<a class="headerlink" href="#id857" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id858">
<h4>iou_threshold<a class="headerlink" href="#id858" title="Permalink to this heading">¶</a></h4>
<p>IoU threshold for the NMS algorithm.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="id859">
<h4>score_threshold<a class="headerlink" href="#id859" title="Permalink to this heading">¶</a></h4>
<p>Boxes with scores lower than the threshold are filtered by the NMS algorithm.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.0</p></li>
</ul>
</div>
<div class="section" id="soft-nms-sigma">
<h4>soft_nms_sigma<a class="headerlink" href="#soft-nms-sigma" title="Permalink to this heading">¶</a></h4>
<p>Sigma parameter for Soft NMS. When this param is set to a non-zero value,
boxes reduce the score of other overlapping boxes
instead of directly causing them to be pruned. When the value of the param
is 0, the NMS algorithm defaults to the hard version.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.0</p></li>
</ul>
</div>
</div>
<div class="section" id="id860">
<h3>Outputs<a class="headerlink" href="#id860" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id861">
<h4>out[0]<a class="headerlink" href="#id861" title="Permalink to this heading">¶</a></h4>
<p>Selected Output boxes. Each element can be understood as a 4-tuple
with the same meaning as in[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, max_num_boxes, 4]. max_num_boxes is expressed by maxDimensions in Qnn_Tensor_t. The number of valid boxes is specified by out[3].</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id862">
<h4>out[1]<a class="headerlink" href="#id862" title="Permalink to this heading">¶</a></h4>
<p>Selected Output box scores. Gives the score for the box in the
corresponding position in out[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, max_num_boxes]. max_num_boxes is expressed by maxDimensions in Qnn_Tensor_t. The number of valid scores is specified by out[3].</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id863">
<h4>out[2]<a class="headerlink" href="#id863" title="Permalink to this heading">¶</a></h4>
<p>Selected Output classes. Gives the class label for the box in the
corresponding position in out[0].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [batch, max_num_boxes]. max_num_boxes is expressed by maxDimensions in Qnn_Tensor_t. The number of valid classes is specified by out[3].</p></li>
</ul>
</div>
<div class="section" id="id864">
<h4>out[3]<a class="headerlink" href="#id864" title="Permalink to this heading">¶</a></h4>
<p>Number of valid boxes per batch element that remain after NMS.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [batch]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: &lt;= max_num_boxes</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="out-4-m">
<h4>out[4..M]<a class="headerlink" href="#out-4-m" title="Permalink to this heading">¶</a></h4>
<p>Selected features post NMS. They are filtered along axis 0 that matches
the dimensions of the boxes. max_num_boxes is expressed by maxDimensions
in Qnn_Tensor_t. The number of valid classes is specified by out[3].
The number of these output features must match the number of input features in
in[2..m].</p>
<p>This tensor is repeated, meaning the same definition can apply to multiple tensors.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: N-dimensional. dim[0] should match <em>batch</em>; dim[1] should match max_num_boxes.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatypes as in[2..m]</p></li>
<li><p>Number: M &gt;= 4</p></li>
<li><p>Shape: Rank &gt; 0</p></li>
<li><p>Value: (M - 3) must be equal to (m - 1)</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="nonmaxsuppression">
<span id="id865"></span><h2>NonMaxSuppression<a class="headerlink" href="#nonmaxsuppression" title="Permalink to this heading">¶</a></h2>
<p>Filters out boxes that have high intersection-over-union (IOU) overlap with
previously selected boxes. Bounding boxes with a score less than <em>score_threshold</em>
are removed.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#NonMaxSuppression">NonMaxSuppression</a></p></li>
</ul>
<div class="section" id="id867">
<h3>Inputs<a class="headerlink" href="#id867" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id868">
<h4>in[0]<a class="headerlink" href="#id868" title="Permalink to this heading">¶</a></h4>
<p>Bounding boxes: Elements can be understood as 4-tuples of bounding box
coordinates given in the form (y1,x1,y2,x2), where (y1, x1) and (y2, x2)
represent a diagonal pair of corners.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, num_boxes, 4]</p></li>
</ul>
</div>
<div class="section" id="id869">
<h4>in[1]<a class="headerlink" href="#id869" title="Permalink to this heading">¶</a></h4>
<p>Bounding box scores.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, num_classes, num_boxes]</p></li>
</ul>
</div>
</div>
<div class="section" id="id870">
<h3>Parameters<a class="headerlink" href="#id870" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id871">
<h4>iou_threshold<a class="headerlink" href="#id871" title="Permalink to this heading">¶</a></h4>
<p>Represents the threshold used by NMS algorithm to determine whether boxes
overlap too much.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [0, 1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id872">
<h4>score_threshold<a class="headerlink" href="#id872" title="Permalink to this heading">¶</a></h4>
<p>Boxes with scores lower than the threshold are filtered out by the NMS algorithm.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0.0</p></li>
</ul>
</div>
<div class="section" id="max-boxes-selected">
<h4>max_boxes_selected<a class="headerlink" href="#max-boxes-selected" title="Permalink to this heading">¶</a></h4>
<p>Maximum number of boxes that can be selected per batch per class. Note that
default 0 means there is no valid output boxes. Note that if value provided is
greater than <em>num_boxes</em> it is set to the value of num_boxes.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id873">
<h3>Outputs<a class="headerlink" href="#id873" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id874">
<h4>out[0]<a class="headerlink" href="#id874" title="Permalink to this heading">¶</a></h4>
<p>selected_indices: Indices of the elements that have been kept by NMS algorithm.
Each element can be understood as a 3-tuple with index format (batch_index,
class_index, box_index).</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [max_selected_indices, 3]. max_selected_indices = batch * num_classes * max_boxes_selected, where the valid number of selected_indices is specified by out[1].</p></li>
</ul>
</div>
<div class="section" id="id875">
<h4>out[1]<a class="headerlink" href="#id875" title="Permalink to this heading">¶</a></h4>
<p>Valid number of selected indices.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [1]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be &lt;= max_selected_indices</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="nonzero">
<span id="id876"></span><h2>NonZero<a class="headerlink" href="#nonzero" title="Permalink to this heading">¶</a></h2>
<p>Generates a 2D output tensor containing the indices to nonzero elements of in[0].</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#NonZero">ops::NonZero</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nonzero.html">NonZero</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/where">Where</a></p></li>
</ul>
<div class="section" id="id878">
<h3>Inputs<a class="headerlink" href="#id878" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id879">
<h4>in[0]<a class="headerlink" href="#id879" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id880">
<h3>Parameters<a class="headerlink" href="#id880" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id881">
<h3>Outputs<a class="headerlink" href="#id881" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id882">
<h4>out[0]<a class="headerlink" href="#id882" title="Permalink to this heading">¶</a></h4>
<p>Indices to nonzero elements of in[0].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32, QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [M, N], where M is the total number of non-zero elements in in[0].</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="nv12torgb">
<span id="id883"></span><h2>Nv12ToRgb<a class="headerlink" href="#nv12torgb" title="Permalink to this heading">¶</a></h2>
<p>Transform Nv12 to RGB (or BRG).</p>
<div class="section" id="id884">
<h3>Inputs<a class="headerlink" href="#id884" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id885">
<h4>in[0]<a class="headerlink" href="#id885" title="Permalink to this heading">¶</a></h4>
<p>Input tensor.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [b, w*h*3/2] where w and h are the width and height of the image.</p></li>
</ul>
</div>
</div>
<div class="section" id="id886">
<h3>Parameters<a class="headerlink" href="#id886" title="Permalink to this heading">¶</a></h3>
<div class="section" id="output-order">
<h4>output_order<a class="headerlink" href="#output-order" title="Permalink to this heading">¶</a></h4>
<p>Controls the order of the output tensor. Set to
QNN_OP_NV12_TO_RGB_OUTPUT_ORDER_RGB the output will be in RGB. Set to
QNN_OP_NV12_TO_RGB_OUTPUT_ORDER_BGR, the output will be BGR.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>RGB = 0,</p></li>
<li><p>BGR = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id887">
<h3>Outputs<a class="headerlink" href="#id887" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id888">
<h4>out[0]<a class="headerlink" href="#id888" title="Permalink to this heading">¶</a></h4>
<p>Output tensor.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [b,h,w,3] where w and h are the width and height of the image.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="nv21torgb">
<span id="id889"></span><h2>Nv21ToRgb<a class="headerlink" href="#nv21torgb" title="Permalink to this heading">¶</a></h2>
<p>Transform Nv21 to RGB (or BRG).</p>
<div class="section" id="id890">
<h3>Inputs<a class="headerlink" href="#id890" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id891">
<h4>in[0]<a class="headerlink" href="#id891" title="Permalink to this heading">¶</a></h4>
<p>Input tensor.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [b, w*h*3/2] where w and h are the width and height of the image.</p></li>
</ul>
</div>
</div>
<div class="section" id="id892">
<h3>Parameters<a class="headerlink" href="#id892" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id893">
<h4>output_order<a class="headerlink" href="#id893" title="Permalink to this heading">¶</a></h4>
<p>Controls the order of the output tensor. Set to
QNN_OP_NV21_TO_RGB_OUTPUT_ORDER_RGB the output will be in RGB. Set to
QNN_OP_NV21_TO_RGB_OUTPUT_ORDER_BGR, the output will be BGR.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>RGB = 0,</p></li>
<li><p>BGR = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id894">
<h3>Outputs<a class="headerlink" href="#id894" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id895">
<h4>out[0]<a class="headerlink" href="#id895" title="Permalink to this heading">¶</a></h4>
<p>Output tensor.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [b,h,w,3] where w and h are the width and height of the image.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="onehot">
<span id="id896"></span><h2>OneHot<a class="headerlink" href="#onehot" title="Permalink to this heading">¶</a></h2>
<p>Creates a one-hot encoded tensor. Locations in indices
will take on QNN_OP_ONE_HOT_PARAM_ON_VALUE while all other locations take
on QNN_OP_ONE_HOT_PARAM_OFF_VALUE. Depth of one-hot locations can be specified
with QNN_OP_ONE_HOT_PARAM_DEPTH.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/one_hot">one_hot</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#OneHot">OneHot</a></p></li>
</ul>
<div class="section" id="id898">
<h3>Inputs<a class="headerlink" href="#id898" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id899">
<h4>in[0]<a class="headerlink" href="#id899" title="Permalink to this heading">¶</a></h4>
<p>Indices of one hot encoding</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32, QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
<li><p>Value: Index values must be in range [0, QNN_OP_ONE_HOT_PARAM_DEPTH-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id900">
<h3>Parameters<a class="headerlink" href="#id900" title="Permalink to this heading">¶</a></h3>
<div class="section" id="depth">
<h4>depth<a class="headerlink" href="#depth" title="Permalink to this heading">¶</a></h4>
<p>Depth of the one-hot dimension.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="id901">
<h4>axis<a class="headerlink" href="#id901" title="Permalink to this heading">¶</a></h4>
<p>The axis to fill the one-hot dimension.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: in range [0, N]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="on-value">
<h4>on_value<a class="headerlink" href="#on-value" title="Permalink to this heading">¶</a></h4>
<p>The value to fill at the indices provided by in[0].</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="off-value">
<h4>off_value<a class="headerlink" href="#off-value" title="Permalink to this heading">¶</a></h4>
<p>The value to fill at all other indices not provided in in[0].</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as QNN_OP_ONE_HOT_PARAM_ON_VALUE</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id902">
<h3>Outputs<a class="headerlink" href="#id902" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id903">
<h4>out[0]<a class="headerlink" href="#id903" title="Permalink to this heading">¶</a></h4>
<p>Output one-hot encoded tensor.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Shape is the same as in[0], but with rank(out[0]) = N + 1. A dimension of QNN_OP_ONE_HOT_PARAM_DEPTH inserted at the axis specified by QNN_OP_ONE_HOT_PARAM_AXIS.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as QNN_OP_ONE_HOT_PARAM_ON_VALUE</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="pack">
<span id="id904"></span><h2>Pack<a class="headerlink" href="#pack" title="Permalink to this heading">¶</a></h2>
<p>Packs the list of same rank tensors into a tensor with rank one higher than each tensor
by packing them along the axis dimension.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/stack">Stack</a></p></li>
</ul>
<div class="section" id="id905">
<h3>Inputs<a class="headerlink" href="#id905" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id906">
<h4>in[0..m]<a class="headerlink" href="#id906" title="Permalink to this heading">¶</a></h4>
<p>input tensors. m &gt;=1</p>
<p>This tensor is repeated, meaning the same definition can apply to multiple tensors.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: N-dimensional. Must be the same for all inputs.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Number: m &gt;= 1</p></li>
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id907">
<h3>Parameters<a class="headerlink" href="#id907" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id908">
<h4>axis<a class="headerlink" href="#id908" title="Permalink to this heading">¶</a></h4>
<p>Dimension along which packing will happen</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Value &lt;= (rank(in[0]))</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id909">
<h3>Outputs<a class="headerlink" href="#id909" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id910">
<h4>out[0]<a class="headerlink" href="#id910" title="Permalink to this heading">¶</a></h4>
<p>The packed output tensor</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape:</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: rank(out[0]) = rank(in[0]) + 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="pad">
<span id="id911"></span><h2>Pad<a class="headerlink" href="#pad" title="Permalink to this heading">¶</a></h2>
<p>Pads input tensor with the appropriate value based on the scheme picked.
Pad amount is a tensor with shape [N, 2] where N is the rank of the input.
Pad amount [i, 0] identifies pad size to add before on dimension i and
[i, 1] identifies pad size to add after on dimension i.
The output tensor on that dimension will have a size equal to the input tensor
plus the padding before and after.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>The pad value is applicable when scheme used is CONSTANT. Client is responsible
to provide a value that is appropriate to the operation consuming the padded input.
Pad value will be ignored for other schemes.</p>
<p>Mirror padding scheme uses tensor data to fill the pad amount. The padded region
does not use the border value when using MIRROR_REFLECT whereas
it uses the border value when using MIRROR_SYMMETRIC.</p>
<p>For MIRROR_REFLECT, the before and after pad amounts must not be greater than
shape(in[0])[i] - 1.
For MIRROR_SYMMETRIC, the before and after pad amounts must not be greater than
shape(in[0])[i].</p>
<p>Edge padding scheme applies padding with the edge values of the tensor
in each dimension.</p>
<p>Refer Pad backend definition for supported data type and layouts for each backend.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0afe2c4f9e541dcc278509921fd2c8a502">ANEURALNETWORKS_PAD_V2</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/mirror-pad">Mirror Pad</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pad">ops::Pad</a></p></li>
</ul>
<div class="section" id="id912">
<h3>Inputs<a class="headerlink" href="#id912" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id913">
<h4>in[0]<a class="headerlink" href="#id913" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id914">
<h3>Parameters<a class="headerlink" href="#id914" title="Permalink to this heading">¶</a></h3>
<div class="section" id="scheme">
<h4>scheme<a class="headerlink" href="#scheme" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>CONSTANT = 0,</p></li>
<li><p>MIRROR_SYMMETRIC = 1,</p></li>
<li><p>MIRROR_REFLECT = 2,</p></li>
<li><p>EDGE = 3</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id915">
<h4>pad_amount<a class="headerlink" href="#id915" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [rank(in[0]), 2]</p></li>
</ul>
</div>
<div class="section" id="pad-constant-value">
<h4>pad_constant_value<a class="headerlink" href="#pad-constant-value" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id916">
<h3>Outputs<a class="headerlink" href="#id916" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id917">
<h4>out[0]<a class="headerlink" href="#id917" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same rank as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="poolavg2d">
<span id="id918"></span><h2>PoolAvg2d<a class="headerlink" href="#poolavg2d" title="Permalink to this heading">¶</a></h2>
<p>Performs 2D average pooling on the input activation tensor by averaging a subset of
the input tensor values according to the filter_size and stride, effectively
downsampling the input data into the output activation tensor.</p>
<p>Average pooling is performed over 2D spatial shape of the input activation tensor,
i.e. over it’s [height, width] sub-shape.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a12e6b53aadbd3736c38f1a159adea788">ANEURALNETWORKS_AVERAGE_POOL_2D</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#AveragePool">AveragePool</a></p></li>
</ul>
<div class="section" id="id919">
<h3>Inputs<a class="headerlink" href="#id919" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id920">
<h4>in[0]<a class="headerlink" href="#id920" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height, width, channel]</p></li>
</ul>
</div>
</div>
<div class="section" id="id921">
<h3>Parameters<a class="headerlink" href="#id921" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id922">
<h4>filter_size<a class="headerlink" href="#id922" title="Permalink to this heading">¶</a></h4>
<p>Defines filter size for 2D spatial axes of in[0].
Number of elements to average = filter_size[0]*filter_size[1]</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] : [filter_height, filter_width]</p></li>
</ul>
</div>
<div class="section" id="id923">
<h4>stride<a class="headerlink" href="#id923" title="Permalink to this heading">¶</a></h4>
<p>Defines stride for 2D spatial axes of in[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] : [height_stride, width_stride]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Strides must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id924">
<h4>pad_amount<a class="headerlink" href="#id924" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 2D spatial axes of in[0].
Pad value = 0.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2,2] with format [[height_pad_before, height_pad_after], [width_pad_before, width_pad_after]]</p></li>
</ul>
</div>
<div class="section" id="count-pad-for-edges">
<h4>count_pad_for_edges<a class="headerlink" href="#count-pad-for-edges" title="Permalink to this heading">¶</a></h4>
<p>Include pad elements when calculating average for the edges. 0 = do not include pad.
Any other value will include padding into average calculation.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="rounding-mode">
<h4>rounding_mode<a class="headerlink" href="#rounding-mode" title="Permalink to this heading">¶</a></h4>
<p>Indicate the rounding mode used in truncating output dimensions to integer values.
Available options: 0: FLOOR, 1: CEIL.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>FLOOR = 0,</p></li>
<li><p>CEIL = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id925">
<h3>Outputs<a class="headerlink" href="#id925" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id926">
<h4>out[0]<a class="headerlink" href="#id926" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<p>The output 2D spatial dimensions are functions of the filter_size, stride,
pad_amount and rounding_mode.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROUND</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filter_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROUND</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filter_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">where</span><span class="w"> </span><span class="n">ROUND</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">()</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">ceil</span><span class="p">(),</span><span class="w"> </span><span class="n">based</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">.</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height_out, width_out, channel]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="poolavg3d">
<span id="id927"></span><h2>PoolAvg3d<a class="headerlink" href="#poolavg3d" title="Permalink to this heading">¶</a></h2>
<p>Performs 3D average pooling on the input activation tensor by averaging a subset of
the input tensor values according to the filter_size and stride, effectively
downsampling the input data into the output activation tensor.</p>
<p>Average pooling is performed over 3D spatial shape of the input activation tensor,
i.e. over it’s [depth, height, width] sub-shape.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#AveragePool">AveragePool</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool3d">AveragePool3D</a></p></li>
</ul>
<div class="section" id="id929">
<h3>Inputs<a class="headerlink" href="#id929" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id930">
<h4>in[0]<a class="headerlink" href="#id930" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, depth, height, width, channel]</p></li>
</ul>
</div>
</div>
<div class="section" id="id931">
<h3>Parameters<a class="headerlink" href="#id931" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id932">
<h4>filter_size<a class="headerlink" href="#id932" title="Permalink to this heading">¶</a></h4>
<p>Defines filter size for 3D spatial axes of in[0].
Number of elements to average = filter_size[0] * filter_size[1] * filter_size[2]</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3] : [filter_depth, filter_height, filter_width]</p></li>
</ul>
</div>
<div class="section" id="id933">
<h4>stride<a class="headerlink" href="#id933" title="Permalink to this heading">¶</a></h4>
<p>Defines stride for 3D spatial axes of in[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3] : [depth_stride, height_stride, width_stride]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Strides must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id934">
<h4>pad_amount<a class="headerlink" href="#id934" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 3D spatial axes of in[0].
Pad value = 0.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3,2] with format [[depth_pad_before, depth_pad_after], [height_pad_before, height_pad_after], [width_pad_before, width_pad_after]]</p></li>
</ul>
</div>
<div class="section" id="id935">
<h4>count_pad_for_edges<a class="headerlink" href="#id935" title="Permalink to this heading">¶</a></h4>
<p>Include pad elements when calculating average for the edges. 0 = do not include
pad. Any other value will include padding into average calculation.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="id936">
<h4>rounding_mode<a class="headerlink" href="#id936" title="Permalink to this heading">¶</a></h4>
<p>Indicate the rounding mode used in truncating output dimensions to integer
values. Available options: 0: FLOOR, 1: CEIL.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>FLOOR = 0,</p></li>
<li><p>CEIL = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id937">
<h3>Outputs<a class="headerlink" href="#id937" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id938">
<h4>out[0]<a class="headerlink" href="#id938" title="Permalink to this heading">¶</a></h4>
<p>output activation :
The output 3D spatial dimensions are functions of the filter_size, stride,
pad_amount and rounding_mode.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">depth_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROUND</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">depth</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filter_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">height_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROUND</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filter_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">width_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROUND</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filter_size</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">where</span><span class="w"> </span><span class="n">ROUND</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">()</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">ceil</span><span class="p">(),</span><span class="w"> </span><span class="n">based</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="o">*</span><span class="n">rounding_mode</span><span class="o">*</span><span class="p">.</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, depth_out, height_out, width_out, channel]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="poolmax2d">
<span id="id939"></span><h2>PoolMax2d<a class="headerlink" href="#poolmax2d" title="Permalink to this heading">¶</a></h2>
<p>Performs 2D maximum pooling on the input activation tensor by computing maximum value in a subset of the
input tensor values according to the filter_size and stride, effectively downsampling the input data
into the output activation tensor.
Maximum pooling is performed over 2D spatial shape of the input activation tensor,
i.e. over it’s [height, width] sub-shape.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a0f227a4d98ad5af31f7fd4d255d246ce">ANEURALNETWORKS_MAX_POOL_2D</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MaxPool">MaxPool</a></p></li>
</ul>
<div class="section" id="id940">
<h3>Inputs<a class="headerlink" href="#id940" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id941">
<h4>in[0]<a class="headerlink" href="#id941" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height, width, channel]</p></li>
</ul>
</div>
</div>
<div class="section" id="id942">
<h3>Parameters<a class="headerlink" href="#id942" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id943">
<h4>filter_size<a class="headerlink" href="#id943" title="Permalink to this heading">¶</a></h4>
<p>Defines max pool filter size for 2D spatial axes of in[0].
Number of elements to pool from = filter_size[0] * filter_size[1]</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] : [filter_height, filter_width]</p></li>
</ul>
</div>
<div class="section" id="id944">
<h4>stride<a class="headerlink" href="#id944" title="Permalink to this heading">¶</a></h4>
<p>Defines max pool stride size for 2D spatial axes of in[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] : [height_stride, width_stride]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Strides must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id945">
<h4>pad_amount<a class="headerlink" href="#id945" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 2D spatial axes
of in[0]. Pad value = 0.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2,2] with format [[height_pad_before, height_pad_after], [width_pad_before, width_pad_after]]</p></li>
</ul>
</div>
<div class="section" id="id946">
<h4>rounding_mode<a class="headerlink" href="#id946" title="Permalink to this heading">¶</a></h4>
<p>Indicate the rounding mode used in truncating output dimensions to integer values.
Available options: 0: FLOOR, 1: CEIL.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>FLOOR = 0,</p></li>
<li><p>CEIL = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id947">
<h3>Outputs<a class="headerlink" href="#id947" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id948">
<h4>out[0]<a class="headerlink" href="#id948" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<p>The output 2D spatial dimensions are functions of the filter_size, stride,
pad_amount and rounding_mode.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROUND</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filter_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROUND</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filter_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">where</span><span class="w"> </span><span class="n">ROUND</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">()</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">ceil</span><span class="p">(),</span><span class="w"> </span><span class="n">based</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">.</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height_out, width_out, channel]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="poolmax3d">
<span id="id949"></span><h2>PoolMax3d<a class="headerlink" href="#poolmax3d" title="Permalink to this heading">¶</a></h2>
<p>Performs 3D maximum pooling on the input activation tensor by computing maximum
value in a subset of the input tensor values according to the filter_size and
stride, effectively downsampling the input data into the output activation tensor.
Maximum pooling is performed over 3D spatial shape of the input activation tensor,
i.e. over it’s [depth, height, width] sub-shape.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MaxPool">MaxPool</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/max_pool3d">MaxPool3D</a></p></li>
<li><p>PyTorch: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool3d.html">MaxPool3D</a></p></li>
</ul>
<div class="section" id="id952">
<h3>Inputs<a class="headerlink" href="#id952" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id953">
<h4>in[0]<a class="headerlink" href="#id953" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, depth, height, width, channel]</p></li>
</ul>
</div>
</div>
<div class="section" id="id954">
<h3>Parameters<a class="headerlink" href="#id954" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id955">
<h4>filter_size<a class="headerlink" href="#id955" title="Permalink to this heading">¶</a></h4>
<p>Defines max pool filter size for 3D spatial axes of in[0].
Number of elements to pool from = filter_size[0] * filter_size[1] * filter_size[2]</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3] : [filter_depth, filter_height, filter_width]</p></li>
</ul>
</div>
<div class="section" id="id956">
<h4>stride<a class="headerlink" href="#id956" title="Permalink to this heading">¶</a></h4>
<p>Defines max pool stride size for 3D spatial axes of in[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3] : [depth_stride, height_stride, width_stride]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Strides must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id957">
<h4>pad_amount<a class="headerlink" href="#id957" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 3D spatial axes
of in[0]. Pad value = 0.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3,2] with format [[depth_pad_before, depth_pad_after], [height_pad_before, height_pad_after], [width_pad_before, width_pad_after]]</p></li>
</ul>
</div>
<div class="section" id="id958">
<h4>rounding_mode<a class="headerlink" href="#id958" title="Permalink to this heading">¶</a></h4>
<p>Indicate the rounding mode used in truncating output dimensions to integer values.
Available options: 0: FLOOR, 1: CEIL.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>FLOOR = 0,</p></li>
<li><p>CEIL = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id959">
<h3>Outputs<a class="headerlink" href="#id959" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id960">
<h4>out[0]<a class="headerlink" href="#id960" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<p>The output 3D spatial dimensions are functions of the filter_size, stride,
pad_amount, and rounding_mode.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">depth_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROUND</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">depth</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filter_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROUND</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filter_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width_out</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ROUND</span><span class="p">((</span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filter_size</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stride</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="n">where</span><span class="w"> </span><span class="n">ROUND</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">()</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">ceil</span><span class="p">(),</span><span class="w"> </span><span class="n">based</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">.</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, depth_out, height_out, width_out, channel]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="prelu">
<span id="id961"></span><h2>Prelu<a class="headerlink" href="#prelu" title="Permalink to this heading">¶</a></h2>
<p>The <strong>P</strong>arametric <strong>re</strong>ctified <strong>l</strong>inear <strong>u</strong>nit operation computes:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">0</span>
<span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span>
</pre></div>
</div>
<p>The coefficient tensor in[1] is applied element-wise to input activation tensor in[0].
Only unidirectional broadcasting is possible, from in[1] to in[0].</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a82e7e7c709ad117a0178203217be30cf">ANEURALNETWORKS_PRELU</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Prelu">ops::PRELU</a></p></li>
<li><p>QNN: <a class="reference external" href="../general/terminology.html#element-wise-operation-rules">BroadcastingRules</a></p></li>
</ul>
<div class="section" id="id963">
<h3>Inputs<a class="headerlink" href="#id963" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id964">
<h4>in[0]<a class="headerlink" href="#id964" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id965">
<h4>in[1]<a class="headerlink" href="#id965" title="Permalink to this heading">¶</a></h4>
<p>coefficients</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M, where 0 &lt; M &lt;= N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id966">
<h3>Parameters<a class="headerlink" href="#id966" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id967">
<h3>Outputs<a class="headerlink" href="#id967" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id968">
<h4>out[0]<a class="headerlink" href="#id968" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="quantize">
<span id="id969"></span><h2>Quantize<a class="headerlink" href="#quantize" title="Permalink to this heading">¶</a></h2>
<p>Implements:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">round</span><span class="p">(</span><span class="n">input</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">scale</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span>
</pre></div>
</div>
<p>where <em>output</em> is limited to <em>out[0]</em>’s data type maximum and minimum.</p>
<p>Note that <em>scale</em> and <em>offset</em> are determined from out[0].</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a60e0015c8f08ed26d59afe92f728068d">ANEURALNETWORKS_QUANTIZE</a></p></li>
<li><p>QNN: <a class="reference internal" href="#dequantize">Dequantize</a></p></li>
</ul>
<div class="section" id="id970">
<h3>Inputs<a class="headerlink" href="#id970" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id971">
<h4>in[0]<a class="headerlink" href="#id971" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32, backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id972">
<h3>Parameters<a class="headerlink" href="#id972" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id973">
<h3>Outputs<a class="headerlink" href="#id973" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id974">
<h4>out[0]<a class="headerlink" href="#id974" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_SFIXED_POINT_4, QNN_DATATYPE_UFIXED_POINT_4, QNN_DATATYPE_SFIXED_POINT_8, QNN_DATATYPE_UFIXED_POINT_8, QNN_DATATYPE_SFIXED_POINT_16, QNN_DATATYPE_UFIXED_POINT_16, QNN_DATATYPE_SFIXED_POINT_32, QNN_DATATYPE_UFIXED_POINT_32, backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="reducemax">
<span id="id975"></span><h2>ReduceMax<a class="headerlink" href="#reducemax" title="Permalink to this heading">¶</a></h2>
<p>Reduces a tensor by computing the maximum of elements along given dimensions as
specified in <em>axes</em>. If <em>keep_dims</em> is true, the reduced dimensions are retained
with length 1. Otherwise, the rank of the tensor is reduced by 1 for each entry in
<em>axes</em>.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a257a84d4cfa9f6eef0997ddd591e9584">ANEURALNETWORKS_REDUCE_MAX</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMax">ops::ReduceMax</a></p></li>
</ul>
<div class="section" id="id976">
<h3>Inputs<a class="headerlink" href="#id976" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id977">
<h4>in[0]<a class="headerlink" href="#id977" title="Permalink to this heading">¶</a></h4>
<p>Input activations</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: N-dimensional</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id978">
<h3>Parameters<a class="headerlink" href="#id978" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id979">
<h4>axes<a class="headerlink" href="#id979" title="Permalink to this heading">¶</a></h4>
<p>A list of dimensions along which to reduce. Each value must be in range
[0,N-1] and must be listed only once.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: 1D of shape [M]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: 0 &lt; M &lt;= N</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id980">
<h4>keep_dims<a class="headerlink" href="#id980" title="Permalink to this heading">¶</a></h4>
<p>If true, the resulting tensor has the same number of dimensions as
the input tensor.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id981">
<h3>Outputs<a class="headerlink" href="#id981" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id982">
<h4>out[0]<a class="headerlink" href="#id982" title="Permalink to this heading">¶</a></h4>
<p>Output activations</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: K-dimensional, where K = N if <em>keep_dims</em> is true and K = max(1, N - M) otherwise K-dimensional, where K = N if <em>keep_dims</em> is true and K = max(1, N - M) otherwise</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="reducemean">
<span id="id983"></span><h2>ReduceMean<a class="headerlink" href="#reducemean" title="Permalink to this heading">¶</a></h2>
<p>Reduces a tensor by computing the mean of elements along given dimensions as
specified in <em>axes</em>. If <em>keep_dims</em> is true, the reduced dimensions are retained
with length 1. Otherwise, the rank of the tensor is reduced by 1 for each entry
in <em>axes</em>.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a047fe95a35b27f45c05432b6ca18eb6c">ANEURALNETWORKS_MEAN</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMean">ops::ReduceMean</a></p></li>
</ul>
<div class="section" id="id984">
<h3>Inputs<a class="headerlink" href="#id984" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id985">
<h4>in[0]<a class="headerlink" href="#id985" title="Permalink to this heading">¶</a></h4>
<p>Input activations</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: N-dimensional</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id986">
<h3>Parameters<a class="headerlink" href="#id986" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id987">
<h4>axes<a class="headerlink" href="#id987" title="Permalink to this heading">¶</a></h4>
<p>A list of dimensions along which to reduce. Each value must be in
range [0,N-1] and must be listed only once.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: 1D of shape [M]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: 0 &lt; M &lt;= N</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id988">
<h4>keep_dims<a class="headerlink" href="#id988" title="Permalink to this heading">¶</a></h4>
<p>If true, the resulting tensor has the same number of dimensions as
the input tensor.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id989">
<h3>Outputs<a class="headerlink" href="#id989" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id990">
<h4>out[0]<a class="headerlink" href="#id990" title="Permalink to this heading">¶</a></h4>
<p>Output activations</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: K-dimensional, where K = N if <em>keep_dims</em> is true and K = max(1, N - M) otherwise.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="reducemin">
<span id="id991"></span><h2>ReduceMin<a class="headerlink" href="#reducemin" title="Permalink to this heading">¶</a></h2>
<p>Reduces a tensor by computing the minimum of elements along given dimensions as
specified in <em>axes</em>. If <em>keep_dims</em> is true, the reduced dimensions are retained
with length 1. Otherwise, the rank of the tensor is reduced by 1 for each entry in
<em>axes</em>.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0ab5934984ee3e89ffb703b0cac7d6a2f8">ANEURALNETWORKS_REDUCE_MIN</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMin">ops::ReduceMin</a></p></li>
</ul>
<div class="section" id="id992">
<h3>Inputs<a class="headerlink" href="#id992" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id993">
<h4>in[0]<a class="headerlink" href="#id993" title="Permalink to this heading">¶</a></h4>
<p>Input activations</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: N-dimensional</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id994">
<h3>Parameters<a class="headerlink" href="#id994" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id995">
<h4>axes<a class="headerlink" href="#id995" title="Permalink to this heading">¶</a></h4>
<p>A list of dimensions along which to reduce. Each value must be in range [0,N-1]
and must be listed only once.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: 1D of shape [M]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: 0 &lt; M &lt;= N</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id996">
<h4>keep_dims<a class="headerlink" href="#id996" title="Permalink to this heading">¶</a></h4>
<p>If true, the resulting tensor has the same number of dimensions as
the input tensor.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id997">
<h3>Outputs<a class="headerlink" href="#id997" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id998">
<h4>out[0]<a class="headerlink" href="#id998" title="Permalink to this heading">¶</a></h4>
<p>Output activations</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: K-dimensional, where K = N if <em>keep_dims</em> is true and K = max(1, N - M) otherwise</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="reduceprod">
<span id="id999"></span><h2>ReduceProd<a class="headerlink" href="#reduceprod" title="Permalink to this heading">¶</a></h2>
<p>Reduces a tensor by computing the product of elements along given dimensions as
specified in <em>axes</em>. If <em>keep_dims</em> is true, the reduced dimensions are retained
with length 1. Otherwise, the rank of the tensor is reduced by 1 for each entry in
<em>axes</em>.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0aea51a05dfc337082df51b4a263eb0c5c">ANEURALNETWORKS_REDUCE_PROD</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceProd">ops::ReduceProd</a></p></li>
</ul>
<div class="section" id="id1000">
<h3>Inputs<a class="headerlink" href="#id1000" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1001">
<h4>in[0]<a class="headerlink" href="#id1001" title="Permalink to this heading">¶</a></h4>
<p>Input activations</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: N-dimensional</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1002">
<h3>Parameters<a class="headerlink" href="#id1002" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1003">
<h4>axes<a class="headerlink" href="#id1003" title="Permalink to this heading">¶</a></h4>
<p>A list of dimensions along which to reduce. Each value must be in range [0,N-1]
and must be listed only once.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: 1D of shape [M]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: 0 &lt; M &lt;= N</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1004">
<h4>keep_dims<a class="headerlink" href="#id1004" title="Permalink to this heading">¶</a></h4>
<p>If true, the resulting tensor has the same number of dimensions as the input
tensor.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id1005">
<h3>Outputs<a class="headerlink" href="#id1005" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1006">
<h4>out[0]<a class="headerlink" href="#id1006" title="Permalink to this heading">¶</a></h4>
<p>Output activations</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: K-dimensional, where K = N if <em>keep_dims</em> is true and K = max(1, N - M) otherwise</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="reducesum">
<span id="id1007"></span><h2>ReduceSum<a class="headerlink" href="#reducesum" title="Permalink to this heading">¶</a></h2>
<p>Reduces a tensor by computing the sum of elements along given dimensions as specified
in <em>axes</em>. If <em>keep_dims</em> is true, the reduced dimensions are retained with length 1.
Otherwise, the rank of the tensor is reduced by 1 for each entry in <em>axes</em>.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0aa2b7674dd559dd3233523688ad71cb3e">ANEURALNETWORKS_REDUCE_SUM</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceSum">ops::ReduceSum</a></p></li>
</ul>
<div class="section" id="id1008">
<h3>Inputs<a class="headerlink" href="#id1008" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1009">
<h4>in[0]<a class="headerlink" href="#id1009" title="Permalink to this heading">¶</a></h4>
<p>Input activations</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: N-dimensional</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1010">
<h3>Parameters<a class="headerlink" href="#id1010" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1011">
<h4>axes<a class="headerlink" href="#id1011" title="Permalink to this heading">¶</a></h4>
<p>A list of dimensions along which to reduce. Each value must be in range [0,N-1]
and must be listed only once.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: 1D of shape [M]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: 0 &lt; M &lt;= N</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1012">
<h4>keep_dims<a class="headerlink" href="#id1012" title="Permalink to this heading">¶</a></h4>
<p>If true, the resulting tensor has the same number of dimensions as the
input tensor.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id1013">
<h3>Outputs<a class="headerlink" href="#id1013" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1014">
<h4>out[0]<a class="headerlink" href="#id1014" title="Permalink to this heading">¶</a></h4>
<p>Output activations</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: K-dimensional, where K = N if <em>keep_dims</em> is true and K = max(1, N - M) otherwise</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="reducesumsquare">
<span id="id1015"></span><h2>ReduceSumSquare<a class="headerlink" href="#reducesumsquare" title="Permalink to this heading">¶</a></h2>
<p>Reduces a tensor by computing the sum square of elements along given dimensions as
specified in <em>axes</em>. If <em>keep_dims</em> is true, the reduced dimensions are retained with
length 1. Otherwise, the rank of the tensor is reduced by 1 for each entry in <em>axes</em>.
If rank(<em>in[0]</em>) = 0, no reduction occurs and the output is simply <em>in[0]</em>
squared.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#ReduceSumSquare">ops::ReduceSumSquare</a></p></li>
</ul>
<div class="section" id="id1016">
<h3>Inputs<a class="headerlink" href="#id1016" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1017">
<h4>in[0]<a class="headerlink" href="#id1017" title="Permalink to this heading">¶</a></h4>
<p>Input activations</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: N-dimensional</p></li>
</ul>
</div>
</div>
<div class="section" id="id1018">
<h3>Parameters<a class="headerlink" href="#id1018" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1019">
<h4>axes<a class="headerlink" href="#id1019" title="Permalink to this heading">¶</a></h4>
<p>A list of dimensions along which to reduce. Each value must be in range [0,N-1]
and must be listed only once. If rank(<em>in[0]</em>) = 0, this param is ignored.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: 1D of shape [M]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: 0 &lt; M &lt;= N unless rank(<em>in[0]</em>) = 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1020">
<h4>keep_dims<a class="headerlink" href="#id1020" title="Permalink to this heading">¶</a></h4>
<p>If true, the resulting tensor has the same number of dimensions as the
input tensor. If rank(<em>in[0]</em>) = 0, this param is ignored.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id1021">
<h3>Outputs<a class="headerlink" href="#id1021" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1022">
<h4>out[0]<a class="headerlink" href="#id1022" title="Permalink to this heading">¶</a></h4>
<p>Output activations</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: K-dimensional, where K = N if <em>keep_dims</em> is true and K = max(0, N - M) otherwise, where N = rank(<em>in[0]</em>) and M = size(<em>axes</em>)</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="relu">
<span id="id1023"></span><h2>Relu<a class="headerlink" href="#relu" title="Permalink to this heading">¶</a></h2>
<p>The <strong>Re</strong>ctified <strong>l</strong>inear <strong>u</strong>nit operation computes:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">input</span><span class="p">).</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0abb2f979866b131c5089ba0caaecee656">ANEURALNETWORKS_RELU</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/relu">ops::Relu</a></p></li>
</ul>
<div class="section" id="id1025">
<h3>Inputs<a class="headerlink" href="#id1025" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1026">
<h4>in[0]<a class="headerlink" href="#id1026" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1027">
<h3>Parameters<a class="headerlink" href="#id1027" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id1028">
<h3>Outputs<a class="headerlink" href="#id1028" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1029">
<h4>out[0]<a class="headerlink" href="#id1029" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
<li><p>Must have same data format as in[0] (e.g. both sparse or both dense)</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="relu1">
<span id="id1030"></span><h2>Relu1<a class="headerlink" href="#relu1" title="Permalink to this heading">¶</a></h2>
<p>The <strong>Re</strong>ctified <strong>l</strong>inear 1 <strong>u</strong>nit operation computes:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="mf">1.f</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="mf">-1.f</span><span class="p">,</span><span class="w"> </span><span class="n">input</span><span class="p">)).</span>
</pre></div>
</div>
<p><strong>DEPRECATED:</strong> Use <a class="reference internal" href="#reluminmax">ReluMinMax</a> instead.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a73b9a2ded1dda2925d2e73aec44d2e2e">ANEURALNETWORKS_RELU1</a></p></li>
</ul>
<div class="section" id="id1031">
<h3>Inputs<a class="headerlink" href="#id1031" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1032">
<h4>in[0]<a class="headerlink" href="#id1032" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1033">
<h3>Parameters<a class="headerlink" href="#id1033" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id1034">
<h3>Outputs<a class="headerlink" href="#id1034" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1035">
<h4>out[0]<a class="headerlink" href="#id1035" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="relu6">
<span id="id1036"></span><h2>Relu6<a class="headerlink" href="#relu6" title="Permalink to this heading">¶</a></h2>
<p>The <strong>Re</strong>ctified <strong>l</strong>inear 6 <strong>u</strong>nit operation computes:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">input</span><span class="p">)).</span>
</pre></div>
</div>
<p><strong>DEPRECATED:</strong> Use <a class="reference internal" href="#reluminmax">ReluMinMax</a> instead.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a04a24c2d6f0aac4c3f5324c1d7764714">ANEURALNETWORKS_RELU6</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/relu6">ops::Relu6</a></p></li>
</ul>
<div class="section" id="id1038">
<h3>Inputs<a class="headerlink" href="#id1038" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1039">
<h4>in[0]<a class="headerlink" href="#id1039" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1040">
<h3>Parameters<a class="headerlink" href="#id1040" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id1041">
<h3>Outputs<a class="headerlink" href="#id1041" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1042">
<h4>out[0]<a class="headerlink" href="#id1042" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="reluminmax">
<span id="id1043"></span><h2>ReluMinMax<a class="headerlink" href="#reluminmax" title="Permalink to this heading">¶</a></h2>
<p>The Rectified Linear Unit Min Max operation computes:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="n">max_value</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="n">min_value</span><span class="p">,</span><span class="w"> </span><span class="n">input</span><span class="p">)),</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">min_value</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">max_value</span>
</pre></div>
</div>
<p>The ReluMinMax rectifies values within min_value and max_value.
It can support different types of Relu operations. For example, for Relu6, use
min_value=0 and max_value=6.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a04a24c2d6f0aac4c3f5324c1d7764714">ANEURALNETWORKS_RELU6</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/relu6">ops::Relu6</a></p></li>
</ul>
<div class="section" id="id1046">
<h3>Inputs<a class="headerlink" href="#id1046" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1047">
<h4>in[0]<a class="headerlink" href="#id1047" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1048">
<h3>Parameters<a class="headerlink" href="#id1048" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1049">
<h4>min_value<a class="headerlink" href="#id1049" title="Permalink to this heading">¶</a></h4>
<p>The minimum value in Relu operation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
<div class="section" id="id1050">
<h4>max_value<a class="headerlink" href="#id1050" title="Permalink to this heading">¶</a></h4>
<p>The maximum value in Relu operation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
</div>
<div class="section" id="id1051">
<h3>Outputs<a class="headerlink" href="#id1051" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1052">
<h4>out[0]<a class="headerlink" href="#id1052" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="reshape">
<span id="id1053"></span><h2>Reshape<a class="headerlink" href="#reshape" title="Permalink to this heading">¶</a></h2>
<p>Reshapes a tensor of N dimension to an output shape of M dimension while retaining
the values of the input tensor. The number of elements implied by the output shape
must be the same as the shape of the input tensor. Note that N can equal M.</p>
<p>See Reshape backend definition for supported datatypes</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a535e7e99383ee49456c8671843b93a59">ANEURALNETWORKS_RESHAPE</a></p></li>
</ul>
<div class="section" id="id1054">
<h3>Inputs<a class="headerlink" href="#id1054" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1055">
<h4>in[0]<a class="headerlink" href="#id1055" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of N dimension</p></li>
</ul>
</div>
</div>
<div class="section" id="id1056">
<h3>Parameters<a class="headerlink" href="#id1056" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id1057">
<h3>Outputs<a class="headerlink" href="#id1057" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1058">
<h4>out[0]<a class="headerlink" href="#id1058" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of M dimension</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="resize">
<span id="id1059"></span><h2>Resize<a class="headerlink" href="#resize" title="Permalink to this heading">¶</a></h2>
<p>Resizes the spatial dimensions of an input tensor with shape [batch, D1, D2, …,
Dn, channel], where D1, …, Dn are the spatial dimensions. Every value of the
output tensor is calculated as a weighted average of sampling locations in the input
tensor.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#resize">Resize</a></p></li>
</ul>
<div class="section" id="id1061">
<h3>Inputs<a class="headerlink" href="#id1061" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1062">
<h4>in[0]<a class="headerlink" href="#id1062" title="Permalink to this heading">¶</a></h4>
<p>Input image</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of N dimension with shape [batch, D1, D2, … Dn, channel], where D1, …, Dn are the spatial dimensions.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1063">
<h3>Parameters<a class="headerlink" href="#id1063" title="Permalink to this heading">¶</a></h3>
<div class="section" id="exclude-outside">
<h4>exclude_outside<a class="headerlink" href="#exclude-outside" title="Permalink to this heading">¶</a></h4>
<p>If true, the weight of sampling locations outside the tensor will be set to 0
and the weight will be renormalized so that their sum is 1.0.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="transformation-mode">
<h4>transformation_mode<a class="headerlink" href="#transformation-mode" title="Permalink to this heading">¶</a></h4>
<p>Determines how to transform the coordinates in the original input tensor to the
coordinates in the resized tensor. Note that the coordinates of each dimension
are transformed individually. Supported values are 0: HALF_PIXEL,
1: PYTORCH_HALF_PIXEL, 2: ALIGN_CORNERS, 3: ASYMMETRIC.</p>
<p>When transformation_mode = HALF_PIXEL:</p>
<div class="math notranslate nohighlight">
\[x_{out} = (x_{in} + 0.5) * \mbox{scale} - 0.5\]</div>
<p>When transformation_mode = PYTORCH_HALF_PIXEL:</p>
<div class="math notranslate nohighlight">
\[\begin{split}x_{out} &amp;= (x_{in} + 0.5) * \mbox{scale} - 0.5\ (\text{if}\ \text{shape} (\mbox{out[0]})[axis_{x}] &gt; 1;) \\
x_{out} &amp;= 0\ (\text{otherwise}) \\\end{split}\]</div>
<p>When transformation_mode = ALIGN_CORNERS:</p>
<div class="math notranslate nohighlight">
\[x_{out} = \frac{x_{in} * (\text{shape}(\mbox{out[0]})[axis_{x}] - 1)}{\text{shape} (\mbox{in[0]})[axis_{x}] - 1}\]</div>
<p>When transformation_mode = ASYMMETRIC:</p>
<div class="math notranslate nohighlight">
\[x_{out} = x_{in} * \mbox{scale}\]</div>
<p>where</p>
<p><span class="math notranslate nohighlight">\(x_{in}\)</span> is a coordinate of <span class="math notranslate nohighlight">\(\text{shape} (\mbox{in[0]})[axis_{x}]\)</span>,</p>
<p><span class="math notranslate nohighlight">\(x_{out}\)</span> is a coordinate of <span class="math notranslate nohighlight">\(\text{shape} (\mbox{out[0]})[axis_{x}]\)</span>,</p>
<p><span class="math notranslate nohighlight">\(\mbox{scale} = \frac{\text{shape} (\mbox{out[0]})[axis_{x}]}{\text{shape} (\mbox{in[0]})[axis_{x}]}\)</span>.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>HALF_PIXEL = 0,</p></li>
<li><p>PYTORCH_HALF_PIXEL = 1,</p></li>
<li><p>ALIGN_CORNERS = 2,</p></li>
<li><p>ASYMMETRIC = 3</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1064">
<h4>interpolation_mode<a class="headerlink" href="#id1064" title="Permalink to this heading">¶</a></h4>
<p>Determines the interpolation method. Supported values are
0: NEAREST, 1: LINEAR, 2: CUBIC.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>NEAREST = 0,</p></li>
<li><p>LINEAR = 1,</p></li>
<li><p>CUBIC = 2</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="nearest-mode">
<h4>nearest_mode<a class="headerlink" href="#nearest-mode" title="Permalink to this heading">¶</a></h4>
<p>Determines the rounding method used when <em>interpolation_mode</em> is set to NEAREST.
Supported values are 0: ROUND_PREFER_FLOOR, 1: ROUND_PREFER_CEIL, 2: FLOOR, 3 :
CEIL.</p>
<p>For the following example let <em>x</em> represent a value in the range (0, 1].</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">When</span><span class="w"> </span><span class="n">QNN_OP_RESIZE_PARAM_NEAREST_MODE</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">QNN_OP_RESIZE_NEAREST_MODE_ROUND_PREFER_FLOOR</span><span class="w"> </span><span class="o">:</span>
<span class="n">floor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="k">if</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ceil</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="n">otherwise</span><span class="p">.</span>

<span class="n">When</span><span class="w"> </span><span class="n">QNN_OP_RESIZE_PARAM_NEAREST_MODE</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">QNN_OP_RESIZE_NEAREST_MODE_ROUND_PREFER_CEIL</span><span class="w"> </span><span class="o">:</span>
<span class="n">ceil</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="k">if</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">floor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="n">otherwise</span><span class="p">.</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>ROUND_PREFER_FLOOR = 0,</p></li>
<li><p>ROUND_PREFER_CEIL = 1,</p></li>
<li><p>FLOOR = 2,</p></li>
<li><p>CEIL = 3</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>interpolation_mode must be set to NEAREST for this parameter to be valid.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="cubic-coeff">
<h4>cubic_coeff<a class="headerlink" href="#cubic-coeff" title="Permalink to this heading">¶</a></h4>
<p>Coefficient used in cubic interpolation.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: -0.75</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>interpolation_mode must be set to CUBIC for this parameter to be valid.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1065">
<h3>Outputs<a class="headerlink" href="#id1065" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1066">
<h4>out[0]<a class="headerlink" href="#id1066" title="Permalink to this heading">¶</a></h4>
<p>Output image</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of N dimension after resizing.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="resizebilinear">
<span id="id1067"></span><h2>ResizeBilinear<a class="headerlink" href="#resizebilinear" title="Permalink to this heading">¶</a></h2>
<p>Resize a 4D image in the height and width dimensions, computing new pixel values by
bilinear interpolation. Image will be distorted if the aspect ratio of the output
does not match the aspect ratio of the input. The output height and width are defined
by the shape of the output tensor, and not computed.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a42bd92518e273b6716ecd56b571fcd3e">ANEURALNETWORKS_RESIZE_BILINEAR</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/image/resize">ResizeMethod.BILINEAR</a></p></li>
</ul>
<div class="section" id="id1068">
<h3>Inputs<a class="headerlink" href="#id1068" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1069">
<h4>in[0]<a class="headerlink" href="#id1069" title="Permalink to this heading">¶</a></h4>
<p>Input image</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch,height,width,depth]</p></li>
</ul>
</div>
</div>
<div class="section" id="id1070">
<h3>Parameters<a class="headerlink" href="#id1070" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1071">
<h4>align_corners<a class="headerlink" href="#id1071" title="Permalink to this heading">¶</a></h4>
<p>If true, the centers of the 4 corner pixels of the input and output tensors are
aligned, preserving the values at the corner pixels</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: If True half_pixel_centers parameter MUST be false</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="half-pixel-centers">
<h4>half_pixel_centers<a class="headerlink" href="#half-pixel-centers" title="Permalink to this heading">¶</a></h4>
<p>True or False where value 0 is False and any other is True. If true, the pixels
are assumed to be at (0.5,0.5).</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: If True align_corners parameter MUST be false</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1072">
<h3>Outputs<a class="headerlink" href="#id1072" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1073">
<h4>out[0]<a class="headerlink" href="#id1073" title="Permalink to this heading">¶</a></h4>
<p>Output image</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch,new_height,new_width,depth]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="resizenearestneighbor">
<span id="id1074"></span><h2>ResizeNearestNeighbor<a class="headerlink" href="#resizenearestneighbor" title="Permalink to this heading">¶</a></h2>
<p>Resize a 4D image in the height and width dimensions, computing new pixel values by
nearest-neighbor sampling. Image will be distorted if the aspect ratio of the output
does not match the aspect ratio of the input. The output height and width are defined
by the shape of the output tensor, and not computed.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a633997ea5224dc4063d35b9f2b2ab84b">ANEURALNETWORKS_RESIZE_NEAREST_NEIGHBOR</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/image/resize">ResizeMethod.NEAREST_NEIGHBOR</a></p></li>
</ul>
<div class="section" id="id1075">
<h3>Inputs<a class="headerlink" href="#id1075" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1076">
<h4>in[0]<a class="headerlink" href="#id1076" title="Permalink to this heading">¶</a></h4>
<p>Input image</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch,height,width,depth]</p></li>
</ul>
</div>
</div>
<div class="section" id="id1077">
<h3>Parameters<a class="headerlink" href="#id1077" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1078">
<h4>align_corners<a class="headerlink" href="#id1078" title="Permalink to this heading">¶</a></h4>
<p>If true, the centers of the 4 corner pixels of the input and output tensors are
aligned, preserving the values at the corner pixels.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: If True half_pixel_centers parameter MUST be false</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1079">
<h4>half_pixel_centers<a class="headerlink" href="#id1079" title="Permalink to this heading">¶</a></h4>
<p>True or False where value 0 is False and any other is True. If true, the pixels
are assumed to be at (0.5,0.5).</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: If True align_corners parameter MUST be false</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1080">
<h3>Outputs<a class="headerlink" href="#id1080" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1081">
<h4>out[0]<a class="headerlink" href="#id1081" title="Permalink to this heading">¶</a></h4>
<p>Output image</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch,new_height,new_width,depth]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="roialign">
<span id="id1082"></span><h2>RoiAlign<a class="headerlink" href="#roialign" title="Permalink to this heading">¶</a></h2>
<p>Extract rectangular <strong>R</strong>egions <strong>o</strong>f <strong>I</strong>nterest from a feature map, and
scale them to a uniform size by average pooling of bilinearly interpolated sample
points within the region.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a2848b39dd4bfba78f2438fda0d9397a4">ANEURALNETWORKS_ROI_ALIGN</a></p></li>
</ul>
<div class="section" id="id1083">
<h3>Inputs<a class="headerlink" href="#id1083" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1084">
<h4>in[0]<a class="headerlink" href="#id1084" title="Permalink to this heading">¶</a></h4>
<p>Input feature map</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch,height,width,num_features]</p></li>
</ul>
</div>
<div class="section" id="id1085">
<h4>in[1]<a class="headerlink" href="#id1085" title="Permalink to this heading">¶</a></h4>
<p>RoIs : Elements may be interpreted as 4-tuples of (x1,y1,x2,y2)
giving the upper-left and bottom-right corners of the RoI.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois,4]</p></li>
</ul>
</div>
<div class="section" id="id1086">
<h4>in[2]<a class="headerlink" href="#id1086" title="Permalink to this heading">¶</a></h4>
<p>Batch index in the feature map to which each RoI corresponds.
Positions in this input correspond to the same box as the same position in in[1].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32, backend specific</p></li>
<li><p>Shape: [num_rois]</p></li>
</ul>
</div>
</div>
<div class="section" id="id1087">
<h3>Parameters<a class="headerlink" href="#id1087" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1088">
<h4>img_size_ratio<a class="headerlink" href="#id1088" title="Permalink to this heading">¶</a></h4>
<p>The ratio between the original image and the input feature map,
in the form [height_ratio, width_ratio].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: [2] with elements [height_ratio, width_ratio]</p></li>
</ul>
</div>
<div class="section" id="num-samples-y">
<h4>num_samples_y<a class="headerlink" href="#num-samples-y" title="Permalink to this heading">¶</a></h4>
<p>The number of interpolated sample points to use in the height
dimension for each RoI.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: -1</p></li>
</ul>
</div>
<div class="section" id="num-samples-x">
<h4>num_samples_x<a class="headerlink" href="#num-samples-x" title="Permalink to this heading">¶</a></h4>
<p>The number of interpolated sample points to use in the width dimension for
each RoI.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: -1</p></li>
</ul>
</div>
<div class="section" id="aligned">
<h4>aligned<a class="headerlink" href="#aligned" title="Permalink to this heading">¶</a></h4>
<p>If true, shift the box coordinates by -0.5 for a better alignment with the
neighboring pixels.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="allow-invalid-roi">
<h4>allow_invalid_roi<a class="headerlink" href="#allow-invalid-roi" title="Permalink to this heading">¶</a></h4>
<p>When set to true invalid RoIs of in[1] are allowed. An invalid RoI is defined
as having coordinate values where (x2 - x1 = 0) and (y2 - y1 = 0). Note that the
corresponding feature map in out[0] is set to all zeros for the invalid RoI.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_BOOL_8</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id1089">
<h3>Outputs<a class="headerlink" href="#id1089" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1090">
<h4>out[0]<a class="headerlink" href="#id1090" title="Permalink to this heading">¶</a></h4>
<p>Output feature map</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois,out_height,out_width,num_features]. Max and current values may differ for <em>num_rois</em>, and current value will be updated by the backend.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="roipooling">
<span id="id1091"></span><h2>RoiPooling<a class="headerlink" href="#roipooling" title="Permalink to this heading">¶</a></h2>
<p>Extract rectangular <strong>R</strong>egions <strong>o</strong>f <strong>I</strong>nterest from a feature map,
and scale them to a uniform size by max pooling of bilinearly interpolated sample
points within the region.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a6736198af337b2efbdb0b6b64dee7fe4">ANEURALNETWORKS_ROI_POOLING</a></p></li>
</ul>
<div class="section" id="id1092">
<h3>Inputs<a class="headerlink" href="#id1092" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1093">
<h4>in[0]<a class="headerlink" href="#id1093" title="Permalink to this heading">¶</a></h4>
<p>Input feature map</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch,height,width,num_features]</p></li>
</ul>
</div>
<div class="section" id="id1094">
<h4>in[1]<a class="headerlink" href="#id1094" title="Permalink to this heading">¶</a></h4>
<p>RoIs. Elements may be interpreted as 4-tuples of (x1,y1,x2,y2) giving the
upper-left and bottom-right corners of the RoI.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois,4]</p></li>
</ul>
</div>
<div class="section" id="id1095">
<h4>in[2]<a class="headerlink" href="#id1095" title="Permalink to this heading">¶</a></h4>
<p>Batch index in the feature map to which each RoI corresponds. Positions in this
input correspond to the same box as the same position in in[1].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [num_rois]</p></li>
</ul>
</div>
</div>
<div class="section" id="id1096">
<h3>Parameters<a class="headerlink" href="#id1096" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1097">
<h4>img_size_ratio<a class="headerlink" href="#id1097" title="Permalink to this heading">¶</a></h4>
<p>The ratio between the original image and the input feature map, in the form
[height_ratio, width_ratio].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: [2] with elements [height_ratio, width_ratio]</p></li>
</ul>
</div>
</div>
<div class="section" id="id1098">
<h3>Outputs<a class="headerlink" href="#id1098" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1099">
<h4>out[0]<a class="headerlink" href="#id1099" title="Permalink to this heading">¶</a></h4>
<p>Output feature map</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [num_rois,out_height,out_width,num_features]. Max and current values may differ for <em>num_rois</em>, and current value will be updated by the backend.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="scatterelements">
<span id="id1100"></span><h2>ScatterElements<a class="headerlink" href="#scatterelements" title="Permalink to this heading">¶</a></h2>
<p>Takes three input tensors: <em>data</em>, <em>indices</em>, and <em>updates</em> of the same rank N and
optional parameter <em>axis</em> to create an output tensor. Out[0] is produced by creating
a copy of in[0] and then updating it with values that are specified by in[2] at the
index positions specified by in[1]. Note that for each entry in <em>updates</em> the target
index of out[0] is the same index as the entry itself with the exception of the
index-value in the <em>axis</em> dimension which is obtained from <em>indices</em>.</p>
<p>Example for a 3-D tensor case is performed as below with <em>reduction</em> set to
QNN_OP_SCATTER_ELEMENTS_REDUCTION_NONE:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">updates</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">updates</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">updates</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.</span>
</pre></div>
</div>
<p>Example for a 3-D tensor case is performed as below with <em>reduction</em> set to
QNN_OP_SCATTER_ELEMENTS_REDUCTION_ADD:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">updates</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">updates</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">updates</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.</span>
</pre></div>
</div>
<p>Example for a 3-D tensor case is performed as below with <em>reduction</em> set to
QNN_OP_SCATTER_ELEMENTS_REDUCTION_MUL:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">updates</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">updates</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]]</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">updates</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#ScatterElements">ops::ScatterElements</a></p></li>
</ul>
<div class="section" id="id1101">
<h3>Inputs<a class="headerlink" href="#id1101" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1102">
<h4>in[0]<a class="headerlink" href="#id1102" title="Permalink to this heading">¶</a></h4>
<p>input data</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1103">
<h4>in[1]<a class="headerlink" href="#id1103" title="Permalink to this heading">¶</a></h4>
<p>indices : contains the index values used in the <em>axis</em> dimension to scatter
<em>updates</em>.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32, QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Indices must be in range [0, Shape(in[0])[<em>axis</em>] - 1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1104">
<h4>in[2]<a class="headerlink" href="#id1104" title="Permalink to this heading">¶</a></h4>
<p>updates : values to scatter into out[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same shape as in[1]</p></li>
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1105">
<h3>Parameters<a class="headerlink" href="#id1105" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1106">
<h4>axis<a class="headerlink" href="#id1106" title="Permalink to this heading">¶</a></h4>
<p>The axis of out[0] to scatter on.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be in range [0, N - 1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="reduction">
<h4>reduction<a class="headerlink" href="#reduction" title="Permalink to this heading">¶</a></h4>
<p>Operation that is applied to all update values of in[2] to out[0] at the
specified indices from in[1]. When <em>reduction</em> is set to “NONE”, values in in[2]
are assigned to out[0] at the indices specified by in[1] and duplicate indices
will override previous updated values. When <em>reduction</em> is set to “ADD”, values
in in[2] are added to the values of out[0] at the indices specified by in[1] and
duplicate indices are allowed. When <em>reduction</em> is set to “MUL”, values in in[2]
are multiplied to the values of out[0] at the indices specified by in[1] and
duplicate indices are allowed.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>NONE = 0,</p></li>
<li><p>ADD = 1,</p></li>
<li><p>MUL = 2</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1107">
<h3>Outputs<a class="headerlink" href="#id1107" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1108">
<h4>out[0]<a class="headerlink" href="#id1108" title="Permalink to this heading">¶</a></h4>
<p>Output data</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same shape as in[0]</p></li>
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="scatternd">
<span id="id1109"></span><h2>ScatterNd<a class="headerlink" href="#scatternd" title="Permalink to this heading">¶</a></h2>
<p>Takes three input tensors: data, indices, and updates to create an output tensor.
out[0] is produced by creating a copy of in[0] and then updating it with values that
are specified by in[2] at the index positions specified by in[1].</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ScatterND">ops::ScatterND</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/scatter_nd">ops::scatter_nd</a></p></li>
</ul>
<div class="section" id="id1110">
<h3>Inputs<a class="headerlink" href="#id1110" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1111">
<h4>in[0]<a class="headerlink" href="#id1111" title="Permalink to this heading">¶</a></h4>
<p>input data</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank n</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1112">
<h4>in[1]<a class="headerlink" href="#id1112" title="Permalink to this heading">¶</a></h4>
<p>Tensor of indices to scatter updates to create output tensor. Note that when
Shape(in[1])[-1] is equal to <em>n</em> each value of in[2] is specific to a
single element of out[0]. Otherwise when Shape(in[1])[-1] is less
than <em>n</em> each value of in[2] is specific to a slice of the output tensor.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32, QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: a tensor of rank k</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
<li><p>Shape: Shape(in[1])[-1] must be &gt;= 0 and &lt;= n</p></li>
<li><p>Value: Indices can not be out of range of in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1113">
<h4>in[2]<a class="headerlink" href="#id1113" title="Permalink to this heading">¶</a></h4>
<p>Updates to scatter into the output tensor</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank n + k - Shape(in[1])[-1] - 1, where <em>n</em> is the rank of in[0] and <em>k</em> is the rank of in[1].</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank = n + k - Shape(in[1])[-1] - 1</p></li>
<li><p>Shape: The number of slices/elements to update should be equal to the number of indices provided.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1114">
<h3>Parameters<a class="headerlink" href="#id1114" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1115">
<h4>reduction<a class="headerlink" href="#id1115" title="Permalink to this heading">¶</a></h4>
<p>Operation that is applied to all update values of in[2] to out[0] at the
specified indices from in[1]. When <em>reduction</em> is set to “NONE”, values in in[2]
are assigned to out[0] at the indices specified by in[1] and duplicate indices
will override previous updated values. When <em>reduction</em> is set to “ADD”, values
in in[2] are added to the values of out[0] at the indices specified by in[1] and
duplicate indices are allowed. When <em>reduction</em> is set to “MUL”, values in in[2]
are multiplied to the values of out[0] at the indices specified by in[1] and
duplicate indices are allowed.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>NONE = 0,</p></li>
<li><p>ADD = 1,</p></li>
<li><p>MUL = 2</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1116">
<h3>Outputs<a class="headerlink" href="#id1116" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1117">
<h4>out[0]<a class="headerlink" href="#id1117" title="Permalink to this heading">¶</a></h4>
<p>Output data</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank n</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same shape as in[0]</p></li>
<li><p>Datatype: Same datatype as in[2]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="shape">
<span id="id1118"></span><h2>Shape<a class="headerlink" href="#shape" title="Permalink to this heading">¶</a></h2>
<p>Generates a 1D output tensor containing the shape of the input tensor. Parameters
<em>start</em> and <em>end</em> can be used to compute a slice of the input tensor’s shape.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#Shape">ops::Shape</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/shape">Shape</a></p></li>
</ul>
<div class="section" id="id1120">
<h3>Inputs<a class="headerlink" href="#id1120" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1121">
<h4>in[0]<a class="headerlink" href="#id1121" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of N dimension</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1122">
<h3>Parameters<a class="headerlink" href="#id1122" title="Permalink to this heading">¶</a></h3>
<div class="section" id="start">
<h4>start<a class="headerlink" href="#start" title="Permalink to this heading">¶</a></h4>
<p>Starting axis for slicing the shape of the input tensor. Note that the start
axis is inclusive and will include the size of the start axis in the output
tensor.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: <em>start</em> must be in range [0, N-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="end">
<h4>end<a class="headerlink" href="#end" title="Permalink to this heading">¶</a></h4>
<p>Ending axis for slicing the shape of the input tensor. Note that the end axis
specified is exclusive and will not include the size of the end axis in the
output tensor.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: <em>end</em> must be in range [<em>start</em> + 1, N]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1123">
<h3>Outputs<a class="headerlink" href="#id1123" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1124">
<h4>out[0]<a class="headerlink" href="#id1124" title="Permalink to this heading">¶</a></h4>
<p>Shape of the input tensor.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: 1D of shape [M] where M = <em>end</em> - <em>start</em></p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="sigmoid">
<span id="id1125"></span><h2>Sigmoid<a class="headerlink" href="#sigmoid" title="Permalink to this heading">¶</a></h2>
<p>Computes the sigmoid activation function elementwise on an input tensor.
The sigmoid function is defined as</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>where <em>exp</em> is exponentiation by the base of the natural logarithm.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a82a340eb540933f638db420369650483">ANEURALNETWORKS_LOGISTIC</a></p></li>
</ul>
<div class="section" id="id1127">
<h3>Inputs<a class="headerlink" href="#id1127" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1128">
<h4>in[0]<a class="headerlink" href="#id1128" title="Permalink to this heading">¶</a></h4>
<p>Input feature map.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1129">
<h3>Parameters<a class="headerlink" href="#id1129" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id1130">
<h3>Outputs<a class="headerlink" href="#id1130" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1131">
<h4>out[0]<a class="headerlink" href="#id1131" title="Permalink to this heading">¶</a></h4>
<p>Output feature map.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="softmax">
<span id="id1132"></span><h2>Softmax<a class="headerlink" href="#softmax" title="Permalink to this heading">¶</a></h2>
<p>Computes data normalization exponentially on an input tensor given an optional
positive scaling factor, beta. The computation is done element-wise per batch along
the specified axis.</p>
<p>See Softmax backend definition for supported datatypes and constraints per backend</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a2bfbb83a537701e2843a3d5004250c2c">ANEURALNETWORKS_SOFTMAX</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax">Softmax</a></p></li>
</ul>
<div class="section" id="id1134">
<h3>Inputs<a class="headerlink" href="#id1134" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1135">
<h4>in[0]<a class="headerlink" href="#id1135" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of N dimension</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1136">
<h3>Parameters<a class="headerlink" href="#id1136" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1137">
<h4>axis<a class="headerlink" href="#id1137" title="Permalink to this heading">¶</a></h4>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: N-1</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: must be in range [0, N-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1138">
<h4>beta<a class="headerlink" href="#id1138" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_FLOAT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1.0</p></li>
</ul>
</div>
</div>
<div class="section" id="id1139">
<h3>Outputs<a class="headerlink" href="#id1139" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1140">
<h4>out[0]<a class="headerlink" href="#id1140" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of N dimension</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="spacetobatch">
<span id="id1141"></span><h2>SpaceToBatch<a class="headerlink" href="#spacetobatch" title="Permalink to this heading">¶</a></h2>
<p>A type of tensor realignment operation that rearranges blocks of spatial data
in batch dimension.</p>
<p>The op moves blocks of data of size (block_size[0] * block_size[1]) from the
height and width dimensions of the input tensor into the
batch dimension of the output tensor after optional padding.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/space_to_batch">Space To Batch</a></p></li>
</ul>
<div class="section" id="id1142">
<h3>Inputs<a class="headerlink" href="#id1142" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1143">
<h4>in[0]<a class="headerlink" href="#id1143" title="Permalink to this heading">¶</a></h4>
<p>Input Activation.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D tensor of shape [batch, height, width, depth]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: height must be divisible by block_size[0] after any paddings have been applied.</p></li>
<li><p>Shape: width must be divisible by block_size[1] after any paddings have been applied.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1144">
<h3>Parameters<a class="headerlink" href="#id1144" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1145">
<h4>block_size<a class="headerlink" href="#id1145" title="Permalink to this heading">¶</a></h4>
<p>Vector that represents block size along the <em>height</em> and <em>width</em>
dimensions respectively.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] with format [block_height, block_width]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Elements must be &gt;=1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1146">
<h4>pad_amount<a class="headerlink" href="#id1146" title="Permalink to this heading">¶</a></h4>
<p>Paddings along the height and width dimensions of the input tensor.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2,2] with format [[pad_top, pad_bottom], [pad_left, pad_right]]</p></li>
<li><p>Default: [[0, 0], [0, 0]]</p></li>
</ul>
</div>
</div>
<div class="section" id="id1147">
<h3>Outputs<a class="headerlink" href="#id1147" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1148">
<h4>out[0]<a class="headerlink" href="#id1148" title="Permalink to this heading">¶</a></h4>
<p>Output Activation.</p>
<p>Permuted output tensor with new spatial dimensions
[<em>output_height</em>, <em>output_width</em>] defined by</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">output_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_top</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_bottom</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">output_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_left</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">pad_right</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D tensor of shape [(batch * block_size[0] * block_size[1]), output_height, output_width, depth]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="spacetodepth">
<span id="id1149"></span><h2>SpaceToDepth<a class="headerlink" href="#spacetodepth" title="Permalink to this heading">¶</a></h2>
<p>A type of tensor realignment operation that rearranges blocks of
spatial data into depth.</p>
<p>The op moves blocks of data of size (block_size[0] * block_size[1]) from the
height and width dimensions of the input tensor into the
depth dimension of the output tensor.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a90099ec472f6571a932b111d979dcccd">ANEURALNETWORKS_SPACE_TO_DEPTH</a></p></li>
</ul>
<div class="section" id="id1150">
<h3>Inputs<a class="headerlink" href="#id1150" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1151">
<h4>in[0]<a class="headerlink" href="#id1151" title="Permalink to this heading">¶</a></h4>
<p>Input Activation.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D tensor of shape [batch, height, width, depth]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: height must be divisible by block_size[0]</p></li>
<li><p>Shape: width must be divisible by block_size[1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1152">
<h3>Parameters<a class="headerlink" href="#id1152" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1153">
<h4>block_size<a class="headerlink" href="#id1153" title="Permalink to this heading">¶</a></h4>
<p>Vector that represents block size along the <em>height</em> and <em>width</em> dimensions
respectively.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] with format [block_height, block_width]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Elements must be &gt;=1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1154">
<h4>mode<a class="headerlink" href="#id1154" title="Permalink to this heading">¶</a></h4>
<p>Specifies the order in which elements of in[0] are rearranged. If
QNN_OP_SPACE_TO_DEPTH_PARAM_MODE is set to QNN_OP_SPACE_TO_DEPTH_MODE_DCR then
elements along the depth dimension are rearranged in the order of depth, column,
and then row; if set to QNN_OP_SPACE_TO_DEPTH_MODE_CRD elements along the depth
dimension are rearranged in the order of column, row, and then depth.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Values:</p>
<blockquote>
<div><ul class="simple">
<li><p>DCR = 0,</p></li>
<li><p>CRD = 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1155">
<h3>Outputs<a class="headerlink" href="#id1155" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1156">
<h4>out[0]<a class="headerlink" href="#id1156" title="Permalink to this heading">¶</a></h4>
<p>Output Activation.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: 4D tensor of shape [batch, (height / block_size[0]), (width / block_size[1]), (depth * block_size[0] * block_size[1])]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="sparsetodense">
<span id="id1157"></span><h2>SparseToDense<a class="headerlink" href="#sparsetodense" title="Permalink to this heading">¶</a></h2>
<p>Convert a sparse tensor to a dense tensor.</p>
<p>References:</p>
<ul class="simple">
<li><p>QNN: <a class="reference internal" href="#createsparse">CreateSparse</a></p></li>
<li><p>QNN: <a class="reference internal" href="#getsparseindices">GetSparseIndices</a></p></li>
<li><p>QNN: <a class="reference internal" href="#getsparsevalues">GetSparseValues</a></p></li>
</ul>
<div class="section" id="id1158">
<h3>Inputs<a class="headerlink" href="#id1158" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1159">
<h4>in[0]<a class="headerlink" href="#id1159" title="Permalink to this heading">¶</a></h4>
<p>input</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Must be a sparse tensor.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1160">
<h3>Parameters<a class="headerlink" href="#id1160" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id1161">
<h3>Outputs<a class="headerlink" href="#id1161" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1162">
<h4>out[0]<a class="headerlink" href="#id1162" title="Permalink to this heading">¶</a></h4>
<p>output</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Must not be a sparse tensor.</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="split">
<span id="id1163"></span><h2>Split<a class="headerlink" href="#split" title="Permalink to this heading">¶</a></h2>
<p>Splits input tensor along a given <em>axis</em> into multiple output tensors according
to <em>split_index</em>.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0afb787314a8631fe847f1fd93cfd576a7">ANEURALNETWORKS_SPLIT</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Split">ops::Split</a></p></li>
</ul>
<div class="section" id="id1164">
<h3>Inputs<a class="headerlink" href="#id1164" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1165">
<h4>in[0]<a class="headerlink" href="#id1165" title="Permalink to this heading">¶</a></h4>
<p>Input data</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1166">
<h3>Parameters<a class="headerlink" href="#id1166" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1167">
<h4>axis<a class="headerlink" href="#id1167" title="Permalink to this heading">¶</a></h4>
<p>Specifies axis to split on.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: must be in range [0, N-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="split-index">
<h4>split_index<a class="headerlink" href="#split-index" title="Permalink to this heading">¶</a></h4>
<p>1-D tensor specifying starting index of each split slice in <em>axis</em>.
Index values must be in range [1, shape(in[0])[axis]-1] and
split_index[i+1] &gt; split_index[i]. <em>axis</em> is split into size(split_index)+1
slices.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [M]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: M &lt;= shape(in[0])[axis]</p></li>
<li><p>Value: Must be in range [1, shape(in[0])[axis]-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1168">
<h3>Outputs<a class="headerlink" href="#id1168" title="Permalink to this heading">¶</a></h3>
<div class="section" id="out-0-m">
<h4>out[0..m]<a class="headerlink" href="#out-0-m" title="Permalink to this heading">¶</a></h4>
<p>Resulting (M+1) output data tensors.</p>
<p>This tensor is repeated, meaning the same definition can apply to multiple tensors.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: rank(out[m]) = rank(in[0]), where sum(m, size(shape(out[m])[axis])) = size(shape(in[0])[axis])</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same rank as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="squeeze">
<span id="id1169"></span><h2>Squeeze<a class="headerlink" href="#squeeze" title="Permalink to this heading">¶</a></h2>
<p>Removes dimensions of size 1 from the shape of the input tensor in[0].
The number of elements implied by output tensor must be the same as the input tensor.
This functionality can also be achieved using the <a class="reference internal" href="#reshape">Reshape</a> operation. Note that
user can prevent removing certain dimensions of size 1 by expressing as such in
shape(out[0]).</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a1207019989837ee9d10c5b6663504933">ANEURALNETWORKS_SQUEEZE</a></p></li>
</ul>
<div class="section" id="id1170">
<h3>Inputs<a class="headerlink" href="#id1170" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1171">
<h4>in[0]<a class="headerlink" href="#id1171" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Rank = N, N &gt; 1</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 1</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1172">
<h3>Parameters<a class="headerlink" href="#id1172" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id1173">
<h3>Outputs<a class="headerlink" href="#id1173" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1174">
<h4>out[0]<a class="headerlink" href="#id1174" title="Permalink to this heading">¶</a></h4>
<p>output activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank M</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: M &lt;= rank(in[0])</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="stridedslice">
<span id="id1175"></span><h2>StridedSlice<a class="headerlink" href="#stridedslice" title="Permalink to this heading">¶</a></h2>
<p>Extract “slices” from a tensor by sampling in each dimension. Parameters are applied
in the following order: <em>new_axes_mask</em>, <em>ranges</em>/<em>end_mask</em>/<em>begin_mask</em>, and then
<em>shrink_axis</em>. <em>new_axis_mask</em> is applied to the input tensor to create an
<em>intermediate tensor</em> and all other parameters are applied in respect to this
<em>intermediate tensor</em>. If <em>new_axis_mask</em> is not provided then these parameters are
applied directly to the input tensor.
Equivalent to python:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">begin</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">:</span><span class="n">end</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">:</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">],...,</span><span class="n">begin</span><span class="p">[</span><span class="n">n</span><span class="mi">-1</span><span class="p">]</span><span class="o">:</span><span class="n">end</span><span class="p">[</span><span class="n">n</span><span class="mi">-1</span><span class="p">]</span><span class="o">:</span><span class="n">stride</span><span class="p">[</span><span class="n">n</span><span class="mi">-1</span><span class="p">]]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a89695302f8b1e7ae7ce8f4d8c0b8a752">ANEURALNETWORKS_STRIDED_SLICE</a></p></li>
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/strided_slice">strided_slice</a></p></li>
</ul>
<div class="section" id="id1176">
<h3>Inputs<a class="headerlink" href="#id1176" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1177">
<h4>in[0]<a class="headerlink" href="#id1177" title="Permalink to this heading">¶</a></h4>
<p>Input data</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank n</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1178">
<h3>Parameters<a class="headerlink" href="#id1178" title="Permalink to this heading">¶</a></h3>
<div class="section" id="ranges">
<h4>ranges<a class="headerlink" href="#ranges" title="Permalink to this heading">¶</a></h4>
<p>Specifies the slice range for each axis, in the form (begin,end,stride).
Begin must be in the range [0, shape(in[0])[i] - 1] and end must be in the range
[-1, shape(in[0])[i]]. Strides may be negative if begin[i] &gt;= end[i]. For a
negative stride to include index 0, we permit the end of the range to be -1.
Note that ranges extend “one past the end” similar to a C++ iterator, but the
slice will include the begin index.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: [rank(in[0]) + new,3] : [[begin_0, end_0, stride_0], …. , [begin_{n+new-1}, end_{n+new-1}, stride_{n+new-1}]], where <em>new</em> is the number of new axes that will be inserted.</p></li>
</ul>
</div>
<div class="section" id="begin-mask">
<h4>begin_mask<a class="headerlink" href="#begin-mask" title="Permalink to this heading">¶</a></h4>
<p>A bit mask corresponding to the begin axes of ranges that indicates whether
certain axes of the intermediate tensor are to be retained or ignored during
the slicing. If the ith bit of begin_mask is set, ranges[i][0] will be ignored
and the fullest possible range in that dimension is used instead.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="end-mask">
<h4>end_mask<a class="headerlink" href="#end-mask" title="Permalink to this heading">¶</a></h4>
<p>A bit mask corresponding to the end axes of ranges that indicates whether
certain axes of the intermediate tensor are to be retained or ignored during
the slicing. If the ith bit of end_mask is set, ranges[i][1] will be ignored
and the fullest possible range in that dimension is used instead.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="shrink-axes">
<h4>shrink_axes<a class="headerlink" href="#shrink-axes" title="Permalink to this heading">¶</a></h4>
<p>A bit mask corresponding to the axes of the intermediate tensor to omit in
the output shape. If the ith bit of <em>new_axes_mask</em> is also set it overrides any
shrink_axes setting at the same bit. All bits set beyond the shape of the
intermediate tensor will be ignored. Note that the begin range provided for any
axes that is omitted will be used in respect to the other axes. E.g. Given a 3-D
shape [10, 20, 30] and only the 0th axis being omitted by shrink_axes and the
entire range is used for the other 2 axes. If range[0][0] = 5, which is the
begin value for the 0th axis, then the output shape would be a 2-D shape of
[20, 30] corresponding to the 6th slice of the 0th dimension.</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
<div class="section" id="new-axes-mask">
<h4>new_axes_mask<a class="headerlink" href="#new-axes-mask" title="Permalink to this heading">¶</a></h4>
<p>A bit mask to insert new axes at positions specified by the set bits. If the ith
bit in new_axes_mask is set, a new length 1 dimension is inserted into the input
tensor at this position and an intermediate tensor is created. <em>ranges</em>,
<em>end_mask</em>, <em>begin_mask</em> applied to positions where a new axes has been inserted
are ignored since any new axes will always be size 1.</p>
<p>Notes:</p>
<ul class="simple">
<li><p>The most significant bit of new_axes_mask is defined by the number of <em>ranges</em>
provided by the user, e.g. Given 8 sets of ranges the most significant bit
would be the 7th bit.</p></li>
<li><p>From the 0th bit to the most significant bit in new_axis_mask there must be
exactly rank(in[0]) number of unset bits.</p></li>
<li><p>All bits past the most significant bit will be ignored.</p></li>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
</ul>
</div>
</div>
<div class="section" id="id1179">
<h3>Outputs<a class="headerlink" href="#id1179" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1180">
<h4>out[0]<a class="headerlink" href="#id1180" title="Permalink to this heading">¶</a></h4>
<p>Output data</p>
<p>Dimension at axis i is max(1, ceil( (ranges[i,1]-ranges[i,0])/ranges[i,2] ) ),
except where omitted by <em>shrink_axes</em>, or ‘1’ where specified by <em>new_axes_mask</em>.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: rank is rank(in[0]) + new - shrink, where <em>new</em> is the number of new axes that will be inserted and <em>shrink</em> is the number of axes that will be omitted.</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="tanh">
<span id="id1181"></span><h2>Tanh<a class="headerlink" href="#tanh" title="Permalink to this heading">¶</a></h2>
<p>Computes the hyperbolic tangent function elementwise over an input feature map.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a4b63c9caab823f112d82d853a77381e5">ANEURALNETWORKS_TANH</a></p></li>
</ul>
<div class="section" id="id1183">
<h3>Inputs<a class="headerlink" href="#id1183" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1184">
<h4>in[0]<a class="headerlink" href="#id1184" title="Permalink to this heading">¶</a></h4>
<p>Input feature map.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1185">
<h3>Parameters<a class="headerlink" href="#id1185" title="Permalink to this heading">¶</a></h3>
<p>None</p>
</div>
<div class="section" id="id1186">
<h3>Outputs<a class="headerlink" href="#id1186" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1187">
<h4>out[0]<a class="headerlink" href="#id1187" title="Permalink to this heading">¶</a></h4>
<p>Output feature map.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: Any</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
<li><p>Shape: Same shape as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="tile">
<span id="id1188"></span><h2>Tile<a class="headerlink" href="#tile" title="Permalink to this heading">¶</a></h2>
<p>Creates a new tensor by tiling an input tensor. The input tensor is replicated along
each dimension for as many times as specified by the multiples tensor.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">multiples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0aae56dc75c058291cee272a537978ecd3">ANEURALNETWORKS_TILE</a></p></li>
</ul>
<div class="section" id="id1189">
<h3>Inputs<a class="headerlink" href="#id1189" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1190">
<h4>in[0]<a class="headerlink" href="#id1190" title="Permalink to this heading">¶</a></h4>
<p>Input tensor</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1191">
<h3>Parameters<a class="headerlink" href="#id1191" title="Permalink to this heading">¶</a></h3>
<div class="section" id="multiples">
<h4>multiples<a class="headerlink" href="#multiples" title="Permalink to this heading">¶</a></h4>
<p>A 1D tensor of length N which contains the replication factor for each
dimension.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [N], N = rank(in[0])</p></li>
</ul>
</div>
</div>
<div class="section" id="id1192">
<h3>Outputs<a class="headerlink" href="#id1192" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1193">
<h4>out[0]<a class="headerlink" href="#id1193" title="Permalink to this heading">¶</a></h4>
<p>The tiled output tensor</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">multiples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="topk">
<span id="id1194"></span><h2>TopK<a class="headerlink" href="#topk" title="Permalink to this heading">¶</a></h2>
<p>Find the K largest values along the last dimension at each position in a tensor,
and return those values sorted, along with their indices in the input tensor.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0afb989792e22adaaa6fb540ae8415f562">ANEURALNETWORKS_TOPK_V2</a></p></li>
</ul>
<div class="section" id="id1195">
<h3>Inputs<a class="headerlink" href="#id1195" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1196">
<h4>in[0]<a class="headerlink" href="#id1196" title="Permalink to this heading">¶</a></h4>
<p>Input tensor</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1197">
<h3>Parameters<a class="headerlink" href="#id1197" title="Permalink to this heading">¶</a></h3>
<div class="section" id="k">
<h4>k<a class="headerlink" href="#k" title="Permalink to this heading">¶</a></h4>
<p>The number of elements to extract from the input tensor at each position.
Must be &lt;= shape(in[0])[rank(in[0])-1].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
</ul>
</div>
</div>
<div class="section" id="id1198">
<h3>Outputs<a class="headerlink" href="#id1198" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1199">
<h4>out[0]<a class="headerlink" href="#id1199" title="Permalink to this heading">¶</a></h4>
<p>Sorted largest values of input tensor at each position.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: same as in[0], except the last dimension which is <em>k</em></p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1200">
<h4>out[1]<a class="headerlink" href="#id1200" title="Permalink to this heading">¶</a></h4>
<p>Index values of elements of out[0] in in[0]. If two elements of out[0] in the
same position have the same value, the one with the larger index will appear
first.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32, QNN_DATATYPE_INT_32</p></li>
<li><p>Shape: same as in[0], except the last dimension which is <em>k</em></p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Same shape as out[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="transpose">
<span id="id1201"></span><h2>Transpose<a class="headerlink" href="#transpose" title="Permalink to this heading">¶</a></h2>
<p>Transposes the input tensor to produce an output with the same data but axes
permuted according to the perm tensor.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">perm</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li><p>Android NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a92d7bc95eb68525334b6cfe80cd271ee">ANEURALNETWORKS_TRANSPOSE</a></p></li>
</ul>
<div class="section" id="id1202">
<h3>Inputs<a class="headerlink" href="#id1202" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1203">
<h4>in[0]<a class="headerlink" href="#id1203" title="Permalink to this heading">¶</a></h4>
<p>Input tensor</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1204">
<h3>Parameters<a class="headerlink" href="#id1204" title="Permalink to this heading">¶</a></h3>
<div class="section" id="perm">
<h4>perm<a class="headerlink" href="#perm" title="Permalink to this heading">¶</a></h4>
<p>The permutations of the dimensions of the input tensor. The tensor values should
be in range [0,N-1] and each dimension must be listed only once.</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [N], N = rank(in[0])</p></li>
</ul>
</div>
</div>
<div class="section" id="id1205">
<h3>Outputs<a class="headerlink" href="#id1205" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1206">
<h4>out[0]<a class="headerlink" href="#id1206" title="Permalink to this heading">¶</a></h4>
<p>The permuted output tensor</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="transposeconv1d">
<span id="id1207"></span><h2>TransposeConv1d<a class="headerlink" href="#transposeconv1d" title="Permalink to this heading">¶</a></h2>
<p>Performs the transpose 1D convolution operation. This operation is also known as
“Deconvolution”. Application of the filter moves according to the specified stride.
For backends supporting quantized data types, clients can pass filters which are
either quantized per-tensor or per-axis with possible constraints on the axis value
that is supported.</p>
<p>For regular transpose convolution, <em>group</em> is 1. Group field greater than 1 implies
a grouped transpose convolution where a group of different filters is applied to
each output channel group and the result is concatenated together.</p>
<p>References:</p>
<ul class="simple">
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose">ConvTranspose</a></p></li>
</ul>
<div class="section" id="id1208">
<h3>Inputs<a class="headerlink" href="#id1208" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1209">
<h4>in[0]<a class="headerlink" href="#id1209" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, width, channel_in]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: channel_in must be evenly divisible by group</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1210">
<h4>in[1]<a class="headerlink" href="#id1210" title="Permalink to this heading">¶</a></h4>
<p>filters</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [filter_width, channel_in, channel_out/group]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: channel_out must be evenly divisible by group</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1211">
<h4>in[2]<a class="headerlink" href="#id1211" title="Permalink to this heading">¶</a></h4>
<p>biases</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [channel_out]</p></li>
<li><p>Default: {0,..,0}</p></li>
</ul>
</div>
</div>
<div class="section" id="id1212">
<h3>Parameters<a class="headerlink" href="#id1212" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1213">
<h4>stride<a class="headerlink" href="#id1213" title="Permalink to this heading">¶</a></h4>
<p>Defines stride for 1D spatial (i.e. width) axes of in[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1214">
<h4>pad_amount<a class="headerlink" href="#id1214" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 1D spatial
(i.e. width) axes of in[0].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] with format [width_pad_before, width_pad_after]</p></li>
</ul>
</div>
<div class="section" id="id1215">
<h4>group<a class="headerlink" href="#id1215" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="output-padding">
<h4>output_padding<a class="headerlink" href="#output-padding" title="Permalink to this heading">¶</a></h4>
<p>Controls the additional size added to the 1D spatial axes (i.e width) of the
output shape. Note that output_padding is only used to find output shape, but
does not actually add zero-padding to output.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 0</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Must be &lt; stride</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1216">
<h3>Outputs<a class="headerlink" href="#id1216" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1217">
<h4>out[0]<a class="headerlink" href="#id1217" title="Permalink to this heading">¶</a></h4>
<p>The output 1D spatial dimensions is a function of the filters, stride, and
pad_amount.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">width_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">(</span><span class="n">stride</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">output_padding</span><span class="p">)</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, width_out, channel_out]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="transposeconv2d">
<span id="id1218"></span><h2>TransposeConv2d<a class="headerlink" href="#transposeconv2d" title="Permalink to this heading">¶</a></h2>
<p>Performs the transpose 2D convolution operation. This operation is also known as
“Deconvolution”. Application of the filter moves according to the specified strides.
For backends supporting quantized data types, clients can pass filters which are
either quantized per-tensor or per-axis with possible constraints on the axis value
that is supported.</p>
<p>For regular transpose convolution, <em>group</em> is 1. Group field greater than 1 implies
a grouped transpose convolution where a group of different filters is applied to
each output channel group and the result is concatenated together. Note that
<em>channel_out</em> and <em>channel_in</em> must be evenly divisible by <em>group</em>.</p>
<p>Refer to TransposeConv2d backend definition for supported data type and layouts for
each backend.</p>
<p>References:</p>
<ul class="simple">
<li><p>Android NDK NeuralNetworks: <a class="reference external" href="https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a5ac65e772b035ddb27c18236752aa1fd">ANEURALNETWORKS_TRANSPOSE_CONV_2D</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose">ConvTranspose</a></p></li>
<li><p>QNN: <a class="reference internal" href="#conv2d">Conv2d</a></p></li>
</ul>
<div class="section" id="id1220">
<h3>Inputs<a class="headerlink" href="#id1220" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1221">
<h4>in[0]<a class="headerlink" href="#id1221" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height, width, channel_in]</p></li>
</ul>
</div>
<div class="section" id="id1222">
<h4>in[1]<a class="headerlink" href="#id1222" title="Permalink to this heading">¶</a></h4>
<p>filters</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [filter_height, filter_width, channel_in, channel_out/group]</p></li>
</ul>
</div>
<div class="section" id="id1223">
<h4>in[2]<a class="headerlink" href="#id1223" title="Permalink to this heading">¶</a></h4>
<p>biases</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [channel_out]</p></li>
<li><p>Default: [0]</p></li>
</ul>
</div>
</div>
<div class="section" id="id1224">
<h3>Parameters<a class="headerlink" href="#id1224" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1225">
<h4>stride<a class="headerlink" href="#id1225" title="Permalink to this heading">¶</a></h4>
<p>Defines stride for 2D spatial (i.e. height and width) axes of in[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] : [height_stride, width_stride]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Strides must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1226">
<h4>pad_amount<a class="headerlink" href="#id1226" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 2D spatial
(i.e. height and width) axes of in[0].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2,2] with format [[height_pad_before, height_pad_after], [width_pad_before, width_pad_after]]</p></li>
</ul>
</div>
<div class="section" id="id1227">
<h4>group<a class="headerlink" href="#id1227" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="id1228">
<h4>output_padding<a class="headerlink" href="#id1228" title="Permalink to this heading">¶</a></h4>
<p>Controls the additional size added to the 2D spatial axes (i.e height and width)
of the output shape. Note that output_padding is only used to find output shape,
but does not actually add zero-padding to output.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [2] with format [height_output_padding, width_output_padding]</p></li>
<li><p>Default: [0, 0]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: must be &lt; corresponding strides dimension</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1229">
<h3>Outputs<a class="headerlink" href="#id1229" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1230">
<h4>out[0]<a class="headerlink" href="#id1230" title="Permalink to this heading">¶</a></h4>
<p>The output 2D spatial dimensions are functions of the filters, stride, and
pad_amount.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">height_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">(</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">output_padding</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">width_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">(</span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">output_padding</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, height_out, width_out, channel_out]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="transposeconv3d">
<span id="id1231"></span><h2>TransposeConv3d<a class="headerlink" href="#transposeconv3d" title="Permalink to this heading">¶</a></h2>
<p>Performs the transpose 3D convolution operation. This operation is also known as
“Deconvolution”. Application of the filter moves according to the specified strides.
For backends supporting quantized data types, clients can pass filters which are
either quantized per-tensor or per-axis with possible constraints on the axis value
that is supported.</p>
<p>For regular transpose convolution, <em>group</em> is 1. Group field greater than 1 implies
a grouped transpose convolution where a group of different filters is applied to
each output channel group and the result is concatenated together. Note that
<em>channel_out</em> and <em>channel_in</em> must be evenly divisible by <em>group</em>.</p>
<p>Refer to TransposeConv3d backend definition for supported data type and layouts for
each backend.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/conv3d_transpose">conv3d_transpose</a></p></li>
<li><p>ONNX: <a class="reference external" href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose">ConvTranspose</a></p></li>
</ul>
<div class="section" id="id1233">
<h3>Inputs<a class="headerlink" href="#id1233" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1234">
<h4>in[0]<a class="headerlink" href="#id1234" title="Permalink to this heading">¶</a></h4>
<p>input activation</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, depth, height, width, channel_in]</p></li>
</ul>
</div>
<div class="section" id="id1235">
<h4>in[1]<a class="headerlink" href="#id1235" title="Permalink to this heading">¶</a></h4>
<p>filters</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [filter_depth, filter_height, filter_width, channel_in, channel_out/group]</p></li>
</ul>
</div>
<div class="section" id="id1236">
<h4>in[2]<a class="headerlink" href="#id1236" title="Permalink to this heading">¶</a></h4>
<p>biases</p>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [channel_out]</p></li>
<li><p>Default: [0]</p></li>
</ul>
</div>
</div>
<div class="section" id="id1237">
<h3>Parameters<a class="headerlink" href="#id1237" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1238">
<h4>stride<a class="headerlink" href="#id1238" title="Permalink to this heading">¶</a></h4>
<p>Defines stride for 3D spatial (i.e. depth, height and width) axes of in[0].</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3] : [depth_stride, height_stride, width_stride]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Strides must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1239">
<h4>pad_amount<a class="headerlink" href="#id1239" title="Permalink to this heading">¶</a></h4>
<p>Pad amount to be added to the beginning and end part of 3D spatial (i.e. depth,
height, and width) axes of in[0].</p>
<ul class="simple">
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3,2] with format [[depth_pad_before, depth_pad_after], [height_pad_before, height_pad_after], [width_pad_before, width_pad_after]]</p></li>
</ul>
</div>
<div class="section" id="id1240">
<h4>dilation<a class="headerlink" href="#id1240" title="Permalink to this heading">¶</a></h4>
<p>Dilation value along each spatial axis (i.e. depth, height, and width) of the
filter.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3] : [depth_dilation, height_dilation, width_dilation]</p></li>
<li><p>Default: [1, 1, 1]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: Dilations must be &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id1241">
<h4>group<a class="headerlink" href="#id1241" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Default: 1</p></li>
</ul>
</div>
<div class="section" id="id1242">
<h4>output_padding<a class="headerlink" href="#id1242" title="Permalink to this heading">¶</a></h4>
<p>Controls the additional size added to the 3D spatial axes (i.e depth, height,
and width) of the output shape. Note that output_padding is only used to find
output shape, but does not actually add zero-padding to output.</p>
<ul>
<li><p>Mandatory: false</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: [3] : [depth_output_padding, height_output_padding, width_output_padding]</p></li>
<li><p>Default: [0, 0, 0]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: must be &lt; corresponding strides dimension</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1243">
<h3>Outputs<a class="headerlink" href="#id1243" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1244">
<h4>out[0]<a class="headerlink" href="#id1244" title="Permalink to this heading">¶</a></h4>
<p>The output 3D spatial dimensions are functions of the <em>filters</em>, <em>stride</em>, and
<em>pad_amount</em>.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">dilated_filter_depth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">depth</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dilation</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="n">dilated_filter_height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dilation</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="n">dilated_filter_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dilation</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="n">depth_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">(</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">depth</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dilated_filter_depth</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">output_padding</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">height_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">(</span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">height</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dilated_filter_height</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">output_padding</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">width_out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">(</span><span class="n">stride</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">in</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="n">width</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dilated_filter_width</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">pad_amount</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">output_padding</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: [batch, depth_out, height_out, width_out, channel_out]</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="unpack">
<span id="id1245"></span><h2>UnPack<a class="headerlink" href="#unpack" title="Permalink to this heading">¶</a></h2>
<p>Unpacks input tensor along a given <em>axis</em> into shape(in[0])[axis] tensors with rank
one lower than in[0] by chipping it along the axis dimension.</p>
<p>References:</p>
<ul class="simple">
<li><p>TensorFlow: <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/unstack">unstack</a></p></li>
</ul>
<div class="section" id="id1246">
<h3>Inputs<a class="headerlink" href="#id1246" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1247">
<h4>in[0]<a class="headerlink" href="#id1247" title="Permalink to this heading">¶</a></h4>
<p>Input tensor.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: a tensor of rank N</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Shape: Rank &gt; 0</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1248">
<h3>Parameters<a class="headerlink" href="#id1248" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1249">
<h4>axis<a class="headerlink" href="#id1249" title="Permalink to this heading">¶</a></h4>
<p>Specifies axis to unpack on.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: QNN_DATATYPE_UINT_32</p></li>
<li><p>Shape: scalar</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Value: must be in range [0, N-1]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="id1250">
<h3>Outputs<a class="headerlink" href="#id1250" title="Permalink to this heading">¶</a></h3>
<div class="section" id="id1251">
<h4>out[0..m]<a class="headerlink" href="#id1251" title="Permalink to this heading">¶</a></h4>
<p>Resulting m = shape(in[0])[axis] output data tensors.</p>
<p>This tensor is repeated, meaning the same definition can apply to multiple tensors.</p>
<ul>
<li><p>Mandatory: true</p></li>
<li><p>Data type: backend specific</p></li>
<li><p>Shape: rank(out[0..m]) = rank(in[0]) - 1</p></li>
<li><p>Constraints:</p>
<blockquote>
<div><ul class="simple">
<li><p>Datatype: Same datatype as in[0]</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="CpuOpDefSupplement.html" class="btn btn-neutral float-right" title="CPU Backend Op Definition Supplement" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="../general/terminology.html" class="btn btn-neutral float-left" title="Common Terminology" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020-2024, Qualcomm Technologies, Inc..

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>