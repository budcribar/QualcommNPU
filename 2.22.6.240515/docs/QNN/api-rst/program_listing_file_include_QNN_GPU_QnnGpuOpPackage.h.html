

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Program Listing for File QnnGpuOpPackage.h &mdash; Qualcomm® AI Engine Direct</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom_css.css" type="text/css" />
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Qualcomm® AI Engine Direct
          

          
          </a>

          
            
            
              <div class="version">
                v2.22.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../general/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/backend.html">Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/op_packages.html">Op Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/operations.html">Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/glossary.html">Glossary</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Qualcomm® AI Engine Direct</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Program Listing for File QnnGpuOpPackage.h</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="program-listing-for-file-qnngpuoppackage-h">
<span id="program-listing-file-include-qnn-gpu-qnngpuoppackage-h"></span><h1>Program Listing for File QnnGpuOpPackage.h<a class="headerlink" href="#program-listing-for-file-qnngpuoppackage-h" title="Permalink to this heading">¶</a></h1>
<p>↰ <a class="reference internal" href="file_include_QNN_GPU_QnnGpuOpPackage.h.html#file-include-qnn-gpu-qnngpuoppackage-h"><span class="std std-ref">Return to documentation for file</span></a> (<code class="docutils literal notranslate"><span class="pre">include/QNN/GPU/QnnGpuOpPackage.h</span></code>)</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">//==============================================================================</span>
<span class="c1">//</span>
<span class="c1">//  Copyright (c) 2020-2023 Qualcomm Technologies, Inc.</span>
<span class="c1">//  All Rights Reserved.</span>
<span class="c1">//  Confidential and Proprietary - Qualcomm Technologies, Inc.</span>
<span class="c1">//</span>
<span class="c1">//==============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> *  @file</span>
<span class="cm"> *  @brief  A header which defines the QNN GPU specialization of the QnnOpPackage.h interface.</span>
<span class="cm"> */</span>

<span class="cp">#ifndef QNN_GPU_OP_PACKAGE_H</span>
<span class="cp">#define QNN_GPU_OP_PACKAGE_H</span>

<span class="cp">#ifdef __cplusplus</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdint&gt;</span>
<span class="cp">#else</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdint.h&gt;</span>
<span class="cp">#endif</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;GPU/QnnGpuCommon.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;GPU/QnnGpuGraph.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;QnnOpPackage.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;QnnTypes.h&quot;</span>

<span class="cp">#ifdef __cplusplus</span>
<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="cp">#endif</span>

<span class="c1">//=============================================================================</span>
<span class="c1">// QnnOpPackage_GlobalInfrastructure_t specialization.</span>
<span class="c1">//=============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which is used to communicate device constant properties</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// GPU device version string</span>
<span class="w">  </span><span class="kt">char</span><span class="w"> </span><span class="n">deviceVersion</span><span class="p">[</span><span class="mi">128</span><span class="p">];</span>
<span class="w">  </span><span class="c1">/// GPU driver interface version {major, minor}</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">interfaceVersion</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">  </span><span class="c1">/// GPU Adreno(TM) tier string</span>
<span class="w">  </span><span class="kt">char</span><span class="w"> </span><span class="n">tierName</span><span class="p">[</span><span class="mi">8</span><span class="p">];</span>
<span class="w">  </span><span class="c1">/// GPU driver version {product, major, minor, patch}</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">compilerVersion</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>
<span class="w">  </span><span class="c1">/// GPU device max work group size</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">maxWorkGroupSize</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// GPU device image 2D max width</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">image2dMaxWidth</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// GPU device image 2D max height</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">image2dMaxHeight</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// GPU device max memory allocation size</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">maxBufferAllocSize</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// GPU device addr alignment in bits</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">baseAddrAlignment</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// GPU device image 2D Array max width</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">image2dArrayMaxWidth</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// GPU device image 2D Array max height</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">image2dArrayMaxHeight</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// GPU device image 2D Array max depth</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">image2dArrayMaxDepth</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_DeviceProperties_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A QNN GPU struct specializing QnnOpPackage_GlobalInfrastructure_t</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">_QnnOpPackage_GlobalInfrastructure_t</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// GPU backend version (as returned by QnnBackend_getApiVersion())</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">Qnn_ApiVersion_t</span><span class="o">*</span><span class="w"> </span><span class="n">sdkApiVersion</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// GPU device properties</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">QnnGpu_DeviceProperties_t</span><span class="o">*</span><span class="w"> </span><span class="n">deviceProperties</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Null terminated path to the OpenCL driver used by the backend</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">driverPath</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpuOpPackage_GlobalInfrastructure_t</span><span class="p">;</span>

<span class="c1">//=============================================================================</span>
<span class="c1">// QnnOpPackage_PackageInfo_t specialization.</span>
<span class="c1">//=============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct having op package specific information</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">_QnnOpPackage_PackageInfo_t</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Null terminated hash key string of all kernel sources</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">kernelRepoHash</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpuOpPackage_PackageInfo_t</span><span class="p">;</span>

<span class="c1">//=============================================================================</span>
<span class="c1">// QnnOpPackage_Optimization_t specialization.</span>
<span class="c1">//=============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify the QNN GPU optimization type</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Undefined option only used for QNN_GPU_OP_PACKAGE_OPTIMIZATION_INIT</span>
<span class="w">  </span><span class="n">QNN_GPU_OPTIMIZATION_TYPE_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Super node optimization</span>
<span class="w">  </span><span class="n">QNN_GPU_OPTIMIZATION_TYPE_SUPER_NODE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpuOpPackage_OptimizationType_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct representing a super node connection constraint.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Producer node corresponding to QnnGpuOpPackage_SuperNodeOptimization_t::operations</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">producer</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Output tensor index corresponding to the producer node</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">producerOutputIndex</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Consumer node corresponding to QnnGpuOpPackage_SuperNodeOptimization_t::operations</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">consumer</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Output tensor index corresponding to the consumer node</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">consumerInputIndex</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpuOpPackage_SuperNodeConnectionConstraint_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify the source of a tensor in an op def for a tensor constraint.</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Tensor is an op def output</span>
<span class="w">  </span><span class="n">QNN_GPU_OPTIMIZATION_SUPER_NODE_TENSOR_SOURCE_OUTPUT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_GPU_OPTIMIZATION_SUPER_NODE_TENSOR_SOURCE_INPUT</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpuOpPackage_TensorConstraintSource_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify the tensor constraint type.</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Add a Qnn_DataType_t to the whitelist of allowable types.</span>
<span class="w">  </span><span class="c1">/// If no data type constraint is present for a tensor, all data types are allowed.</span>
<span class="w">  </span><span class="n">QNN_GPU_OPTIMIZATION_SUPER_NODE_TENSOR_CONSTRAINT_DATA_TYPE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Tensor must match it&#39;s rank</span>
<span class="w">  </span><span class="n">QNN_GPU_OPTIMIZATION_SUPER_NODE_TENSOR_CONSTRAINT_RANK</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Tensor must match one of it&#39;s dimensions</span>
<span class="w">  </span><span class="n">QNN_GPU_OPTIMIZATION_SUPER_NODE_TENSOR_CONSTRAINT_DIMENSION</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Add a Qnn_TensorType_t to the whitelist of allowable tensor types.</span>
<span class="w">  </span><span class="c1">/// If no tensor type constraint is present for a tensor, all types are allowed.</span>
<span class="w">  </span><span class="n">QNN_GPU_OPTIMIZATION_SUPER_NODE_TENSOR_CONSTRAINT_TENSOR_TYPE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpuOpPackage_TensorConstraintType_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct representing a tensor constraint.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Operation corresponding to QnnGpuOpPackage_SuperNodeOptimization_t::operations</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">operationIndex</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Source of the tensor in the Qnn_OpConfig_t</span>
<span class="w">  </span><span class="n">QnnGpuOpPackage_TensorConstraintSource_t</span><span class="w"> </span><span class="n">source</span><span class="p">;</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">/// Tensor index in the Qnn_OpConfig_t, used only for inputs and outputs</span>
<span class="w">    </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">index</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Tensor parameter name in the Qnn_OpConfig_t, used only for parameters</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">name</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="w">  </span><span class="c1">/// Type of tensor constraint</span>
<span class="w">  </span><span class="n">QnnGpuOpPackage_TensorConstraintType_t</span><span class="w"> </span><span class="n">type</span><span class="p">;</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">/// Tensor data type for Qnn_DataType_t constraints</span>
<span class="w">    </span><span class="n">Qnn_DataType_t</span><span class="w"> </span><span class="n">dataType</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Tensor type for Qnn_TensorType_t constraints</span>
<span class="w">    </span><span class="n">Qnn_TensorType_t</span><span class="w"> </span><span class="n">tensorType</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Tensor rank for rank constraints</span>
<span class="w">    </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">rank</span><span class="p">;</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="c1">/// Tensor dimension index for dimension constraints</span>
<span class="w">      </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">index</span><span class="p">;</span>
<span class="w">      </span><span class="c1">/// Tensor dimension size for dimension constraints</span>
<span class="w">      </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">size</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="n">dimension</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpuOpPackage_TensorConstraint_t</span><span class="p">;</span>

<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Null-terminated array of comma separated lists of operations used for matching super node ops.</span>
<span class="w">  </span><span class="c1">/// An asterisk (*) may be used to represent any operation type.</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">**</span><span class="w"> </span><span class="n">operations</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Null-terminated array of pointers to super node connection constraints</span>
<span class="w">  </span><span class="n">QnnGpuOpPackage_SuperNodeConnectionConstraint_t</span><span class="o">**</span><span class="w"> </span><span class="n">connectionConstraints</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Null-terminated array of pointers to super node tensor constraints</span>
<span class="w">  </span><span class="n">QnnGpuOpPackage_TensorConstraint_t</span><span class="o">**</span><span class="w"> </span><span class="n">tensorConstraints</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpuOpPackage_SuperNodeOptimization_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// QnnGpuOpPackage_SuperNodeOptimization_t initializer macro</span>
<span class="cp">#define QNN_GPU_OP_PACKAGE_SUPER_NODE_OPTIMIZATION_INIT \</span>
<span class="cp">  {                                                     \</span>
<span class="cp">    NULL, </span><span class="cm">/*operations*/</span><span class="cp">                                \</span>
<span class="cp">    NULL, </span><span class="cm">/*connectionConstraints*/</span><span class="cp">                     \</span>
<span class="cp">    NULL, </span><span class="cm">/*tensorConstraints*/</span><span class="cp">                         \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct representing a QNN GPU optimization.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">_QnnOpPackage_Optimization_t</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Type of optimization</span>
<span class="w">  </span><span class="n">QnnGpuOpPackage_OptimizationType_t</span><span class="w"> </span><span class="n">type</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Op package assigned name of the optimization</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">name</span><span class="p">;</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">/// Super node optimization, used when type is QNN_GPU_OPTIMIZATION_TYPE_SUPER_NODE</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">QnnGpuOpPackage_SuperNodeOptimization_t</span><span class="o">*</span><span class="w"> </span><span class="n">superNode</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpuOpPackage_Optimization_t</span><span class="p">;</span>

<span class="c1">/// QnnGpuOpPackage_Optimization_t initializer macro</span>
<span class="cp">#define QNN_GPU_OP_PACKAGE_OPTIMIZATION_INIT            \</span>
<span class="cp">  {                                                     \</span>
<span class="cp">    QNN_GPU_OPTIMIZATION_TYPE_UNDEFINED, NULL, { NULL } \</span>
<span class="cp">  }</span>

<span class="c1">//=============================================================================</span>
<span class="c1">// QnnOpPackage_GraphInfrastructure_t specialization.</span>
<span class="c1">//=============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A QNN GPU struct specializing QnnOpPackage_GraphInfrastructure_t</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">_QnnOpPackage_GraphInfrastructure_t</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// GPU precision mode, user-supplied hint used for optimal kernel selection</span>
<span class="w">  </span><span class="n">QnnGpu_Precision_t</span><span class="w"> </span><span class="n">precisionMode</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpuOpPackage_GraphInfrastructure_t</span><span class="p">;</span>

<span class="c1">//=============================================================================</span>
<span class="c1">// QNN GPU Memory Object</span>
<span class="c1">//=============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify the QNN GPU memory object type</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Host memory, only used for Qnn_Param_t tensors</span>
<span class="w">  </span><span class="n">QNN_GPU_MEM_OBJ_TYPE_HOST</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// GPU driver buffer memory object</span>
<span class="w">  </span><span class="n">QNN_GPU_MEM_OBJ_TYPE_BUFFER</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// GPU driver image 2D memory object</span>
<span class="w">  </span><span class="n">QNN_GPU_MEM_OBJ_TYPE_IMAGE2D</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// GPU driver image 2D array memory object</span>
<span class="w">  </span><span class="n">QNN_GPU_MEM_OBJ_TYPE_IMAGE2D_ARRAY</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Aggregation of GPU driver image 2D memory objects</span>
<span class="w">  </span><span class="n">QNN_GPU_MEM_OBJ_TYPE_AGGREGATED_IMAGE2D</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Aggregation of GPU driver image 2D array memory objects</span>
<span class="w">  </span><span class="n">QNN_GPU_MEM_OBJ_TYPE_AGGREGATED_IMAGE2D_ARRAY</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Memory type is unclaimed and can be specified by the op package via the \n</span>
<span class="w">  </span><span class="c1">/// QnnGpu_OutputClaim_t struct</span>
<span class="w">  </span><span class="n">QNN_GPU_MEM_OBJ_TYPE_UNCLAIMED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_MemoryObjectType_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify the QNN GPU memory layout</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// HWC layout</span>
<span class="w">  </span><span class="n">QNN_GPU_MEM_LAYOUT_HWC</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// HCW layout</span>
<span class="w">  </span><span class="n">QNN_GPU_MEM_LAYOUT_HCW</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// CHW layout</span>
<span class="w">  </span><span class="n">QNN_GPU_MEM_LAYOUT_CHW</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Undefined</span>
<span class="w">  </span><span class="n">QNN_GPU_MEM_LAYOUT_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span><span class="p">,</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_MemoryLayout_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A QNN GPU struct specifying a memory object</span>
<span class="cm"> *        This struct is used with the following kernel argument types:</span>
<span class="cm"> *          - QNN_GPU_KERNEL_ARG_TYPE_OP_INPUT_READ</span>
<span class="cm"> *          - QNN_GPU_KERNEL_ARG_TYPE_OP_INPUT_READWRITE</span>
<span class="cm"> *          - QNN_GPU_KERNEL_ARG_TYPE_OP_OUTPUT_WRITE</span>
<span class="cm"> *          - QNN_GPU_KERNEL_ARG_TYPE_INTERNAL_READ</span>
<span class="cm"> *          - QNN_GPU_KERNEL_ARG_TYPE_INTERNAL_READWRITE</span>
<span class="cm"> *          - QNN_GPU_KERNEL_ARG_TYPE_INTERNAL_WRITE</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Type of memory object</span>
<span class="w">  </span><span class="n">QnnGpu_MemoryObjectType_t</span><span class="w"> </span><span class="n">type</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Data type of the memory object</span>
<span class="w">  </span><span class="n">Qnn_DataType_t</span><span class="w"> </span><span class="n">dataType</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Memory object dimensions                                                                 \n</span>
<span class="w">  </span><span class="c1">///   Size is numDimensions. Uses the following type dependent format:                       \n</span>
<span class="w">  </span><span class="c1">///   QNN_GPU_MEM_OBJ_TYPE_BUFFER                   -&gt; {numElements}                         \n</span>
<span class="w">  </span><span class="c1">///   QNN_GPU_MEM_OBJ_TYPE_IMAGE2D                  -&gt; {height,width}                        \n</span>
<span class="w">  </span><span class="c1">///   QNN_GPU_MEM_OBJ_TYPE_IMAGE2D_ARRAY            -&gt; {height,width,array_size}             \n</span>
<span class="w">  </span><span class="c1">///   QNN_GPU_MEM_OBJ_TYPE_AGGREGATED_IMAGE2D       -&gt; {num_batches,height,width}            \n</span>
<span class="w">  </span><span class="c1">///   QNN_GPU_MEM_OBJ_TYPE_AGGREGATED_IMAGE2D_ARRAY -&gt; {num_batches,height,width,array_size}</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="o">*</span><span class="w"> </span><span class="n">dimensions</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Memory object offsets                                         \n</span>
<span class="w">  </span><span class="c1">///   Size is numDimensions.                                      \n</span>
<span class="w">  </span><span class="c1">///   Indicates where the data store starts in the memory object. \n</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="o">*</span><span class="w"> </span><span class="n">offsets</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Number of dimensions in memory object                           \n</span>
<span class="w">  </span><span class="c1">///   Size is numDimensions. Has the following type dependent size: \n</span>
<span class="w">  </span><span class="c1">///   QNN_GPU_MEM_OBJ_TYPE_BUFFER                   -&gt; 1            \n</span>
<span class="w">  </span><span class="c1">///   QNN_GPU_MEM_OBJ_TYPE_IMAGE2D                  -&gt; 2            \n</span>
<span class="w">  </span><span class="c1">///   QNN_GPU_MEM_OBJ_TYPE_IMAGE2D_ARRAY            -&gt; 3            \n</span>
<span class="w">  </span><span class="c1">///   QNN_GPU_MEM_OBJ_TYPE_AGGREGATED_IMAGE2D       -&gt; 3            \n</span>
<span class="w">  </span><span class="c1">///   QNN_GPU_MEM_OBJ_TYPE_AGGREGATED_IMAGE2D_ARRAY -&gt; 4</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numDimensions</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Memory object layout                           \n</span>
<span class="w">  </span><span class="c1">/// Op package specific layout identifier          \n</span>
<span class="w">  </span><span class="c1">/// Default is QNN_GPU_MEM_LAYOUT_UNDEFINED if not already specified by a prior operation</span>
<span class="w">  </span><span class="n">QnnGpu_MemoryLayout_t</span><span class="w"> </span><span class="n">layout</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_MemoryObject_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// QnnGpu_MemoryObject_t initializer macro</span>
<span class="cp">#define QNN_GPU_MEMORY_OBJECT_INIT                    \</span>
<span class="cp">  {                                                   \</span>
<span class="cp">    QNN_GPU_MEM_OBJ_TYPE_UNCLAIMED, </span><span class="cm">/*type*/</span><span class="cp">          \</span>
<span class="cp">    QNN_DATATYPE_UNDEFINED,         </span><span class="cm">/*dataType*/</span><span class="cp">      \</span>
<span class="cp">    NULL,                           </span><span class="cm">/*dimensions*/</span><span class="cp">    \</span>
<span class="cp">    NULL,                           </span><span class="cm">/*offsets*/</span><span class="cp">       \</span>
<span class="cp">    0u,                             </span><span class="cm">/*numDimensions*/</span><span class="cp"> \</span>
<span class="cp">    QNN_GPU_MEM_LAYOUT_UNDEFINED    </span><span class="cm">/*layout*/</span><span class="cp">        \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="c1">//=============================================================================</span>
<span class="c1">// QnnOpPackage_Node_t specialization.</span>
<span class="c1">//=============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A QNN GPU struct specifying a storage tensor</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Tensor ID</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">id</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor&#39;s associated memory object</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">QnnGpu_MemoryObject_t</span><span class="o">*</span><span class="w"> </span><span class="n">memoryObject</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_TensorStorageType_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// QnnGpu_TensorStorageType_t initializer macro</span>
<span class="cp">#define QNN_GPU_TENSOR_STORAGE_TYPE_INIT \</span>
<span class="cp">  {                                      \</span>
<span class="cp">    0u,   </span><span class="cm">/*id*/</span><span class="cp">                         \</span>
<span class="cp">    NULL  </span><span class="cm">/*memoryObject*/</span><span class="cp">               \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A QNN GPU struct specializing QnnOpPackage_Node_t</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">_QnnOpPackage_Node_t</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Optimization index, see QnnOpPackage_Info_t, ignore when only one op config provided</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">optimization</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Null-terminated array of operation config pointers</span>
<span class="w">  </span><span class="c1">/// Only one pointer provided when no optimizations performed</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">Qnn_OpConfig_t</span><span class="o">**</span><span class="w"> </span><span class="n">configs</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Null-terminated array of tensor storage type pointers called out in the config</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">QnnGpu_TensorStorageType_t</span><span class="o">**</span><span class="w"> </span><span class="n">storageTypes</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpuOpPackage_Node_t</span><span class="p">;</span>

<span class="c1">//=============================================================================</span>
<span class="c1">// QnnOpPackage_OpImpl_t specialization.</span>
<span class="c1">//=============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A QNN GPU struct specifying an output tensor claim. Using the principle</span>
<span class="cm"> *        of least work, operations must output a memory object type that is most</span>
<span class="cm"> *        convenient for itself. Only QNN_TENSOR_TYPE_NATIVE tensor types may</span>
<span class="cm"> *        be claimed.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Index into the Qnn_OpConfig_t provided in QnnGpuOpPackage_Node_t</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">opConfigIndex</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Index into the operation outputs to identify the tensor</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">outputIndex</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Specification of the claimed memory object</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">QnnGpu_MemoryObject_t</span><span class="o">*</span><span class="w"> </span><span class="n">memoryObject</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_OutputClaim_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// QnnGpu_OutputClaim_t initializer macro</span>
<span class="cp">#define QNN_GPU_OUTPUT_CLAIM_INIT \</span>
<span class="cp">  {                               \</span>
<span class="cp">    0u,      </span><span class="cm">/*opConfigIndex*/</span><span class="cp">    \</span>
<span class="cp">    0u,      </span><span class="cm">/*outputIndex*/</span><span class="cp">      \</span>
<span class="cp">    NULL     </span><span class="cm">/*memoryObject*/</span><span class="cp">     \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify the kernel argument type.</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Operation input tensor used as kernel input</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_TYPE_OP_INPUT_READ</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Operation input tensor used as kernel output</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_TYPE_OP_INPUT_READWRITE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Operation output tensor used as kernel output</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_TYPE_OP_OUTPUT_WRITE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Operation internal tensor used as kernel input</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_TYPE_INTERNAL_READ</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Operation internal tensor used as kernel input/output</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_TYPE_INTERNAL_READWRITE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Operation internal tensor used as kernel output</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_TYPE_INTERNAL_WRITE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Plain old data kernel argument</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_TYPE_DATA</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Local memory kernel argument</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_TYPE_LOCAL</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Null pointer kernel argument</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_TYPE_NULL_PTR</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span><span class="p">,</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_KernelArgType_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A QNN GPU struct specifying a kernel argument corresponding to a tensor.</span>
<span class="cm"> *        This struct is used with the following kernel argument types:</span>
<span class="cm"> *          - QNN_GPU_KERNEL_ARG_TYPE_OP_INPUT_READ</span>
<span class="cm"> *          - QNN_GPU_KERNEL_ARG_TYPE_OP_INPUT_READWRITE</span>
<span class="cm"> *          - QNN_GPU_KERNEL_ARG_TYPE_OP_OUTPUT_WRITE</span>
<span class="cm"> *          - QNN_GPU_KERNEL_ARG_TYPE_INTERNAL_READ</span>
<span class="cm"> *          - QNN_GPU_KERNEL_ARG_TYPE_INTERNAL_READWRITE</span>
<span class="cm"> *          - QNN_GPU_KERNEL_ARG_TYPE_INTERNAL_WRITE</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Index into the Qnn_OpConfig_t provided in QnnGpuOpPackage_Node_t, ignored for INTERNAL types</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">opConfigIndex</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Index into the operation input ot output list or the internal tensor list</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">tensorIndex</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Batch element index for aggregated tensor types</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">element</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_TensorKernelArg_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// QnnGpu_TensorKernelArg_t initializer macro</span>
<span class="cp">#define QNN_GPU_TENSOR_KERNEL_ARG_INIT \</span>
<span class="cp">  {                                    \</span>
<span class="cp">    0u,   </span><span class="cm">/*opConfigIndex*/</span><span class="cp">            \</span>
<span class="cp">    0u,   </span><span class="cm">/*tensorIndex*/</span><span class="cp">              \</span>
<span class="cp">    0u    </span><span class="cm">/*element*/</span><span class="cp">                  \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify the kernel data argument type.</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_CL_TYPE_CHAR</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_CL_TYPE_UCHAR</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_CL_TYPE_SHORT</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_CL_TYPE_USHORT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_CL_TYPE_INT</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_CL_TYPE_UINT</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_CL_TYPE_LONG</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_CL_TYPE_ULONG</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_CL_TYPE_FLOAT</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_ARG_CL_TYPE_DOUBLE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">9</span><span class="p">,</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_DataKernelArgType_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A QNN GPU struct specifying a kernel argument corresponding to a plain old data.</span>
<span class="cm"> *        This struct is used only with the QNN_GPU_KERNEL_ARG_TYPE_DATA arg type.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Data type of the data</span>
<span class="w">  </span><span class="n">QnnGpu_DataKernelArgType_t</span><span class="w"> </span><span class="n">type</span><span class="p">;</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">/// Used with QNN_GPU_KERNEL_ARG_CL_TYPE_CHAR</span>
<span class="w">    </span><span class="kt">int8_t</span><span class="w"> </span><span class="n">qnnChar</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Used with QNN_GPU_KERNEL_ARG_CL_TYPE_UCHAR</span>
<span class="w">    </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">qnnUChar</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Used with QNN_GPU_KERNEL_ARG_CL_TYPE_SHORT</span>
<span class="w">    </span><span class="kt">int16_t</span><span class="w"> </span><span class="n">qnnShort</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Used with QNN_GPU_KERNEL_ARG_CL_TYPE_USHORT</span>
<span class="w">    </span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">qnnUShort</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Used with QNN_GPU_KERNEL_ARG_CL_TYPE_INT</span>
<span class="w">    </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">qnnInt</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Used with QNN_GPU_KERNEL_ARG_CL_TYPE_UINT</span>
<span class="w">    </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">qnnUInt</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Used with QNN_GPU_KERNEL_ARG_CL_TYPE_LONG</span>
<span class="w">    </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">qnnLong</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Used with QNN_GPU_KERNEL_ARG_CL_TYPE_ULONG</span>
<span class="w">    </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">qnnULong</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Used with QNN_GPU_KERNEL_ARG_CL_TYPE_FLOAT</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">qnnFloat</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Used with QNN_GPU_KERNEL_ARG_CL_TYPE_DOUBLE</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">qnnDouble</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_DataKernelArg_t</span><span class="p">;</span>

<span class="c1">/// QnnGpu_DataKernelArg_t initializer macro</span>
<span class="cp">#define QNN_GPU_DATA_KERNEL_ARG_INIT          \</span>
<span class="cp">  {                                           \</span>
<span class="cp">    QNN_GPU_KERNEL_ARG_CL_TYPE_CHAR, </span><span class="cm">/*type*/</span><span class="cp"> \</span>
<span class="cp">    {                                         \</span>
<span class="cp">      0 </span><span class="cm">/*qnnChar*/</span><span class="cp">                           \</span>
<span class="cp">    }                                         \</span>
<span class="cp">  }</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A QNN GPU struct specifying a kernel argument corresponding to a local memory type.</span>
<span class="cm"> *        This struct is used only with the QNN_GPU_KERNEL_ARG_TYPE_LOCAL arg type.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Size of the memory requested in bytes</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">size</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_LocalKernelArg_t</span><span class="p">;</span>

<span class="c1">/// QnnGpu_LocalKernelArg_t initializer macro</span>
<span class="cp">#define QNN_GPU_LOCAL_KERNEL_ARG_INIT \</span>
<span class="cp">  { 0u </span><span class="cm">/*size*/</span><span class="cp"> }</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A QNN GPU struct specifying a kernel argument.</span>
<span class="cm"> *        Note that the QNN_GPU_KERNEL_ARG_TYPE_NULL_PTR type does not have an entry in</span>
<span class="cm"> *        the union.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Type of kernel argument</span>
<span class="w">  </span><span class="n">QnnGpu_KernelArgType_t</span><span class="w"> </span><span class="n">type</span><span class="p">;</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">/// Tensor type argument</span>
<span class="w">    </span><span class="n">QnnGpu_TensorKernelArg_t</span><span class="w"> </span><span class="n">tensor</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Plain old data argument</span>
<span class="w">    </span><span class="n">QnnGpu_DataKernelArg_t</span><span class="w"> </span><span class="n">data</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Local memory argument</span>
<span class="w">    </span><span class="n">QnnGpu_LocalKernelArg_t</span><span class="w"> </span><span class="n">local</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_KernelArg_t</span><span class="p">;</span>

<span class="c1">/// QnnGpu_KernelArg_t initializer macro</span>
<span class="cp">#define QNN_GPU_KERNEL_ARG_INIT                 \</span>
<span class="cp">  {                                             \</span>
<span class="cp">    QNN_GPU_KERNEL_ARG_TYPE_NULL_PTR, </span><span class="cm">/*type*/</span><span class="cp">  \</span>
<span class="cp">    {                                           \</span>
<span class="cp">      QNN_GPU_TENSOR_KERNEL_ARG_INIT </span><span class="cm">/*tensor*/</span><span class="cp"> \</span>
<span class="cp">    }                                           \</span>
<span class="cp">  }</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify the kernel source type.</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_SOURCE_TYPE_TEXT</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_GPU_KERNEL_SOURCE_TYPE_BINARY</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_KernelSourceType_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A QNN GPU struct specifying a kernel.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Kernel source code or binary</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">kernelSource</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Length of kernel source/binary in bytes</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">sourceLength</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Type of kernel source</span>
<span class="w">  </span><span class="n">QnnGpu_KernelSourceType_t</span><span class="w"> </span><span class="n">sourceType</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Null terminated build options string used for kernel compilation</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">buildOptions</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Rank of the globalWorkSizes</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">globalWorkDim</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Global work sizes used by enqueuing the kernel</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">globalWorkSizes</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
<span class="w">  </span><span class="c1">/// Rank of the localWorkSizes</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">localWorkDim</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Local work sizes used by enqueuing the kernel</span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">localWorkSizes</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
<span class="w">  </span><span class="c1">/// Null-terminated array of kernel arguments in the order they appear in the kernel function</span>
<span class="w">  </span><span class="n">QnnGpu_KernelArg_t</span><span class="o">**</span><span class="w"> </span><span class="n">args</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Null terminated name of the kernel</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">name</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// If non-zero, kernel will be enqueued during execute even if it is static</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">isDynamic</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Reserved field, must be null</span>
<span class="w">  </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">reserved</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_Kernel_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// QnnGpu_Kernel_t initializer macro</span>
<span class="cp">#define QNN_GPU_KERNEL_INIT                              \</span>
<span class="cp">  {                                                      \</span>
<span class="cp">    NULL,                            </span><span class="cm">/*kernelSource*/</span><span class="cp">    \</span>
<span class="cp">    0u,                              </span><span class="cm">/*sourceLength*/</span><span class="cp">    \</span>
<span class="cp">    QNN_GPU_KERNEL_SOURCE_TYPE_TEXT, </span><span class="cm">/*sourceType*/</span><span class="cp">      \</span>
<span class="cp">    NULL,                            </span><span class="cm">/*buildOptions*/</span><span class="cp">    \</span>
<span class="cp">    0u,                              </span><span class="cm">/*globalWorkDim*/</span><span class="cp">   \</span>
<span class="cp">    {0u},                            </span><span class="cm">/*globalWorkSizes*/</span><span class="cp"> \</span>
<span class="cp">    0u,                              </span><span class="cm">/*localWorkDim*/</span><span class="cp">    \</span>
<span class="cp">    {0u},                            </span><span class="cm">/*localWorkSizes*/</span><span class="cp">  \</span>
<span class="cp">    NULL,                            </span><span class="cm">/*args*/</span><span class="cp">            \</span>
<span class="cp">    NULL,                            </span><span class="cm">/*name*/</span><span class="cp">            \</span>
<span class="cp">    0u,                              </span><span class="cm">/*isDynamic*/</span><span class="cp">       \</span>
<span class="cp">    NULL                             </span><span class="cm">/*reserved*/</span><span class="cp">        \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A QNN GPU struct specifying an operation.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">_QnnOpPackage_OpImpl_t</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Null-terminated array of output claims</span>
<span class="w">  </span><span class="n">QnnGpu_OutputClaim_t</span><span class="o">**</span><span class="w"> </span><span class="n">outputClaims</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Null-terminated array of tensor requests</span>
<span class="w">  </span><span class="n">QnnGpu_MemoryObject_t</span><span class="o">**</span><span class="w"> </span><span class="n">memoryObjects</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Null-terminated array of kernels</span>
<span class="w">  </span><span class="n">QnnGpu_Kernel_t</span><span class="o">**</span><span class="w"> </span><span class="n">kernels</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGpu_Operation_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// QnnGpu_Operation_t initializer macro</span>
<span class="cp">#define QNN_GPU_OPERATION_INIT     \</span>
<span class="cp">  {                                \</span>
<span class="cp">    NULL,     </span><span class="cm">/*outputClaims*/</span><span class="cp">     \</span>
<span class="cp">    NULL,     </span><span class="cm">/*memoryObjects*/</span><span class="cp">    \</span>
<span class="cp">    NULL,     </span><span class="cm">/*kernels*/</span><span class="cp">          \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cp">#ifdef __cplusplus</span>
<span class="p">}</span><span class="w">  </span><span class="c1">// extern &quot;C&quot;</span>
<span class="cp">#endif</span>

<span class="cp">#endif</span>
</pre></div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020-2024, Qualcomm Technologies, Inc..

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>