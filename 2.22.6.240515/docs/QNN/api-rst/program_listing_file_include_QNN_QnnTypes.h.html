

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Program Listing for File QnnTypes.h &mdash; Qualcomm® AI Engine Direct</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom_css.css" type="text/css" />
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Qualcomm® AI Engine Direct
          

          
          </a>

          
            
            
              <div class="version">
                v2.22.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../general/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/backend.html">Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/op_packages.html">Op Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/operations.html">Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/glossary.html">Glossary</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Qualcomm® AI Engine Direct</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Program Listing for File QnnTypes.h</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="program-listing-for-file-qnntypes-h">
<span id="program-listing-file-include-qnn-qnntypes-h"></span><h1>Program Listing for File QnnTypes.h<a class="headerlink" href="#program-listing-for-file-qnntypes-h" title="Permalink to this heading">¶</a></h1>
<p>↰ <a class="reference internal" href="file_include_QNN_QnnTypes.h.html#file-include-qnn-qnntypes-h"><span class="std std-ref">Return to documentation for file</span></a> (<code class="docutils literal notranslate"><span class="pre">include/QNN/QnnTypes.h</span></code>)</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">//==============================================================================</span>
<span class="c1">//</span>
<span class="c1">// Copyright (c) 2019-2024 Qualcomm Technologies, Inc.</span>
<span class="c1">// All Rights Reserved.</span>
<span class="c1">// Confidential and Proprietary - Qualcomm Technologies, Inc.</span>
<span class="c1">//</span>
<span class="c1">//==============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> *  @file</span>
<span class="cm"> *  @brief  A header which contains the base types required by the API.</span>
<span class="cm"> *          Strings are expected to be UTF-8 encoded and NULL terminated.</span>
<span class="cm"> */</span>

<span class="cp">#ifndef QNN_TYPES_H</span>
<span class="cp">#define QNN_TYPES_H</span>

<span class="cp">#ifdef __cplusplus</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstddef&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdint&gt;</span>
<span class="cp">#else</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stddef.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdint.h&gt;</span>
<span class="cp">#endif</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;QnnCommon.h&quot;</span>

<span class="cp">#ifdef __cplusplus</span>
<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="cp">#endif</span>

<span class="c1">//=============================================================================</span>
<span class="c1">// Data Types</span>
<span class="c1">//=============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum which defines various data types.</span>
<span class="cm"> *</span>
<span class="cm"> * @note  4-bit data types (QNN_DATATYPE_SFIXED_POINT_4 and</span>
<span class="cm"> *        QNN_DATATYPE_UFIXED_POINT_4) are stored in tightly</span>
<span class="cm"> *        packed format into a single byte in little endian</span>
<span class="cm"> *        format. This allows two 4-bit quantized elements to be</span>
<span class="cm"> *        stored in a single byte. The lower nibble stores the first</span>
<span class="cm"> *        value while the higher nibble stores the second value.</span>
<span class="cm"> *        For example, to represent two 4-bit quantized values of</span>
<span class="cm"> *        10 and 4, they will be stored in a single byte as (0100 1010).</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Signed Int: 0x00XX</span>

<span class="w">  </span><span class="c1">/// 8-bit integer type</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_INT_8</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0008</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// 16-bit integer type</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_INT_16</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0016</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// 32-bit integer type</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_INT_32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0032</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// 64-bit integer type</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_INT_64</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0064</span><span class="p">,</span>

<span class="w">  </span><span class="c1">// Unsigned Int: 0x01XX</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_UINT_8</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0108</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_UINT_16</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0116</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_UINT_32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0132</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_UINT_64</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0164</span><span class="p">,</span>

<span class="w">  </span><span class="c1">// Float: 0x02XX</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_FLOAT_16</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0216</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_FLOAT_32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0232</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_FLOAT_64</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0264</span><span class="p">,</span>

<span class="w">  </span><span class="c1">// Signed Fixed Point: 0x03XX</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_SFIXED_POINT_4</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0304</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_SFIXED_POINT_8</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0308</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_SFIXED_POINT_16</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0316</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_SFIXED_POINT_32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0332</span><span class="p">,</span>

<span class="w">  </span><span class="c1">// Unsigned Fixed Point: 0x04XX</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_UFIXED_POINT_4</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0404</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0408</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_UFIXED_POINT_16</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0416</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_UFIXED_POINT_32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0432</span><span class="p">,</span>

<span class="w">  </span><span class="c1">// Bool: 0x05XX</span>
<span class="w">  </span><span class="c1">/// 8-bit boolean type, 0 = false, any non-zero value = true</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_BOOL_8</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0508</span><span class="p">,</span>

<span class="w">  </span><span class="c1">// String: 0x06xx</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_STRING</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x0608</span><span class="p">,</span>

<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_DATATYPE_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_DataType_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum which defines the different precision modes supported by QNN backends.</span>
<span class="cm"> *        A precision mode may be used to express the math type used in the implementation</span>
<span class="cm"> *        of an operation.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// FLOATING POINT REPRESENTATIONS</span>

<span class="w">  </span><span class="c1">/// 32-bit Floating point precision. The format of the floating point</span>
<span class="w">  </span><span class="c1">/// value is left to backends to choose.</span>
<span class="w">  </span><span class="n">QNN_PRECISION_FLOAT32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// 16-bit Floating point precision. The format of the floating point</span>
<span class="w">  </span><span class="c1">/// value is left to backends to choose.</span>
<span class="w">  </span><span class="n">QNN_PRECISION_FLOAT16</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>

<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_PRECISION_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_Precision_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify the tensor type, application accessible or native to QNN</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Client application writeable tensor.</span>
<span class="w">  </span><span class="n">QNN_TENSOR_TYPE_APP_WRITE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Client application readable tensor.</span>
<span class="w">  </span><span class="n">QNN_TENSOR_TYPE_APP_READ</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Tensor that can both be read and written by an application. Used in scenarios that may include</span>
<span class="w">  </span><span class="c1">/// supplying an output tensor from one graph as the input to another graph.</span>
<span class="w">  </span><span class="n">QNN_TENSOR_TYPE_APP_READWRITE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Tensor native to a graph which may be optimized by a backend and are not accessible by a</span>
<span class="w">  </span><span class="c1">/// client.</span>
<span class="w">  </span><span class="n">QNN_TENSOR_TYPE_NATIVE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Static data which doesn&#39;t change during execution and may be optimized by a backend. Since the</span>
<span class="w">  </span><span class="c1">/// data cannot change, static tensors cannot have dynamic dimensions.</span>
<span class="w">  </span><span class="n">QNN_TENSOR_TYPE_STATIC</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Tensor type NULL which can be used to represent optional tensors. Other Qnn_Tensor_t metadata</span>
<span class="w">  </span><span class="c1">/// is ignored.</span>
<span class="w">  </span><span class="n">QNN_TENSOR_TYPE_NULL</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span>
<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_TENSOR_TYPE_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_TensorType_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify the parameter type : Scalar or Tensor</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">QNN_PARAMTYPE_SCALAR</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_PARAMTYPE_TENSOR</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_PARAMTYPE_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0xFFFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_ParamType_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify definition source for field(s) following this enum</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Indicates backend implementation to update or decide</span>
<span class="w">  </span><span class="n">QNN_DEFINITION_IMPL_GENERATED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Indicates that provided definition needs to be used</span>
<span class="w">  </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_DEFINITION_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_Definition_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify a priority.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// QNN_PRIORITY_LOW is always available for use.</span>
<span class="w">  </span><span class="n">QNN_PRIORITY_LOW</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// QNN_PRIORITY_NORMAL is always available for use.</span>
<span class="w">  </span><span class="n">QNN_PRIORITY_NORMAL</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_PRIORITY_DEFAULT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_PRIORITY_NORMAL</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// QNN_PRIORITY_NORMAL_HIGH usage may be restricted and would silently be treated as</span>
<span class="w">  </span><span class="c1">/// QNN_PRIORITY_NORMAL</span>
<span class="w">  </span><span class="n">QNN_PRIORITY_NORMAL_HIGH</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">150</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// QNN_PRIORITY_HIGH usage may be restricted and would silently be treated as</span>
<span class="w">  </span><span class="c1">/// QNN_PRIORITY_NORMAL</span>
<span class="w">  </span><span class="n">QNN_PRIORITY_HIGH</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">200</span><span class="p">,</span>
<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_PRIORITY_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_Priority_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A typedef to indicate context binary size.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">Qnn_ContextBinarySize_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to describe reporting levels for the error handling API</span>
<span class="cm"> * QNN_ERROR_REPORTING_LEVEL_BRIEF: get basic information about an error</span>
<span class="cm"> * QNN_ERROR_REPORTING_LEVEL_DETAILED: get detailed information about an error</span>
<span class="cm"> * in memory-based object forms</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">QNN_ERROR_REPORTING_LEVEL_BRIEF</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_ERROR_REPORTING_LEVEL_DETAILED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_ERROR_REPORTING_LEVEL_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_ErrorReportingLevel_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A typedef describing error reporting configuration</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Error reporting level</span>
<span class="w">  </span><span class="n">Qnn_ErrorReportingLevel_t</span><span class="w"> </span><span class="n">reportingLevel</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Amount of memory to be reserved for error information. Specified in KB</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">storageLimit</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_ErrorReportingConfig_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_ErrorReportingConfig_t initializer macro</span>
<span class="cp">#define QNN_ERROR_REPORTING_CONFIG_INIT                     \</span>
<span class="cp">  {                                                         \</span>
<span class="cp">    QNN_ERROR_REPORTING_LEVEL_UNDEFINED, </span><span class="cm">/*reportingLevel*/</span><span class="cp"> \</span>
<span class="cp">    0u                                   </span><span class="cm">/*storageLimit*/</span><span class="cp">   \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which is used to provide a version number using 3 values:</span>
<span class="cm"> * major, minor, patch</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">major</span><span class="p">;</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">minor</span><span class="p">;</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">patch</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_Version_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_Version_t initializer macro</span>
<span class="cp">#define QNN_VERSION_INIT \</span>
<span class="cp">  {                      \</span>
<span class="cp">    0u,    </span><span class="cm">/*major*/</span><span class="cp">     \</span>
<span class="cp">    0u,    </span><span class="cm">/*minor*/</span><span class="cp">     \</span>
<span class="cp">    0u     </span><span class="cm">/*patch*/</span><span class="cp">     \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct used to provide the versions of both the core QNN API</span>
<span class="cm"> * and any Backend Specific API</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Version of the QNN core API common to all backends</span>
<span class="w">  </span><span class="n">Qnn_Version_t</span><span class="w"> </span><span class="n">coreApiVersion</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Version of the backend-specific API</span>
<span class="w">  </span><span class="n">Qnn_Version_t</span><span class="w"> </span><span class="n">backendApiVersion</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_ApiVersion_t</span><span class="p">;</span>

<span class="c1">/// Qnn_ApiVersion_t initializer macro</span>
<span class="cp">#define QNN_API_VERSION_INIT                            \</span>
<span class="cp">  {                                                     \</span>
<span class="cp">    {                                                   \</span>
<span class="cp">        QNN_API_VERSION_MAJOR, </span><span class="cm">/*coreApiVersion.major*/</span><span class="cp"> \</span>
<span class="cp">        QNN_API_VERSION_MINOR, </span><span class="cm">/*coreApiVersion.minor*/</span><span class="cp"> \</span>
<span class="cp">        QNN_API_VERSION_PATCH  </span><span class="cm">/*coreApiVersion.patch*/</span><span class="cp"> \</span>
<span class="cp">    },                                                  \</span>
<span class="cp">        QNN_VERSION_INIT </span><span class="cm">/*backendApiVersion*/</span><span class="cp">          \</span>
<span class="cp">  }</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A value representing an immutable value which configures a node.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">Qnn_DataType_t</span><span class="w"> </span><span class="n">dataType</span><span class="p">;</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="nc">UNNAMED</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">floatValue</span><span class="p">;</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">doubleValue</span><span class="p">;</span>
<span class="w">    </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">uint64Value</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">int64Value</span><span class="p">;</span>
<span class="w">    </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">uint32Value</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">int32Value</span><span class="p">;</span>
<span class="w">    </span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">uint16Value</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int16_t</span><span class="w"> </span><span class="n">int16Value</span><span class="p">;</span>
<span class="w">    </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">uint8Value</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int8_t</span><span class="w"> </span><span class="n">int8Value</span><span class="p">;</span>
<span class="w">    </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">bool8Value</span><span class="p">;</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">stringValue</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_Scalar_t</span><span class="p">;</span>

<span class="c1">/// Qnn_Scalar_t initializer macro</span>
<span class="cp">#define QNN_SCALAR_INIT                  \</span>
<span class="cp">  {                                      \</span>
<span class="cp">    QNN_DATATYPE_UNDEFINED, </span><span class="cm">/*dataType*/</span><span class="cp"> \</span>
<span class="cp">    {                                    \</span>
<span class="cp">      0.0f </span><span class="cm">/*floatValue*/</span><span class="cp">                \</span>
<span class="cp">    }                                    \</span>
<span class="cp">  }</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum to specify quantization encoding type structure</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Indicates Qnn_ScaleOffset_t encoding type</span>
<span class="w">  </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Indicates Qnn_AxisScaleOffset_t encoding type</span>
<span class="w">  </span><span class="n">QNN_QUANTIZATION_ENCODING_AXIS_SCALE_OFFSET</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Indicates Qnn_BwScaleOffset_t encoding type</span>
<span class="w">  </span><span class="n">QNN_QUANTIZATION_ENCODING_BW_SCALE_OFFSET</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Indicates Qnn_BwAxisScaleOffset_t encoding type</span>
<span class="w">  </span><span class="n">QNN_QUANTIZATION_ENCODING_BW_AXIS_SCALE_OFFSET</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_QUANTIZATION_ENCODING_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_QuantizationEncoding_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct to express quantization parameters as a positive scale with a zero offset.</span>
<span class="cm"> *</span>
<span class="cm"> * float_value = (quantized_value + offset) * scale</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// scale must be strictly positive</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">offset</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_ScaleOffset_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_ScaleOffset_t initializer macro</span>
<span class="cp">#define QNN_SCALE_OFFSET_INIT \</span>
<span class="cp">  {                           \</span>
<span class="cp">    0.0f, </span><span class="cm">/*scale*/</span><span class="cp">           \</span>
<span class="cp">    0     </span><span class="cm">/*offset*/</span><span class="cp">          \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct to express quantization parameters as a positive scale with a zero offset and a</span>
<span class="cm"> * bitwidth.</span>
<span class="cm"> *</span>
<span class="cm"> * float_value = (quantized_value + offset) * scale</span>
<span class="cm"> *</span>
<span class="cm"> * bitwidth must be &gt; 0, and is used to express the true number of bits used to quantize the value,</span>
<span class="cm"> * which may be different from the bitwidth of the tensor indicated by its data type. For example:</span>
<span class="cm"> * the quantization encoding for a tensor of type QNN_DATATYPE_UFIXED_POINT_8 that is quantized to</span>
<span class="cm"> * 4-bit precision may be expressed by setting bitwidth = 4. In such circumstances, data quantized</span>
<span class="cm"> * to a lower precision will still occupy the full extent of bits allotted to the tensor as per its</span>
<span class="cm"> * data type in unpacked form.</span>
<span class="cm"> *</span>
<span class="cm"> * The datatype used must be the smallest type which can accommodate the bitwidth. For example: a</span>
<span class="cm"> * tensor quantized to 4-bit precision must use an 8-bit datatype, 16-bit or larger datatypes are</span>
<span class="cm"> * not permitted.</span>
<span class="cm"> *</span>
<span class="cm"> * Tensor elements are expected to occupy the least significant bits of the total size alloted to</span>
<span class="cm"> * the datatype, and all bits above the specified bitwidth will be ignored. For example: an 8-bit</span>
<span class="cm"> * datatype tensor quantized to 4-bit precision will be interpreted as a 4-bit value contained in</span>
<span class="cm"> * the lower 4 bits of each element, and the upper 4 bits will be ignored. For signed datatypes, the</span>
<span class="cm"> * value will be interpreted as a two&#39;s complement integer where the signed bit is the most</span>
<span class="cm"> * significant bit permitted by the specified bitwidth. For example: -3 would be represented as</span>
<span class="cm"> * 0b11111101 as a signed 8-bit integer, but can also be represented as 0b00001101 as a signed 4-bit</span>
<span class="cm"> * integer stored in an 8-bit container. Either of these representations are valid to express -3 as</span>
<span class="cm"> * a 4-bit signed integer in an 8-bit container, and will be treated identically because the upper 4</span>
<span class="cm"> * bits will be ignored.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// bitwidth must be &lt;= number of bits specified by data type of tensor</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">bitwidth</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// scale must be strictly positive</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">offset</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_BwScaleOffset_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_BwScaleOffset_t initializer macro</span>
<span class="cp">#define QNN_BW_SCALE_OFFSET_INIT \</span>
<span class="cp">  {                              \</span>
<span class="cp">    0u,   </span><span class="cm">/*bitwidth*/</span><span class="cp">           \</span>
<span class="cp">    0.0f, </span><span class="cm">/*scale*/</span><span class="cp">              \</span>
<span class="cp">    0     </span><span class="cm">/*offset*/</span><span class="cp">             \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct to express per-axis quantization parameters as a scale with a zero offset</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">axis</span><span class="p">;</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numScaleOffsets</span><span class="p">;</span>
<span class="w">  </span><span class="n">Qnn_ScaleOffset_t</span><span class="o">*</span><span class="w"> </span><span class="n">scaleOffset</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_AxisScaleOffset_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_AxisScaleOffset_t initializer macro</span>
<span class="cp">#define QNN_AXIS_SCALE_OFFSET_INIT \</span>
<span class="cp">  {                                \</span>
<span class="cp">    0,       </span><span class="cm">/*axis*/</span><span class="cp">              \</span>
<span class="cp">    0u,      </span><span class="cm">/*numScaleOffsets*/</span><span class="cp">   \</span>
<span class="cp">    NULL     </span><span class="cm">/*scaleOffset*/</span><span class="cp">       \</span>
<span class="cp">  }                                \</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct to express per-axis quantization parameters as collection of scales, offsets</span>
<span class="cm"> * and bitwidth.</span>
<span class="cm"> *</span>
<span class="cm"> * bitwidth must be &gt; 0 and applies commonly to all axes. It is used to express the true number of</span>
<span class="cm"> * bits used to quantize the value, which may be different from the bitwidth of the tensor indicated</span>
<span class="cm"> * by its data type. For example: the quantization encoding for a tensor of type</span>
<span class="cm"> * QNN_DATATYPE_UFIXED_POINT_8 that is quantized to 4-bit precision may be expressed by setting</span>
<span class="cm"> * bitwidth = 4. In such circumstances, data quantized to a lower precision will still occupy the</span>
<span class="cm"> * full extent of bits allotted to the tensor as per its data type in unpacked form.</span>
<span class="cm"> *</span>
<span class="cm"> * The datatype used must be the smallest type which can accommodate the bitwidth. For example: a</span>
<span class="cm"> * tensor quantized to 4-bit precision must use an 8-bit datatype, 16-bit or larger datatypes are</span>
<span class="cm"> * not permitted.</span>
<span class="cm"> *</span>
<span class="cm"> * Tensor elements are expected to occupy the least significant bits of the total size alloted to</span>
<span class="cm"> * the datatype, and all bits above the specified bitwidth will be ignored. For example: an 8-bit</span>
<span class="cm"> * datatype tensor quantized to 4-bit precision will be interpreted as a 4-bit value contained in</span>
<span class="cm"> * the lower 4 bits of each element, and the upper 4 bits will be ignored. For signed datatypes, the</span>
<span class="cm"> * value will be interpreted as a two&#39;s complement integer where the signed bit is the most</span>
<span class="cm"> * significant bit permitted by the specified bitwidth. For example: -3 would be represented as</span>
<span class="cm"> * 0b11111101 as a signed 8-bit integer, but can also be represented as 0b00001101 as a signed 4-bit</span>
<span class="cm"> * integer stored in an 8-bit container. Either of these representations are valid to express -3 as</span>
<span class="cm"> * a 4-bit signed integer in an 8-bit container, and will be treated identically because the upper 4</span>
<span class="cm"> * bits will be ignored.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// bitwidth must be &lt;= number of bits specified by data type of tensor</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">bitwidth</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">axis</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// numElements applies to both scales and offsets and they are supposed to be a one-to-one match</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numElements</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// scales must be strictly positive</span>
<span class="w">  </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">scales</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// offsets must match scales in their dimension except when it can be NULL to indicate that the</span>
<span class="w">  </span><span class="c1">/// value is symmetrically quantized and hence, offset = 0</span>
<span class="w">  </span><span class="kt">int32_t</span><span class="o">*</span><span class="w"> </span><span class="n">offsets</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_BwAxisScaleOffset_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_BwAxisScaleOffset_t initializer macro</span>
<span class="cp">#define QNN_BW_AXIS_SCALE_OFFSET_INIT \</span>
<span class="cp">  {                                   \</span>
<span class="cp">    0u,      </span><span class="cm">/*bitwidth*/</span><span class="cp">             \</span>
<span class="cp">    0,       </span><span class="cm">/*axis*/</span><span class="cp">                 \</span>
<span class="cp">    0u,      </span><span class="cm">/*numElements*/</span><span class="cp">          \</span>
<span class="cp">    NULL,    </span><span class="cm">/*scales*/</span><span class="cp">               \</span>
<span class="cp">    NULL     </span><span class="cm">/*offsets*/</span><span class="cp">              \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which defines the quantization parameters, and union of supported quantization</span>
<span class="cm"> * encoding structs.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">Qnn_Definition_t</span><span class="w"> </span><span class="n">encodingDefinition</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Quantization encoding type identifying quantization encoding structure to use</span>
<span class="w">  </span><span class="n">Qnn_QuantizationEncoding_t</span><span class="w"> </span><span class="n">quantizationEncoding</span><span class="p">;</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="nc">UNNAMED</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">Qnn_ScaleOffset_t</span><span class="w"> </span><span class="n">scaleOffsetEncoding</span><span class="p">;</span>
<span class="w">    </span><span class="n">Qnn_AxisScaleOffset_t</span><span class="w"> </span><span class="n">axisScaleOffsetEncoding</span><span class="p">;</span>
<span class="w">    </span><span class="n">Qnn_BwScaleOffset_t</span><span class="w"> </span><span class="n">bwScaleOffsetEncoding</span><span class="p">;</span>
<span class="w">    </span><span class="n">Qnn_BwAxisScaleOffset_t</span><span class="w"> </span><span class="n">bwAxisScaleOffsetEncoding</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_QuantizeParams_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_QuantizeParams_t initializer macro</span>
<span class="cp">#define QNN_QUANTIZE_PARAMS_INIT                                      \</span>
<span class="cp">  {                                                                   \</span>
<span class="cp">    QNN_DEFINITION_UNDEFINED,                </span><span class="cm">/*encodingDefinition*/</span><span class="cp">   \</span>
<span class="cp">    QNN_QUANTIZATION_ENCODING_UNDEFINED,     </span><span class="cm">/*quantizationEncoding*/</span><span class="cp"> \</span>
<span class="cp">    {                                                                 \</span>
<span class="cp">      QNN_SCALE_OFFSET_INIT </span><span class="cm">/*scaleOffsetEncoding*/</span><span class="cp">                   \</span>
<span class="cp">    }                                                                 \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An n-dimensional tensor formatted in memory as flat buffer where the last dimension varies</span>
<span class="cm"> *        the fastest. Also known as a dense tensor.</span>
<span class="cm"> */</span>
<span class="cp">#define QNN_TENSOR_DATA_FORMAT_DENSE       0</span>
<span class="cp">#define QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER QNN_TENSOR_DATA_FORMAT_DENSE</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An n-dimensional tensor formatted in memory as a sparse tensor. Sparse tensors may only be</span>
<span class="cm"> *        QNN_TENSOR_TYPE_NATIVE. Sparse tensors must also fully specify Qnn_SparseParams_t.</span>
<span class="cm"> */</span>
<span class="cp">#define QNN_TENSOR_DATA_FORMAT_SPARSE 1</span>

<span class="cm">/**</span>
<span class="cm"> * @brief Tensor data format identifier. The default format</span>
<span class="cm"> *        QNN_TENSOR_DATA_FORMAT_DENSE is supported by all backends. Backends may also support</span>
<span class="cm"> *        QNN_TENSOR_DATA_FORMAT_SPARSE.</span>
<span class="cm"> * @note  Data format for intermediate tensors, i.e ones of type QNN_TENSOR_TYPE_NATIVE</span>
<span class="cm"> *        may not be honored by a backend, because it can choose to pick a data format that is</span>
<span class="cm"> *        more conducive for its execution.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">Qnn_TensorDataFormat_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum specifying memory types of tensor data.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Raw memory pointer</span>
<span class="w">  </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Memory object, provide capability for memory sharing in between QNN accelerator backends.</span>
<span class="w">  </span><span class="n">QNN_TENSORMEMTYPE_MEMHANDLE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_TENSORMEMTYPE_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_TensorMemType_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which defines a memory buffer</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// app-accessible data pointer, provided by app.</span>
<span class="w">  </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// size of buffer, in bytes, pointed to by data.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">dataSize</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_ClientBuffer_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_ClientBuffer_t initializer macro</span>
<span class="cp">#define QNN_CLIENT_BUFFER_INIT \</span>
<span class="cp">  {                            \</span>
<span class="cp">    NULL, </span><span class="cm">/*data*/</span><span class="cp">             \</span>
<span class="cp">    0u    </span><span class="cm">/*dataSize*/</span><span class="cp">         \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which defines an opaque object</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Data pointer to the opaque object</span>
<span class="w">  </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Size of buffer, in bytes, pointed to by data</span>
<span class="w">  </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">len</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_OpaqueObject_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_OpaqueObject_t initializer macro</span>
<span class="cp">#define QNN_OPAQUE_OBJECT_INIT \</span>
<span class="cp">  {                            \</span>
<span class="cp">    NULL, </span><span class="cm">/*data*/</span><span class="cp">             \</span>
<span class="cp">    0u    </span><span class="cm">/*len*/</span><span class="cp">              \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which describes the properties of a V1 version of tensor.</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Integer identifier for a tensor.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">id</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor name.</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">name</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor type.</span>
<span class="w">  </span><span class="n">Qnn_TensorType_t</span><span class="w"> </span><span class="n">type</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor data formatting in memory (refer to definition type for info).</span>
<span class="w">  </span><span class="n">Qnn_TensorDataFormat_t</span><span class="w"> </span><span class="n">dataFormat</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor data type.</span>
<span class="w">  </span><span class="n">Qnn_DataType_t</span><span class="w"> </span><span class="n">dataType</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor quantization params.</span>
<span class="w">  </span><span class="n">Qnn_QuantizeParams_t</span><span class="w"> </span><span class="n">quantizeParams</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor rank.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">rank</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor dimension array of length _rank_. For detailed behavior of dimensions field with</span>
<span class="w">  </span><span class="c1">/// various APIs, refer SDK documentation. Must be NULL when rank is 0.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="o">*</span><span class="w"> </span><span class="n">dimensions</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor memory type.</span>
<span class="w">  </span><span class="n">Qnn_TensorMemType_t</span><span class="w"> </span><span class="n">memType</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Actual data contained in the tensor.</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="nc">UNNAMED</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">/// Tensor data provided by client as a pointer to raw memory (see QNN_TENSORMEMTYPE_RAW).</span>
<span class="w">    </span><span class="n">Qnn_ClientBuffer_t</span><span class="w"> </span><span class="n">clientBuf</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Tensor data shared via a memory handle (see QNN_TENSORMEMTYPE_MEMHANDLE).</span>
<span class="w">    </span><span class="n">Qnn_MemHandle_t</span><span class="w"> </span><span class="n">memHandle</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_TensorV1_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_TensorV1_t initializer macro</span>
<span class="cp">#define QNN_TENSOR_V1_INIT                                        \</span>
<span class="cp">  {                                                               \</span>
<span class="cp">    0u,                                     </span><span class="cm">/*id*/</span><span class="cp">                \</span>
<span class="cp">    NULL,                                   </span><span class="cm">/*name*/</span><span class="cp">              \</span>
<span class="cp">    QNN_TENSOR_TYPE_UNDEFINED,              </span><span class="cm">/*type*/</span><span class="cp">              \</span>
<span class="cp">    QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER,     </span><span class="cm">/*dataFormat*/</span><span class="cp">        \</span>
<span class="cp">    QNN_DATATYPE_UNDEFINED,                 </span><span class="cm">/*dataType*/</span><span class="cp">          \</span>
<span class="cp">    QNN_QUANTIZE_PARAMS_INIT,               </span><span class="cm">/*quantizeParams*/</span><span class="cp">    \</span>
<span class="cp">    0u,                                     </span><span class="cm">/*rank*/</span><span class="cp">              \</span>
<span class="cp">    NULL,                                   </span><span class="cm">/*dimensions*/</span><span class="cp">        \</span>
<span class="cp">    QNN_TENSORMEMTYPE_UNDEFINED,            </span><span class="cm">/*memType*/</span><span class="cp">           \</span>
<span class="cp">    {                                                             \</span>
<span class="cp">      QNN_CLIENT_BUFFER_INIT                </span><span class="cm">/*clientBuf*/</span><span class="cp">         \</span>
<span class="cp">    }                                                             \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum specifying sparse layout of a tensor. Used only when *dataFormat* is set to</span>
<span class="cm"> * QNN_TENSOR_DATA_FORMAT_SPARSE.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Hybrid coordinate list sparse tensor layout</span>
<span class="w">  </span><span class="n">QNN_SPARSE_LAYOUT_HYBRID_COO</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_SPARSE_LAYOUT_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_SparseLayoutType_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which defines the parameters for a COO sparse tensor layout.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Number of specified elements of a sparse tensor. Treated as the maximum when creating a</span>
<span class="w">  </span><span class="c1">/// tensor.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numSpecifiedElements</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Size of the index for a hybrid COO sparse tensor. The size of the index can range from 1 to</span>
<span class="w">  </span><span class="c1">/// the rank of the tensor. This feature allows for partially sparse tensors.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numSparseDimensions</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_SparseLayoutHybridCoo_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_SparseLayoutCoo_t initializer macro</span>
<span class="cp">#define QNN_SPARSE_LAYOUT_HYBRID_COO_INIT \</span>
<span class="cp">  {                                       \</span>
<span class="cp">    0u, </span><span class="cm">/*numSpecifiedElements*/</span><span class="cp">          \</span>
<span class="cp">    0u  </span><span class="cm">/*numSparseDimensions*/</span><span class="cp">           \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which defines the sparse tensor parameters. See the SDK documentation for</span>
<span class="cm"> *        details. Used only when *dataFormat* is set to QNN_TENSOR_DATA_FORMAT_SPARSE.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Specifies the sparse tensor layout</span>
<span class="w">  </span><span class="n">Qnn_SparseLayoutType_t</span><span class="w"> </span><span class="n">type</span><span class="p">;</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="nc">UNNAMED</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">/// Hybrid coordinate list layout. Used when *type* is QNN_SPARSE_LAYOUT_HYBRID_COO.</span>
<span class="w">    </span><span class="n">Qnn_SparseLayoutHybridCoo_t</span><span class="w"> </span><span class="n">hybridCoo</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_SparseParams_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_SparseParams_t initializer macro</span>
<span class="cp">#define QNN_SPARSE_PARAMS_INIT                      \</span>
<span class="cp">  {                                                 \</span>
<span class="cp">    QNN_SPARSE_LAYOUT_UNDEFINED,      </span><span class="cm">/*type*/</span><span class="cp">      \</span>
<span class="cp">    QNN_SPARSE_LAYOUT_HYBRID_COO_INIT </span><span class="cm">/*hybridCoo*/</span><span class="cp"> \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which describes the properties of a V2 version of tensor.</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Unique integer identifier for a tensor, generated by the backend based on the tensor name.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">id</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Unique tensor name.</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">name</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor type.</span>
<span class="w">  </span><span class="n">Qnn_TensorType_t</span><span class="w"> </span><span class="n">type</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor data formatting in memory (refer to definition type for info).</span>
<span class="w">  </span><span class="n">Qnn_TensorDataFormat_t</span><span class="w"> </span><span class="n">dataFormat</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor data type.</span>
<span class="w">  </span><span class="n">Qnn_DataType_t</span><span class="w"> </span><span class="n">dataType</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor quantization params.</span>
<span class="w">  </span><span class="n">Qnn_QuantizeParams_t</span><span class="w"> </span><span class="n">quantizeParams</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor rank. Note that rank cannot be dynamic.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">rank</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor dimension array of length _rank_. For detailed behavior of dimensions field with</span>
<span class="w">  </span><span class="c1">/// various APIs, refer to their API documentation. Must be NULL when rank is 0. Must contain</span>
<span class="w">  </span><span class="c1">/// non-zero values if non-null.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="o">*</span><span class="w"> </span><span class="n">dimensions</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Tensor memory type.</span>
<span class="w">  </span><span class="n">Qnn_TensorMemType_t</span><span class="w"> </span><span class="n">memType</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Actual data contained in the tensor.</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="nc">UNNAMED</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">/// Tensor data provided by client as a pointer to raw memory (see QNN_TENSORMEMTYPE_RAW).</span>
<span class="w">    </span><span class="n">Qnn_ClientBuffer_t</span><span class="w"> </span><span class="n">clientBuf</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Tensor data shared via a memory handle (see QNN_TENSORMEMTYPE_MEMHANDLE).</span>
<span class="w">    </span><span class="n">Qnn_MemHandle_t</span><span class="w"> </span><span class="n">memHandle</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="w">  </span><span class="c1">/// A boolean array of length _rank_ indicating if a tensor dimension is dynamic. Must be NULL</span>
<span class="w">  </span><span class="c1">/// when rank is 0. Can be NULL if all dimensions are static. A true (non-zero) value indicates</span>
<span class="w">  </span><span class="c1">/// the corresponding dimension is dynamic and a false (zero) value indicates the corresponding</span>
<span class="w">  </span><span class="c1">/// dimension is static. Note that QNN_TENSOR_TYPE_STATIC tensors (see _type_) cannot have dynamic</span>
<span class="w">  </span><span class="c1">/// dimensions. Support for this field can be queried via</span>
<span class="w">  </span><span class="c1">/// QNN_PROPERTY_TENSOR_SUPPORT_DYNAMIC_DIMENSIONS. If this field is unsupported, it must be NULL.</span>
<span class="w">  </span><span class="kt">uint8_t</span><span class="o">*</span><span class="w"> </span><span class="n">isDynamicDimensions</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Sparse tensor parameters. Pertains only to sparse tensors (see QNN_TENSOR_DATA_FORMAT_SPARSE).</span>
<span class="w">  </span><span class="c1">/// Support for this field can be queried via QNN_PROPERTY_TENSOR_SUPPORT_SPARSITY.</span>
<span class="w">  </span><span class="n">Qnn_SparseParams_t</span><span class="w"> </span><span class="n">sparseParams</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Indicates whether or not a call to QnnGraph_execute[Async] produced this output tensor.</span>
<span class="w">  </span><span class="c1">/// Applicable only to QNN_TENSOR_TYPE_APP_READ and QNN_TENSOR_TYPE_APP_READWRITE tensor types.</span>
<span class="w">  </span><span class="c1">/// This field will be undefined if QNN_PROPERTY_GRAPH_SUPPORT_EARLY_TERMINATION is not</span>
<span class="w">  </span><span class="c1">/// supported. Otherwise, this field is not used.</span>
<span class="w">  </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">isProduced</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_TensorV2_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_TensorV2_t initializer macro</span>
<span class="cp">#define QNN_TENSOR_V2_INIT                                     \</span>
<span class="cp">  {                                                            \</span>
<span class="cp">    0u,                                 </span><span class="cm">/*id*/</span><span class="cp">                 \</span>
<span class="cp">    NULL,                               </span><span class="cm">/*name*/</span><span class="cp">               \</span>
<span class="cp">    QNN_TENSOR_TYPE_UNDEFINED,          </span><span class="cm">/*type*/</span><span class="cp">               \</span>
<span class="cp">    QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER, </span><span class="cm">/*dataFormat*/</span><span class="cp">         \</span>
<span class="cp">    QNN_DATATYPE_UNDEFINED,             </span><span class="cm">/*dataType*/</span><span class="cp">           \</span>
<span class="cp">    QNN_QUANTIZE_PARAMS_INIT,           </span><span class="cm">/*quantizeParams*/</span><span class="cp">     \</span>
<span class="cp">    0u,                                 </span><span class="cm">/*rank*/</span><span class="cp">               \</span>
<span class="cp">    NULL,                               </span><span class="cm">/*dimensions*/</span><span class="cp">         \</span>
<span class="cp">    QNN_TENSORMEMTYPE_UNDEFINED,        </span><span class="cm">/*memType*/</span><span class="cp">            \</span>
<span class="cp">    {                                                          \</span>
<span class="cp">      QNN_CLIENT_BUFFER_INIT            </span><span class="cm">/*clientBuf*/</span><span class="cp">          \</span>
<span class="cp">    },                                                         \</span>
<span class="cp">    NULL,                               </span><span class="cm">/*isDynamicDimension*/</span><span class="cp"> \</span>
<span class="cp">    QNN_SPARSE_PARAMS_INIT,             </span><span class="cm">/*sparseParams*/</span><span class="cp">       \</span>
<span class="cp">    0u                                  </span><span class="cm">/*isProduced*/</span><span class="cp">         \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief Enum to distinguish various tensor versions</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Enum to choose usage of Qnn_TensorV1_t in Qnn_Tensor_t</span>
<span class="w">  </span><span class="n">QNN_TENSOR_VERSION_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Enum to choose usage of Qnn_TensorV2_t in Qnn_Tensor_t</span>
<span class="w">  </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_TENSOR_VERSION_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_TensorVersion_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which provides various versions of a tensor</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Version of the QNN tensor</span>
<span class="w">  </span><span class="n">Qnn_TensorVersion_t</span><span class="w"> </span><span class="n">version</span><span class="p">;</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="nc">UNNAMED</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">/// Tensor version 1 (see QNN_TENSOR_VERSION_1)</span>
<span class="w">    </span><span class="n">Qnn_TensorV1_t</span><span class="w"> </span><span class="n">v1</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Tensor version 2 (see QNN_TENSOR_VERSION_2)</span>
<span class="w">    </span><span class="n">Qnn_TensorV2_t</span><span class="w"> </span><span class="n">v2</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="p">;</span>

<span class="c1">/// Qnn_Tensor_t initializer macro</span>
<span class="cp">#define QNN_TENSOR_INIT               \</span>
<span class="cp">  {                                   \</span>
<span class="cp">    QNN_TENSOR_VERSION_1, </span><span class="cm">/*version*/</span><span class="cp"> \</span>
<span class="cp">    {                                 \</span>
<span class="cp">      QNN_TENSOR_V1_INIT </span><span class="cm">/*v1*/</span><span class="cp">       \</span>
<span class="cp">    }                                 \</span>
<span class="cp">  }</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which describes the properties of a V1 set of input and output tensors</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// The number of input tensors.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numInputs</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Array of input tensors.</span>
<span class="w">  </span><span class="n">Qnn_Tensor_t</span><span class="o">*</span><span class="w"> </span><span class="n">inputs</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// The number of output tensors.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numOutputs</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Array of output tensors.</span>
<span class="w">  </span><span class="n">Qnn_Tensor_t</span><span class="o">*</span><span class="w"> </span><span class="n">outputs</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_TensorSetV1_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_TensorSetV1_t initializer macro</span>
<span class="cp">#define QNN_TENSOR_SET_V1_INIT \</span>
<span class="cp">  {                            \</span>
<span class="cp">    0u,   </span><span class="cm">/*inputs*/</span><span class="cp">           \</span>
<span class="cp">    NULL, </span><span class="cm">/*inputTensors*/</span><span class="cp">     \</span>
<span class="cp">    0u,   </span><span class="cm">/*numOutputs*/</span><span class="cp">       \</span>
<span class="cp">    NULL  </span><span class="cm">/*outputs*/</span><span class="cp">          \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief Enum to distinguish between tensor set versions</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Enum to choose usage of Qnn_TensorSetV1_t in Qnn_TensorSet_t</span>
<span class="w">  </span><span class="n">QNN_TENSOR_SET_VERSION_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_TENSOR_SET_VERSION_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_TensorSetVersion_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which provides the version of a tensor set</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Version of the QNN tensor set</span>
<span class="w">  </span><span class="n">Qnn_TensorSetVersion_t</span><span class="w"> </span><span class="n">version</span><span class="p">;</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="nc">UNNAMED</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">/// Tensor set version 1 (see QNN_TENSOR_SET_VERSION_1)</span>
<span class="w">    </span><span class="n">Qnn_TensorSetV1_t</span><span class="w"> </span><span class="n">v1</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_TensorSet_t</span><span class="p">;</span>

<span class="c1">/// Qnn_TensorSet_t initializer macro</span>
<span class="cp">#define QNN_TENSOR_SET_INIT               \</span>
<span class="cp">  {                                       \</span>
<span class="cp">    QNN_TENSOR_SET_VERSION_1, </span><span class="cm">/*version*/</span><span class="cp"> \</span>
<span class="cp">    {                                     \</span>
<span class="cp">      QNN_TENSOR_SET_V1_INIT </span><span class="cm">/*v1*/</span><span class="cp">       \</span>
<span class="cp">    }                                     \</span>
<span class="cp">  }</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A struct which defines a named scalar or tensor parameter.</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Parameter type: scalar or tensor</span>
<span class="w">  </span><span class="n">Qnn_ParamType_t</span><span class="w"> </span><span class="n">paramType</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Name of the parameter</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">name</span><span class="p">;</span>

<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="nc">UNNAMED</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">/// Scalar parameter specification</span>
<span class="w">    </span><span class="n">Qnn_Scalar_t</span><span class="w"> </span><span class="n">scalarParam</span><span class="p">;</span>
<span class="w">    </span><span class="c1">/// Tensor parameter specification; tensors referred to must be STATIC.</span>
<span class="w">    </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">tensorParam</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_Param_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_Param_t initializer macro</span>
<span class="cp">#define QNN_PARAM_INIT                     \</span>
<span class="cp">  {                                        \</span>
<span class="cp">    QNN_PARAMTYPE_UNDEFINED, </span><span class="cm">/*paramType*/</span><span class="cp"> \</span>
<span class="cp">    NULL,                    </span><span class="cm">/*name*/</span><span class="cp">      \</span>
<span class="cp">    {                                      \</span>
<span class="cp">      QNN_SCALAR_INIT </span><span class="cm">/*scalarParam*/</span><span class="cp">      \</span>
<span class="cp">    }                                      \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief This struct defines the configuration for a single operation.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// A human-readable name for the operation instance.</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">name</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// The name of the operation package to which this operation&#39;s type belongs.</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">packageName</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// The name of operation type (e.g. Conv2D).</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">typeName</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// The number of static parameters provided in the params array.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numOfParams</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Array of operation parameters.</span>
<span class="w">  </span><span class="n">Qnn_Param_t</span><span class="o">*</span><span class="w"> </span><span class="n">params</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// The number of input tensors.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numOfInputs</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Array of input tensors.</span>
<span class="w">  </span><span class="n">Qnn_Tensor_t</span><span class="o">*</span><span class="w"> </span><span class="n">inputTensors</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// The number of output tensors.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numOfOutputs</span><span class="p">;</span>
<span class="w">  </span><span class="c1">/// Array of output tensors.</span>
<span class="w">  </span><span class="n">Qnn_Tensor_t</span><span class="o">*</span><span class="w"> </span><span class="n">outputTensors</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_OpConfigV1_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_OpConfigV1_t initializer macro</span>
<span class="cp">#define QNN_OPCONFIG_V1_INIT    \</span>
<span class="cp">  {                             \</span>
<span class="cp">    NULL,     </span><span class="cm">/*name*/</span><span class="cp">          \</span>
<span class="cp">    NULL,     </span><span class="cm">/*packageName*/</span><span class="cp">   \</span>
<span class="cp">    NULL,     </span><span class="cm">/*typeName*/</span><span class="cp">      \</span>
<span class="cp">    0u,       </span><span class="cm">/*numOfParams*/</span><span class="cp">   \</span>
<span class="cp">    NULL,     </span><span class="cm">/*params*/</span><span class="cp">        \</span>
<span class="cp">    0u,       </span><span class="cm">/*numOfInputs*/</span><span class="cp">   \</span>
<span class="cp">    NULL,     </span><span class="cm">/*inputTensors*/</span><span class="cp">  \</span>
<span class="cp">    0u,       </span><span class="cm">/*numOfOutputs*/</span><span class="cp">  \</span>
<span class="cp">    NULL      </span><span class="cm">/*outputTensors*/</span><span class="cp"> \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief Enum to distinguish various opConfig versions</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Enum to choose usage of Qnn_OpConfigV1_t in Qnn_OpConfig_t</span>
<span class="w">  </span><span class="n">QNN_OPCONFIG_VERSION_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_OPCONFIG_VERSION_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_OpConfigVersion_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief Structure which provides various versions of an opConfig</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Version of the QNN opConfig</span>
<span class="w">  </span><span class="n">Qnn_OpConfigVersion_t</span><span class="w"> </span><span class="n">version</span><span class="p">;</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="nc">UNNAMED</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">/// Op config version 1 (see QNN_OPCONFIG_VERSION_1)</span>
<span class="w">    </span><span class="n">Qnn_OpConfigV1_t</span><span class="w"> </span><span class="n">v1</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_OpConfig_t</span><span class="p">;</span>

<span class="c1">// clang-format off</span>
<span class="c1">/// Qnn_OpConfig_t initializer macro</span>
<span class="cp">#define QNN_OPCONFIG_INIT               \</span>
<span class="cp">  {                                     \</span>
<span class="cp">    QNN_OPCONFIG_VERSION_1, </span><span class="cm">/*version*/</span><span class="cp"> \</span>
<span class="cp">    {                                   \</span>
<span class="cp">      QNN_OPCONFIG_V1_INIT </span><span class="cm">/*v1*/</span><span class="cp">       \</span>
<span class="cp">    }                                   \</span>
<span class="cp">  }</span>
<span class="c1">// clang-format on</span>

<span class="cm">/**</span>
<span class="cm"> * @brief An enum which identifies SOC models.</span>
<span class="cm"> *</span>
<span class="cm"> * @deprecated This enumeration will no longer be updated.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_UNKNOWN</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SM8350</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SM8325</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">34</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SM7350</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SM7325</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">35</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SM8450</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">36</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SC8280X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">37</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SM7315</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">38</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SA8295</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">39</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SM7450</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">41</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SM8475</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">42</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SM8550</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">43</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SM6450</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">50</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SA8255</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">52</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SM7475</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">54</span><span class="p">,</span>
<span class="w">  </span><span class="n">QNN_SOC_MODEL_SM4450</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">59</span><span class="p">,</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_SocModel_t</span><span class="p">;</span>

<span class="cp">#ifdef __cplusplus</span>
<span class="p">}</span><span class="w">  </span><span class="c1">// extern &quot;C&quot;</span>
<span class="cp">#endif</span>

<span class="cp">#endif  </span><span class="c1">// QNN_TYPES_H</span>
</pre></div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020-2024, Qualcomm Technologies, Inc..

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>