

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Tutorial - Benchmarking the Qualcomm® AI Engine Direct Delegate &mdash; Qualcomm® AI Engine Direct Delegate</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/custom_css.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Tutorial - Running Inference Using Shared Memory" href="tutorial_htp_shared_memory.html" />
    <link rel="prev" title="Tutorial - Skip Delegation Ops Using the Qualcomm® AI Engine Direct Delegate" href="tutorial_skip_node.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Qualcomm® AI Engine Direct Delegate
          

          
          </a>

          
            
            
              <div class="version">
                v2.22.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="qnn_libs.html">Qualcomm® AI Engine Direct Backend Library</a></li>
<li class="toctree-l1"><a class="reference internal" href="support.html">Acceleration Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_op.html">Custom Operator Support</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tutorial_qtld_net_run.html">Tutorial - Running Inference Using the Qualcomm® AI Engine Direct Delegate</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_skip_node.html">Tutorial - Skip Delegation Ops Using the Qualcomm® AI Engine Direct Delegate</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Tutorial - Benchmarking the Qualcomm® AI Engine Direct Delegate</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="#running-the-benchmark">Running the Benchmark</a></li>
<li class="toctree-l3"><a class="reference internal" href="#generate-model-cache-or-restoring-from-one">Generate Model Cache or Restoring from One</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_htp_shared_memory.html">Tutorial - Running Inference Using Shared Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_mix_precision.html">Tutorial - Use Mix-Precision Model with Qualcomm® AI Engine Direct Delegate</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_qtld_profiler.html">Tutorial - Profile Custom Models using Qualcomm® AI Engine Direct Delegate</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_version_history.html">API Version History</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Qualcomm® AI Engine Direct Delegate</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="tutorials.html">Tutorials</a> &raquo;</li>
        
      <li>Tutorial - Benchmarking the Qualcomm® AI Engine Direct Delegate</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tutorial-benchmarking-the-qualcomm-r-ai-engine-direct-delegate">
<h1>Tutorial - Benchmarking the Qualcomm® AI Engine Direct Delegate<a class="headerlink" href="#tutorial-benchmarking-the-qualcomm-r-ai-engine-direct-delegate" title="Permalink to this heading">¶</a></h1>
<p>This tutorial demonstrates how to benchmark models running through the Qualcomm® AI Engine Direct
Delegate using the TFLite benchmark_model application.</p>
<div class="section" id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this heading">¶</a></h2>
<p>The following list of prerequisites must be met before starting this tutorial:</p>
<ol class="arabic simple">
<li><p>Finished the Setup from QNN, notice this is different from the Delegate Setup Section.
The QNN Setup Section can be accessed through $QNN_SDK_ROOT/docs/QNN/index.html.
After open up the index.html, users should see the Setup Section for QNN on the left side.</p></li>
<li><p>A Qualcomm device with an ADB connection.</p></li>
<li><p>Read the <a class="reference internal" href="overview.html"><span class="doc">Overview</span></a> and <a class="reference internal" href="setup.html"><span class="doc">Setup</span></a> pages to
understand the different components of the Qualcomm® AI Engine Direct Delegate.</p></li>
<li><p>The TFLite <a class="reference external" href="https://www.tensorflow.org/lite/performance/measurement#native_benchmark_binary">native benchmark_model application</a>.
It is possible to use a precompiled version of the <em>benchmark_model</em>
application through the External Delegate interface.</p></li>
<li><p>Set the environment variable <cite>TENSORFLOW_HOME</cite> to point to the location where TensorFlow package is installed.
TensorFlow 2.10.1 has been tested and is compatible with this tutorial.</p></li>
</ol>
</div>
<div class="section" id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">¶</a></h2>
<p>This tutorial will use the same <em>inception_v3_quant</em> model used in
<a class="reference internal" href="tutorial_qtld_net_run.html#setup"><span class="std std-ref">Tutorial qtld-net-run Setup</span></a> to perform benchmarking.</p>
<p>Follow the instructions below to download the model and un-tar it. If you have
already performed this setup, these commands can be skipped.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python3<span class="w"> </span><span class="nv">$QNN_SDK_ROOT</span>/examples/Models/InceptionV3/scripts/setup_inceptionv3.py<span class="w"> </span>-a<span class="w"> </span>~/tmpdir<span class="w"> </span>-d
$<span class="w"> </span>python3<span class="w"> </span><span class="nv">$QNN_SDK_ROOT</span>/examples/QNN/TFLiteDelegate/Models/InceptionV3Quant/scripts/convert_inceptionv3_tflite.py
</pre></div>
</div>
<p>There should be a file called <em>inception_v3_quant.tflite</em> under $QNN_SDK_ROOT/examples/QNN/TFLiteDelegate/Models/InceptionV3Quant. This
is the model that will be used to run benchmarking.</p>
<p>Push the <em>benchmark_model</em> application, the TFLite model, the Qualcomm® AI Engine Direct Delegate, and
the Qualcomm® AI Engine Direct backend libraries to the device using ADB.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>adb<span class="w"> </span>shell<span class="w"> </span>mkdir<span class="w"> </span>-p<span class="w"> </span>/data/local/tmp/qnn_delegate/inception_v3_quant
$<span class="w"> </span>adb<span class="w"> </span>push<span class="w"> </span>&lt;PATH_TO_BENCHMARK_MODEL&gt;/benchmark_model<span class="w"> </span>/data/local/tmp/qnn_delegate/
$<span class="w"> </span>adb<span class="w"> </span>push<span class="w"> </span>inception_v3_quant.tflite<span class="w"> </span>/data/local/tmp/qnn_delegate/inception_v3_quant/
$<span class="w"> </span>adb<span class="w"> </span>push<span class="w"> </span><span class="nv">$QNN_SDK_ROOT</span>/lib/aarch64-android/libQnnTFLiteDelegate.so<span class="w"> </span>/data/local/tmp/qnn_delegate/
<span class="c1"># push QNN libraries</span>
$<span class="w"> </span>adb<span class="w"> </span>push<span class="w"> </span><span class="nv">$QNN_SDK_ROOT</span>/lib/aarch64-android/libQnnSystem.so<span class="w"> </span>/data/local/tmp/qnn_delegate/
$<span class="w"> </span>adb<span class="w"> </span>push<span class="w"> </span><span class="nv">$QNN_SDK_ROOT</span>/lib/aarch64-android/libQnnHtp.so<span class="w"> </span>/data/local/tmp/qnn_delegate/
$<span class="w"> </span>adb<span class="w"> </span>push<span class="w"> </span><span class="nv">$QNN_SDK_ROOT</span>/lib/aarch64-android/libQnnHtpPrepare.so<span class="w"> </span>/data/local/tmp/qnn_delegate/
$<span class="w"> </span>adb<span class="w"> </span>push<span class="w"> </span><span class="nv">$QNN_SDK_ROOT</span>/lib/aarch64-android/libQnnHtpV68Stub.so<span class="w"> </span>/data/local/tmp/qnn_delegate/
$<span class="w"> </span>adb<span class="w"> </span>push<span class="w"> </span><span class="nv">$QNN_SDK_ROOT</span>/lib/aarch64-android/libQnnHtpV69Stub.so<span class="w"> </span>/data/local/tmp/qnn_delegate/
$<span class="w"> </span>adb<span class="w"> </span>push<span class="w"> </span><span class="nv">$QNN_SDK_ROOT</span>/lib/aarch64-android/libQnnHtpV73Stub.so<span class="w"> </span>/data/local/tmp/qnn_delegate/
$<span class="w"> </span>adb<span class="w"> </span>push<span class="w"> </span><span class="nv">$QNN_SDK_ROOT</span>/lib/hexagon-v68/unsigned/libQnnHtpV68Skel.so<span class="w"> </span>/data/local/tmp/qnn_delegate/
$<span class="w"> </span>adb<span class="w"> </span>push<span class="w"> </span><span class="nv">$QNN_SDK_ROOT</span>/lib/hexagon-v69/unsigned/libQnnHtpV69Skel.so<span class="w"> </span>/data/local/tmp/qnn_delegate/
$<span class="w"> </span>adb<span class="w"> </span>push<span class="w"> </span><span class="nv">$QNN_SDK_ROOT</span>/lib/hexagon-v73/unsigned/libQnnHtpV73Skel.so<span class="w"> </span>/data/local/tmp/qnn_delegate/
</pre></div>
</div>
<p>Notice that the model data does not need to be pushed to the device. This is
because the <em>benchmark_model</em> application will automatically create random data
for benchmarking.</p>
</div>
<div class="section" id="running-the-benchmark">
<h2>Running the Benchmark<a class="headerlink" href="#running-the-benchmark" title="Permalink to this heading">¶</a></h2>
<p>Run the following command to benchmark the <em>inception_v3_quant</em> model.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>adb<span class="w"> </span>shell<span class="w"> </span><span class="s1">&#39;export LD_LIBRARY_PATH=/data/local/tmp/qnn_delegate/:$LD_LIBRARY_PATH &amp;&amp;</span>
<span class="s1">             export ADSP_LIBRARY_PATH=&quot;/data/local/tmp/qnn_delegate/&quot; &amp;&amp;</span>
<span class="s1">             cd /data/local/tmp/qnn_delegate/inception_v3_quant/ &amp;&amp;</span>
<span class="s1">             /data/local/tmp/qnn_delegate/benchmark_model \</span>
<span class="s1">             --graph=inception_v3_quant.tflite \</span>
<span class="s1">             --external_delegate_path=/data/local/tmp/qnn_delegate/libQnnTFLiteDelegate.so \</span>
<span class="s1">             --external_delegate_options=&quot;backend_type:htp&quot;&#39;</span>
</pre></div>
</div>
<p>In order to enable per-operator profiling measurements from the benchmark, add
the <code class="docutils literal notranslate"><span class="pre">--enable_op_profiling=true</span></code> <em>benchmark_model</em> option along with the
<code class="docutils literal notranslate"><span class="pre">profiling:2</span></code> delegate option. Look at
<a class="reference internal" href="options.html#external-delegate-options"><span class="std std-ref">External Delegate Options</span></a> for more information. Run the following
command to get per-operator profiling measurements. You can also save a csv file
by <code class="docutils literal notranslate"><span class="pre">profiling_output_csv_file</span></code> option of <em>benchmark_model</em>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The profiling behavior of Qualcomm® AI Engine Direct Delegate subject to change in near future. Please use with cautions.</p>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>adb<span class="w"> </span>shell<span class="w"> </span><span class="s1">&#39;export LD_LIBRARY_PATH=/data/local/tmp/qnn_delegate/:$LD_LIBRARY_PATH &amp;&amp;</span>
<span class="s1">             export ADSP_LIBRARY_PATH=&quot;/data/local/tmp/qnn_delegate/&quot; &amp;&amp;</span>
<span class="s1">             cd /data/local/tmp/qnn_delegate/inception_v3_quant/ &amp;&amp;</span>
<span class="s1">             /data/local/tmp/qnn_delegate/benchmark_model \</span>
<span class="s1">             --graph=inception_v3_quant.tflite \</span>
<span class="s1">             --external_delegate_path=/data/local/tmp/qnn_delegate/libQnnTFLiteDelegate.so \</span>
<span class="s1">             --external_delegate_options=&quot;backend_type:htp;profiling:2&quot; \</span>
<span class="s1">             --enable_op_profiling=true&#39;</span>
</pre></div>
</div>
<p>Note that the <em>benchmark_model</em> application displays the unit as a time measurement
whereas HTP backend capture cycles events.</p>
<p>The HTP backend allows for performance modes which can be configured to achieve
the best performance. Adding the <code class="docutils literal notranslate"><span class="pre">htp_performance_mode:1</span></code> delegate option will
enable the maximum performance mode, details for different performance modes
options can be found here <a class="reference internal" href="options.html#external-delegate-options"><span class="std std-ref">External Delegate Options</span></a>.
Run the following command to enable max performance mode.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>adb<span class="w"> </span>shell<span class="w"> </span><span class="s1">&#39;export LD_LIBRARY_PATH=/data/local/tmp/qnn_delegate/:$LD_LIBRARY_PATH &amp;&amp;</span>
<span class="s1">             export ADSP_LIBRARY_PATH=&quot;/data/local/tmp/qnn_delegate/&quot; &amp;&amp;</span>
<span class="s1">             cd /data/local/tmp/qnn_delegate/inception_v3_quant/ &amp;&amp;</span>
<span class="s1">             /data/local/tmp/qnn_delegate/benchmark_model \</span>
<span class="s1">             --graph=inception_v3_quant.tflite \</span>
<span class="s1">             --external_delegate_path=/data/local/tmp/qnn_delegate/libQnnTFLiteDelegate.so \</span>
<span class="s1">             --external_delegate_options=&quot;backend_type:htp;htp_performance_mode:1&quot;&#39;</span>
</pre></div>
</div>
<p>Note that this option is only for the HTP backend. Other backends handle
performance mode configurations internally.</p>
<p>Congratulations, you have just benchmarked the Qualcomm® AI Engine Direct Delegate!</p>
</div>
<div class="section" id="generate-model-cache-or-restoring-from-one">
<h2>Generate Model Cache or Restoring from One<a class="headerlink" href="#generate-model-cache-or-restoring-from-one" title="Permalink to this heading">¶</a></h2>
<p>By specifying <code class="docutils literal notranslate"><span class="pre">model_token</span></code> and <code class="docutils literal notranslate"><span class="pre">cache_dir</span></code> in <code class="docutils literal notranslate"><span class="pre">--external_delegate_options</span></code>, the
model passed in through the <code class="docutils literal notranslate"><span class="pre">--graph</span></code> option will either be saved to a
folder for future use, or loaded from the cache file if that file is present.
Building on the example above:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>adb<span class="w"> </span>shell<span class="w"> </span><span class="s1">&#39;export LD_LIBRARY_PATH=/data/local/tmp/qnn_delegate/:$LD_LIBRARY_PATH &amp;&amp;</span>
<span class="s1">             export ADSP_LIBRARY_PATH=&quot;/data/local/tmp/qnn_delegate/&quot; &amp;&amp;</span>
<span class="s1">             cd /data/local/tmp/qnn_delegate/inception_v3_quant/ &amp;&amp;</span>
<span class="s1">             /data/local/tmp/qnn_delegate/benchmark_model \</span>
<span class="s1">             --graph=inception_v3_quant.tflite \</span>
<span class="s1">             --external_delegate_path=/data/local/tmp/qnn_delegate/libQnnTFLiteDelegate.so \</span>
<span class="s1">             --external_delegate_options=&quot;backend_type:htp;htp_performance_mode:1;cache_dir:/data/local/tmp/;model_token:qnn_delegate_model&quot;&#39;</span>
</pre></div>
</div>
<p>If the cache directory doesn’t exist, model caching will fail.
if it exists and caching data doesn’t exist, model caching will operate in <em>SAVE MODE</em>, meaning
the prepared model will be saved to these files. These files are created by the Qualcomm® AI Engine Direct Delegate.
The effect of caching can be seen if <code class="docutils literal notranslate"><span class="pre">benchmark_model</span></code>
is executed with the same options again.  Its console output would indicate caching is operating
in <em>RESTORE MODE</em>.</p>
<p>The activation of the model caching feature is logged as INFO / WARNING logs.</p>
<p>One way to tell if the model is being restored from the cache file, rather than prepared from the tflite
model file, is by comparing the time it took to initialize the session.  The time can be found on the
<code class="docutils literal notranslate"><span class="pre">Initialized</span> <span class="pre">session</span></code> line in console output:  For moderate or large models, there should be a noticeable
difference.</p>
<p>One thing to note about the model caching feature:  The Qualcomm® AI Engine Direct Delegate is designed to continue with the inference
requests even when the caching feature fails. Here are some of the ways
that the caching feature can fail:</p>
<ul class="simple">
<li><p>Files in <code class="docutils literal notranslate"><span class="pre">cache_dir</span></code> are not readable when restoring, or not writable when saving</p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="tutorial_htp_shared_memory.html" class="btn btn-neutral float-right" title="Tutorial - Running Inference Using Shared Memory" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="tutorial_skip_node.html" class="btn btn-neutral float-left" title="Tutorial - Skip Delegation Ops Using the Qualcomm® AI Engine Direct Delegate" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021-2023, Qualcomm Technologies, Inc..

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>